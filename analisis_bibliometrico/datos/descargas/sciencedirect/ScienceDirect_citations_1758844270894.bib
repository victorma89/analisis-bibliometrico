@article{STIDHAM2025432,
title = {Artificial Intelligence–Enabled Clinical Trials in Inflammatory Bowel Disease: Automating and Enhancing Disease Assessment and Study Management},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {432-443},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.02.039},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525005414},
author = {Ryan W. Stidham and Louis R. Ghanem and Joel G. Fletcher and David H. Bruining},
keywords = {Artificial Intelligence, Inflammatory Bowel Disease, Crohn's Disease, Ulcerative Colitis, Computer Vision, Automation, Large Language Models, Natural Language Processing, Digital Twin},
abstract = {Artificial intelligence (AI) will fundamentally improve how we perform clinical trials by addressing issues of standardizing disease scoring, improving the sensitivity and precision of activity and phenotype assessments, and automating laborious and time-consuming study functions. Progress in AI image analysis is quickly proving to replicate expert judgment in endoscopy, histology, and cross-sectional imaging with speed, reproducibility, and reduced bias. However, AI analytics offer the ability to quantify disease characteristics with more detail and precision than human experts. Large language models and generative AI are automating the collection of high-quality data from electronic records and improving our ability to predict patient outcomes. This narrative review will focus on AI tools available today, their expected implementation, and future-facing opportunities for AI to reimagine inflammatory bowel disease clinical trials.}
}
@article{LIU2025682,
title = {Interactive Design of Dynamic Visual Communication Driven by Artificial Intelligence Algorithms},
journal = {Procedia Computer Science},
volume = {261},
pages = {682-690},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.321},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925014231},
author = {Shen Liu and Li Ding},
keywords = {Dynamic visual communication design, artificial intelligence algorithm, spatial attention mechanism, channel attention mechanism, generative adversarial network},
abstract = {Dynamic visual communication design usually needs to process multimodal information. How to effectively integrate these multi-dimensional features and establish stable associations between different modalities remains a technical challenge. To this end, this article explores the application of artificial intelligence algorithms, especially spatial attention and channel attention mechanisms, in dynamic image and video generation to achieve more accurate semantic consistency between text and images. This article introduces a spatial attention mechanism, which dynamically focuses on the spatial area related to the text description by calculating the similarity between text and image features; at the same time, the channel attention mechanism further optimizes the match with the text description by adjusting the channel weights in the image feature map. In addition, the study introduces user interaction design, and users can influence the generation target of the generator through real-time feedback and adjustment, making it more personalized and in line with needs. The optimization process of the generator and the discriminator further improves the realism and quality of dynamic image and video generation through GAN (Generative Adversarial Network). Experiments show that the proposed method can effectively enhance the semantic consistency in the image generation process and provide new technical support for dynamic visual communication design.}
}
@article{COBO2025103251,
title = {Physical foundations for trustworthy medical imaging: A survey for artificial intelligence researchers},
journal = {Artificial Intelligence in Medicine},
volume = {169},
pages = {103251},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103251},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725001861},
author = {Miriam Cobo and David {Corral Fontecha} and Wilson Silva and Lara {Lloret Iglesias}},
keywords = {Physics, Medical imaging, Artificial intelligence, Physics-informed machine learning, Generative AI},
abstract = {Artificial intelligence in medical imaging has grown rapidly in the past decade, driven by advances in deep learning and widespread access to computing resources. Applications cover diverse imaging modalities, including those based on electromagnetic radiation (e.g., X-rays), subatomic particles (e.g., nuclear imaging), and acoustic waves (ultrasound). Each modality features and limitations are defined by its underlying physics. However, many artificial intelligence practitioners lack a solid understanding of the physical principles involved in medical image acquisition. This gap hinders leveraging the full potential of deep learning, as incorporating physics knowledge into artificial intelligence systems promotes trustworthiness, especially in limited data scenarios. This work reviews the fundamental physical concepts behind medical imaging and examines their influence on recent developments in artificial intelligence, particularly, generative models and reconstruction algorithms. Finally, we describe physics-informed machine learning approaches to improve feature learning in medical imaging.}
}
@article{FELDMAN2023336,
title = {Beyond Clinical Accuracy: Considerations for the Use of Generative Artificial Intelligence Models in Gastrointestinal Care},
journal = {Gastroenterology},
volume = {165},
number = {2},
pages = {336-338},
year = {2023},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2023.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0016508523008740},
author = {Keith Feldman and Fredy Nehme}
}
@article{VASAVADA2025S48,
title = {A NOVEL WEB APPLICATION UTILIZING GENERATIVE ARTIFICIAL INTELLIGENCE TO ENHANCE ENDOSCOPY EDUCATION FOR GASTROENTEROLOGY FELLOWS},
journal = {Gastrointestinal Endoscopy},
volume = {101},
number = {5, Supplement },
pages = {S48},
year = {2025},
note = {ASGE Abstracts - DDW 2025},
issn = {0016-5107},
doi = {https://doi.org/10.1016/j.gie.2025.03.088},
url = {https://www.sciencedirect.com/science/article/pii/S0016510725002573},
author = {Shaleen Vasavada and Theresa H. Nguyen and Scott Larson}
}
@article{ACAMPORA2026100807,
title = {Quantum artificial intelligence: A survey},
journal = {Computer Science Review},
volume = {59},
pages = {100807},
year = {2026},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100807},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725000838},
author = {Giovanni Acampora and Angela Chiatto and Roberto Schiattarella and Autilia Vitiello},
keywords = {Artificial intelligence, Quantum computing, Quantum artificial intelligence},
abstract = {Quantum computing and artificial intelligence are two highly topical fields of research that can benefit from each other’s discoveries by opening a completely new scenario in computation, that of quantum artificial intelligence. Indeed, on the one hand, artificial intelligence algorithms can be made computationally more efficient due to the potential speedup enabled by quantum phenomena; on the other hand, the complex development of quantum computing technologies and methodologies can be properly supported by the use of classical artificial intelligence approaches. The “entanglement” of these two disciplines is opening up completely new directions in computer science research, and this survey aims to provide a systematic and taxonomic overview of the work that has already been done and that which will begin in the near future.}
}
@article{SCHWENDICKE2025315,
title = {Artificial Intelligence in Prosthodontics},
journal = {Dental Clinics of North America},
volume = {69},
number = {2},
pages = {315-326},
year = {2025},
note = {Updates in Prosthodontics},
issn = {0011-8532},
doi = {https://doi.org/10.1016/j.cden.2024.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0011853224000958},
author = {Falk Schwendicke and Hossein {Mohammad Rahimi} and Antonin Tichy},
keywords = {AI, Computer vision, Deep learning, Intraoral scan, Image analysis, Prosthesis}
}
@article{MARTIN2025,
title = {Prevalence of artificial intelligence use and instruction in nursing education: A national study of prelicensure nursing programs in the United States},
journal = {Journal of Nursing Regulation},
year = {2025},
issn = {2155-8256},
doi = {https://doi.org/10.1016/j.jnr.2025.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S2155825625000924},
author = {Brendan Martin and Michaela Reid},
keywords = {Prelicensure nursing education, Artificial intelligence},
abstract = {Background
There is ample evidence that the integration of artificial intelligence (AI) tools into nursing practice is becoming more commonplace, but there are fewer national resources indicating to what degree prelicensure nursing programs employ these technologies and incorporate related topics into their curriculum.
Purpose
The current survey study sought to determine the prevalence of registered nurse (RN) and licensed practical nurse (LPN) education programs’ use of generative AI technologies, and the extent to which they embed AI and other digital health topics into their instructional content.
Methods
A national survey was conducted of all RN and LPN program administrators nationwide for which we had email contact information (N = 2744).
Results
Prelicensure RN programs (n = 122, 24 %) were more likely to use generative AI technology than LPN programs (n = 27, 12 %, p < 0.001), but more than three-quarters of both types of programs reported they do not use such tools or are not sure. In addition to the low usage of generative AI technology, few programs reported teaching advancements in AI and/or other digital health–related topics to their students (RN n = 87, 17 %; LPN n = 25, 11 %).
Conclusion
Nursing education programs that limit integration of AI into their curriculum risk potentially limiting students’ learning on evidence-based practice and may miss opportunities to promote critical reflection. The results of our study underscore the need to support nursing faculty to ensure prelicensure instructional content prepares nursing students for advancements in clinical practice.}
}
@article{UKWANDU2025103616,
title = {The future of teaching and learning in the context of emerging artificial intelligence technologies},
journal = {Futures},
volume = {171},
pages = {103616},
year = {2025},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2025.103616},
url = {https://www.sciencedirect.com/science/article/pii/S0016328725000783},
author = {Elochukwu Ukwandu and Omobolanle Omisade and Karl Jones and Simon Thorne and Mike Castle},
keywords = {Generative artificial intelligence, Prompt technologies, Artificial intelligence, ChatGPT, AI-Agents, Future of teaching and learning, Emerging AI disruptive technologies},
abstract = {In the context of emerging artificial intelligence technologies (AI) such as AI-Bots (ChatGPT) and AI-Agents, it is imperative that adequate adjustment be made, and also seen to be made. However, this has to be done from an informed positions. There is no doubt that these disruptive technologies are changing the way we live, conduct our day-to-day businesses, teach, learn and conduct research. There are also emerging concerns that these dynamics may result in a paradigm shift from student-teacher relationship to student-AI-Tutor-based relationship within the academic circle. Besides, there are foreseeable dangers of compromising academic integrity through high-technology plagiarism and the potentials of students avoiding learning through AI deployment and utilisation in their academic pursuits. But something worth considering is how applying these tools in education will potentially change the entire classroom experience of students, their knowledge and skills outcomes that are relevant in this AI era. This position paper is an effort to put into context what the authors of this paper forecast as the future of teaching and learning in the context of these inevitable disruptions to education activities and its subsectors as we currently know it. The authors found it necessary to take these positions to help bring to fore some practical use cases of AI in education; recent developments and theoretical frameworks in literature, technical reports, as well as experts opinions that can help assuage stakeholder’s concerns despite some obvious existing challenges. It is our view that this paper will be found useful by educators, stakeholders and administrators in the areas of curriculum design, classroom administration and entire academic planning and reviews.}
}
@article{MATOS2025100571,
title = {A systematic review of artificial intelligence applications in education: Emerging trends and challenges},
journal = {Decision Analytics Journal},
volume = {15},
pages = {100571},
year = {2025},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2025.100571},
url = {https://www.sciencedirect.com/science/article/pii/S277266222500027X},
author = {Tomás Matos and Walter Santos and Eftim Zdravevski and Paulo Jorge Coelho and Ivan Miguel Pires and Filipe Madeira},
keywords = {Artificial intelligence, ChatGPT, Educational technology, Machine learning, Adaptive learning, Systematic review},
abstract = {The academic world is becoming increasingly interested in the applications of Artificial Intelligence technology in education. A systematic review examines AI applications in education, focusing on their effectiveness, challenges, and implications. A comprehensive analysis of studies published between 2011 and 2024 encompassed 45 research articles from major databases, such as PubMed Central, IEEE Xplore, Elsevier, Springer, MDPI, ACM, and PMC. The findings highlight the predominant use of generative AI tools like ChatGPT (30%), followed by other advanced technologies, such as GPT-4, machine learning, and virtual reality. Research across global regions, particularly in Canada (18%), the United States (12%), and China (8%), highlights the multifaceted applications of AI in enhancing personalized learning, fostering critical thinking, and supporting professional education. Tools such as ChatGPT have demonstrated strong performance in theoretical knowledge delivery and medical education, while augmented and virtual reality excels in practical skill development. Despite these advances, challenges such as data privacy concerns, algorithmic bias, and the need for specialized educator training remain critical.}
}
@article{SAENKHUM2023101066,
title = {Generative artificial intelligence and second language writing},
journal = {Journal of Second Language Writing},
volume = {62},
pages = {101066},
year = {2023},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2023.101066},
url = {https://www.sciencedirect.com/science/article/pii/S1060374323001042},
author = {Tanita Saenkhum and Soo Hyon Kim}
}
@article{CUAYCONG2024106730,
title = {Abstract 1126 Generative Artificial Intelligence in Molecular Design and Virtual Screening of Novel Caspase-1 Inhibitors},
journal = {Journal of Biological Chemistry},
volume = {300},
number = {3, Supplement },
pages = {106730},
year = {2024},
note = {Discover BMB 2024},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2024.106730},
url = {https://www.sciencedirect.com/science/article/pii/S0021925824012031},
author = {Stephanie Cuaycong and Chidinma Ralph-Mbah and Amele Divo and Yufeng Wei},
keywords = {inflammasome, cell death, caspase-1, edothelial cells}
}
@article{LI2025100023,
title = {A review of data science and artificial intelligence applications in air transportation systems},
journal = {Artificial Intelligence for Transportation},
volume = {2},
pages = {100023},
year = {2025},
issn = {3050-8606},
doi = {https://doi.org/10.1016/j.ait.2025.100023},
url = {https://www.sciencedirect.com/science/article/pii/S3050860625000237},
author = {Lishuai Li},
keywords = {Artificial intelligence, Data science, Air transportation, Air traffic management, Airline operations, Airport management, Aviation safety, Sustainability},
abstract = {The air transportation system is a critical component of global infrastructure, moving passengers and cargo worldwide. Rising traffic volumes and operational complexity have driven the evolution of analytical methods in aviation: from early rule-based automation through mechanism-based models (simulations, digital twins), operations research (optimization, statistics) and data-driven approaches (machine learning, deep learning) to emerging autonomous systems (generative AI, agentic AI). This review examines data science and artificial intelligence (AI) applications that address specific aviation challenges and demonstrate measurable operational improvements. We analyze implementations in airline management, airport operations and air traffic management, identifying performance gains that include reduced delays, improved aircraft utilization, lower maintenance costs, and improved safety metrics. However, AI deployment faces technical barriers including legacy system integration and data standardization, along with regulatory and ethical challenges that include certification processes, data privacy, and liability frameworks for automated decision making. Future research priorities could focus on developing robust AI systems that meet aviation’s stringent safety and reliability standards, advancing AI-enabled sustainability through integrated design and operational optimization, and establishing frameworks for novel air transportation systems, including urban air mobility and autonomous flight operations.}
}
@article{JOWSEY2023971,
title = {Medical education empowered by generative artificial intelligence large language models},
journal = {Trends in Molecular Medicine},
volume = {29},
number = {12},
pages = {971-973},
year = {2023},
issn = {1471-4914},
doi = {https://doi.org/10.1016/j.molmed.2023.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1471491423002113},
author = {Tanisha Jowsey and Jessica Stokes-Parish and Rachelle Singleton and Michael Todorovic},
keywords = {artificial intelligence, large language model, machine learning, education},
abstract = {Generative artificial intelligence (GAI) large language models (LLMs), like ChatGPT, have become the world’s fastest growing applications. Here, we provide useful strategies for educators in medical and health science (M&HS) to integrate GAI-LLMs into learning and teaching practice, ultimately enhancing students’ digital capability.}
}
@article{LEITE2025124115,
title = {Artificial intelligence in higher education: Research notes from a longitudinal study},
journal = {Technological Forecasting and Social Change},
volume = {215},
pages = {124115},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124115},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525001465},
author = {Higor Leite},
keywords = {Generative artificial intelligence, Higher education, Innovation, Technology, Transformative service research},
abstract = {Generative artificial intelligence (GenAI) has disrupted traditional educational approaches. Students are applying GenAI tools to access and create new content. However, the emergence of GenAI in higher education comes with caveats and academics and university administrators are learning to navigate this uncharted territory. GenAI is treated as a double-edged sword, with several benefits, such as innovation and productivity, but also drawbacks regarding ethics and academic misconduct. Therefore, our study aims to understand the impact of GenAI on students' experiences in the higher education ecosystem as students move to a new AI-enhanced job market. This research note article presents preliminary results from a 12-month longitudinal study with students interacting with GenAI. We conducted 35 semi-structured interviews and collected private diary entries (n = 108). Our results show six meaningful themes: Harnessing AI for Enhanced Academic Performance, AI Ethics and Trust Impact on Learning, GenAI as a Supplement to Human Work, Integration and Versatility of GenAI Tools, Balancing GenAI Limitations, and Navigating the AI Adoption Journey. The study also uses the transformative service research lens to present the transformative impact of GenAI in higher education. To contribute to practice and policymakers, we designed a research agenda to inform future studies on GenAI.}
}
@article{OZTURK2025216,
title = {Artificial intelligence as author: Can scientific reviewers recognize GPT-4o-generated manuscripts?},
journal = {The American Journal of Emergency Medicine},
volume = {97},
pages = {216-219},
year = {2025},
issn = {0735-6757},
doi = {https://doi.org/10.1016/j.ajem.2025.07.034},
url = {https://www.sciencedirect.com/science/article/pii/S0735675725004954},
author = {Ahmet Öztürk and Anılcan Tahsin Karahan and Serkan Günay and Abdul Samed Erdal and Seval Komut and Erdal Komut and Yavuz Yiğit},
keywords = {ChatGPT, Artificial intelligence, Journal, Editor, Reviewer},
abstract = {Introduction
Chat Generative Pre-Trained Transformer (ChatGPT) is a natural language processing model. It can be argued that ChatGPT has recently begun to assume the role of a technological assistant capable of supporting academics in the process of scientific writing. ChatGPT may contribute to the spread of incorrect or incomplete information within academic literature, leading to conceptual confusion and potential academic misconduct. The aim of this study is to determine whether a scientific article entirely generated by an AI application such as ChatGPT can be detected by an academic journal editor or peer reviewer.
Methods
This study was conducted between November 1, 2024, and December 1, 2024. GPT-4o, was utilized in this study. ChatGPT was instructed to write a scientific article focused on predicting mortality and return of spontaneous circulation (ROSC) in OHCA cases. The manuscript written by ChatGPT-4o was sent to 14 different reviewers who had previously served as reviewers or editors. The reviewers were asked to evaluate the manuscript as if they were an SCI-E journal editor or peer reviewer. The reviewers were informed that the article had been written by ChatGPT and were asked whether they had identified this during their review.
Results
Among the reviewers, 42.9 % (n = 6) decided to reject the manuscript at the editorial stage, whereas another 42.9 % (n = 6) opted to forward it to a peer reviewer. During the peer review stage, 42.9 % (n = 6) of the reviewers recommended rejection, while 28.6 % (n = 4) suggested major revisions. 78.6 % (n = 11) of the reviewers did not realize that the manuscript had been generated by an artificial intelligence model.
Conclusion
The findings of our study highlight the necessity for journal editors and peer reviewers to be well-informed about ChatGPT and to develop systems capable of identifying whether a manuscript has been written by a human or generated by artificial intelligence.}
}
@article{CHOI20242616,
title = {Leveraging Generative Artificial Intelligence in Diagnosis of Thrombotic Microangiopathies: Focus on Thrombotic Thrombocytopenic Purpura},
journal = {Blood},
volume = {144},
pages = {2616},
year = {2024},
note = {66th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2024-194769},
url = {https://www.sciencedirect.com/science/article/pii/S0006497124053692},
author = {Eunhee Choi and Jung-Hyun Lee and Robert McDougal and William W Lytton},
abstract = {Introduction Thrombotic microangiopathies (TMA), with etiologies ranging from benign to life-threatening, necessitates rapid and accurate diagnosis, particularly for thrombotic thrombocytopenic purpura (TTP), to initiate timely plasmapheresis preventing severe outcomes. Diagnosing TTP is challenging due to overlapping clinical features with other causes of TMA, such as disseminated intravascular coagulation (DIC), immune thrombocytopenic purpura (ITP), and atypical hemolytic uremic syndrome (aHUS), compounded by that specific diagnostic tests such as biopsies or ADAMTS13 activity assays do not result immediately. This study explored GPT-4's capability in suggesting differential diagnoses for TMA patients and identifying a provisional diagnosis of TTP based on clinical presentation and basic diagnostic workup to determine the need for prompt plasmapheresis, assessing its potential as a diagnostic support tool. Method We utilized open-access case reports from PubMed Central that provided a comprehensive list of cases with diagnosis of TMA. The exclusion criteria included cases with no access, copyright permission issues, preprints, insufficient description, non-case reports, non-English language, and no established diagnosis for TMA. Each case input including only the history and physical examination (H&P) and basic diagnostic workup excluding the confirmatory diagnosis was presented to GPT-4 in three separate trials and was prompted to provide clinical reasoning that both favored or rejected the diagnosis of TTP, create a top three differential diagnoses list selected from a comprehensive list of TMA diagnoses, and determine the necessity of plasmapheresis. Generated results were subsequently compared with the confirmed case diagnosis and management provided within the case report. Result An initial PubMed Central search identified 424 cases; 326 were excluded, resulting in 98 eligible cases. The top three differential diagnoses generated for each case in all three trials exhibited relatively higher F1-scores for ITP, TTP, HUS, and HELLP syndrome, with values of 0.58, 0.59, 0.53, and 0.7, respectively. Other causes of TMA scored below 0.5. Overall performance metrics indicated a specificity of 0.85, sensitivity of 0.80, precision of 0.28, and an F1-score of 0.42. When grouped into TTP versus non-TTP cases, the sensitivity was notably high at 0.98, showing that GPT-4 could adequately rule out TTP, although the specificity was 0.76. When comparing the case diagnosis with the primary diagnosis within the top three differential diagnoses, the overall specificity was 0.96, sensitivity was 0.56, precision was 0.58, and the F1-score was 0.57. The match rate of GPT-4 suggesting plasmapheresis compared to the case report was 76%. In cases confirmed as TTP, GPT-4 demonstrated 100% accuracy in recommending plasmapheresis. For non-TTP cases, GPT-4 showed a 66% match rate compared to the case report's decision to initiate plasmapheresis, indicating a 34% reduction in suggesting plasmapheresis for these cases. Error analysis revealed that errors were primarily due to GPT-4 ignoring pertinent findings, inaccurate knowledge, and confounding symptoms or findings within the case report itself. Discussion This study demonstrated that GPT-4 could adequately assist in the diagnosis of TMA and provide suggestions for early management of TTP based on clinical presentation and basic diagnostic workup. GPT-4 appropriately recommended plasmapheresis for TTP cases and showed a comparable performance of that of a clinically commonly used tool in these settings, PLASMIC score. However, in our study, GPT-4 made errors such as ignoring pertinent findings and demonstrating incomplete knowledge, highlighting the need for pretraining and areas to improve regarding diagnosis of TMA. The study suggested that GPT-4 could be integrated as a diagnostic support tool, especially for complex, time-sensitive conditions, while emphasizing that it should complement, not replace, clinical judgment.}
}
@article{ABBAS2025101551,
title = {Management accounting and artificial intelligence: A comprehensive literature review and recommendations for future research},
journal = {The British Accounting Review},
pages = {101551},
year = {2025},
issn = {0890-8389},
doi = {https://doi.org/10.1016/j.bar.2025.101551},
url = {https://www.sciencedirect.com/science/article/pii/S0890838925000010},
author = {Khalid Abbas},
keywords = {Artificial intelligence, Machine learning, Explainable AI, Management accounting, Large language models, Digitalization},
abstract = {Digitalization and artificial intelligence (AI) technologies have the potential to disrupt and transform the management accounting domain and the role of accountants. The study systematically reviews 91 articles, synthesizing scholarly work on digitalization, AI, machine learning (ML), deep learning (DL), explainable AI, generative AI, and large language models (LLMs) in management accounting. In this context, the value of the paper is multi-fold. First, we argue that these technologies transform accounting information and organizational structures, affecting the accounting function's relationship with other organizational functions. Second, they present new challenges for management accountants, including data privacy, confidentiality, security and ethical concerns. Third, digital technologies automate basic accounting tasks and decision-making processes, potentially reshaping management accountants' roles and skills in terms of job elimination, upskilling, deskilling and reskilling. Fourth, these technologies create new opportunities for multidisciplinary collaboration and redefine professional boundaries. This paper contributes by discussing the impact of digitalization and the latest AI technologies on management accounting, illustrating how they can create business value, and highlighting associated challenges and risks for the profession. It proposes research agendas and potential research questions for future studies, providing insight into the potential impacts and implications for the accounting profession and the role of accountants.}
}
@article{JOBSTREIBIZER2025372,
title = {The impact of artificial intelligence on business models: a bibliometric-systematic literature review},
journal = {Management Decision},
volume = {63},
number = {13},
pages = {372-396},
year = {2025},
issn = {0025-1747},
doi = {https://doi.org/10.1108/MD-10-2024-2309},
url = {https://www.sciencedirect.com/science/article/pii/S0025174725000084},
author = {Joshua Jobstreibizer and Tatiana Beliaeva and Marcos Ferasso and Sascha Kraus and Andreas Kallmuenzer},
keywords = {Artificial intelligence, AI, Business models, Bibliometric-systematic literature review, Network analysis},
abstract = {Purpose
This study aims to conduct a bibliometric-Systematic Literature Review’ (B-SLR) to trace the impact of artificial intelligence (AI) on business models (BM). It explores the intellectual structure, key thematic clusters and the evolution of this emerging field, with the aim of identifying current trends and future research directions.
Design/methodology/approach
The analysis covers 87 journal articles retrieved from the Scopus database. It follows the guidelines of a multi-method literature review, combining a bibliometric analysis and a systematic literature review. Co-citation, co-occurrence and timeline analyses were performed to uncover intellectual foundations, map key research areas and track recent developments.
Findings
The study highlights the central role of AI in reshaping BM, particularly in areas such as customer engagement, innovation, sustainability, Industry 4.0 and digitalization. Recent developments emphasize AI’s applications in narrow fields, circular BM and the growing influence of generative AI. A framework of AI adoption in BM is developed, suggesting promising directions for future research.
Research limitations/implications
This study suggests that future research should explore AI’s role in BM more deeply by integrating interdisciplinary perspectives. It highlights the need for more empirical studies on AI-driven innovation and its long-term effects on business strategies, particularly in emerging areas such as generative AI and circular economy models.
Practical implications
This review provides managers with insights into how AI can drive BM innovation and highlights emerging areas of AI applications. It offers a roadmap for integrating AI technologies into BM to gain competitive advantages.
Originality/value
This study provides an up-to-date, comprehensive analysis of AI’s impact on BM, contributing to both academic literature and practical business strategies by synthesizing recent developments and suggesting future research directions.}
}
@article{JEONG2025110855,
title = {Application of Explainable Artificial Intelligence for personalized childhood weight management using IoT data},
journal = {Computers in Biology and Medicine},
volume = {196},
pages = {110855},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110855},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525012065},
author = {Jaemin Jeong and Ji-Hoon Jeong and Gee-Myung Moon and Young-Duk Seo and Euijong Lee},
keywords = {Healthcare, Shapley additive explanation (SHAP), Tabnet, Explainable artificial intelligence (XAI), Generative adversarial networks (GAN)},
abstract = {Childhood obesity is a growing global health concern as it is correlated with an increased risk of adult-onset and chronic diseases. Recent advances in digital healthcare technologies have enhanced the efficiency of health data analysis and diagnosis, leading to increased interest in artificial intelligence (AI) applications in childhood obesity research; however, several challenges remain, such as data limitations, class-imbalance issues, and difficulties in model interpretability. This study addresses these challenges through a comprehensive framework that utilizes wearable devices for real-time lifestyle data collection and employs Wasserstein generative adversarial networks (WGANs) to address data imbalance concerns. The proposed framework incorporates an explainable model architecture combining tabular attention network (TabNet) with eXtreme Gradient Boosting (XGBoost), complemented by SHapley Additive exPlanations (SHAP) analysis for enhanced interpretability. The framework was validated using data collected from 362 elementary school students over six months, with an additional external validation set of 82 students. The results demonstrated exceptional performance with 98.0% accuracy on the test dataset and 85.2% accuracy on the external validation data. Therefore, the framework can provide personalized health guidance by identifying and explaining individual factors that contribute to weight change, thereby enabling targeted intervention strategies for childhood obesity prevention.}
}
@article{CHEN2025113575,
title = {Computational design of indoor lighting supported by artificial intelligence: Recent advances and future prospects},
journal = {Building and Environment},
volume = {285},
pages = {113575},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.113575},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325010479},
author = {Peng Chen and Lixiong Wang and Yuting Wu and Zelin Liang and Juan Yu and Tianyi Chen},
keywords = {Interior lighting, Computational design, Artificial intelligence, Generative design},
abstract = {The growing complexity of indoor lighting requirements demands innovative design approaches. AI-supported computational design has demonstrated potential in generating design solutions under complex constraints, yet the lighting society lacks a comprehensive understanding of this approach. Seventy-nine publications were collected for bibliometric analysis. Then a three-domain framework was proposed and reviewed. For lighting environment integration, (deep) neural networks enable analysis of light intensity, spectrum, and spatial distribution patterns through sparse sensors or RGB images. For lighting performance modeling, ML and ANN achieve real-time, personalized, and environment-aware prediction of lighting performance. For lighting design support, heuristic algorithm-dominated systems intelligently generate luminaire layouts, dimming strategies, and spectral compositions while balancing functional, perceptual, and energy-saving objectives. Deep learning demonstrates end-to-end generative capabilities but is limited by data availability. “Perception-as-generation” is proposed as the future direction for computational lighting design, emphasizing responsiveness to the individual and temporal diversity of perceptual needs. A roadmap is proposed to establishing a lighting decision-making pivot centered on large language models. The associated technical challenges and opportunities are outlined too. This research will help practitioners better understand and apply AI, promote interdisciplinary collaboration in the lighting industry, and inspire lighting design paradigm innovation under the "good lighting" vision.}
}
@article{ALKAN2025112033,
title = {Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112033},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112033},
url = {https://www.sciencedirect.com/science/article/pii/S095219762502041X},
author = {Nurşah Alkan and Umut Aydın and Akın Menekşe and Cengiz Kahraman},
keywords = {Evaluation based on distance from average solution, Continuous intuitionistic fuzzy sets, Multi-criteria decision-making, Artificial intelligence, Chatbot, Chat generative pre-trained transformer},
abstract = {The rapid evolution of artificial intelligence (AI) has introduced novel opportunities and challenges in various fields. In this study, we present a pioneering approach known as Continuous Intuitionistic Fuzzy (CINFU) Evaluation based on Distance from Average Solution (EDAS), an innovative extension of the EDAS method tailored to Continuous Intuitionistic Fuzzy Sets. This methodology is designed to compare the performance of AI tools. The capabilities of AI bots have been examined through their success rates in various tasks and uncertainty levels in decision-making processes. The study aims to evaluate the effectiveness of different models in decision-making processes by analyzing the performances of AI bots such as Chat Generative Pre-trained Transformer (ChatGPT), Bard, and Claude based on both objective measurements and fuzzy evaluation criteria. The comparison focuses on key performance criteria such as Bots Triggered, User Engagement, Message Click-Through Rate, Chat Handoff, User Retention, Bounce Rate & Dwell Time, Leads Captured, and Customer Satisfaction Score. Ultimately, the validity and robustness of the approach have been tested with sensitivity analysis.}
}
@article{PERES2023269,
title = {On ChatGPT and beyond: How generative artificial intelligence may affect research, teaching, and practice},
journal = {International Journal of Research in Marketing},
volume = {40},
number = {2},
pages = {269-275},
year = {2023},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2023.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167811623000162},
author = {Renana Peres and Martin Schreier and David Schweidel and Alina Sorescu},
keywords = {ChatGPT, Generative AI, Artificial intelligence, LLMs},
abstract = {How does ChatGPT, and other forms of Generative Artificial Intelligence (GenAI) affect the way we have been conducting—and evaluating—academic research, teaching, and business practice? What are the implications for the theory and practice of marketing? What are the opportunities and threats, and what are some interesting avenues for future research? This editorial aims to kick off an initial discussion and stimulate research that will help us better understand how the marketing field can fully exploit the potential of GenAI and effectively cope with its challenges.}
}
@article{POIRRIER2023S398,
title = {MSR26 The Use of Copilot, a Generative Artificial Intelligence Tool, as VBA Programming Assistant in Excel-Based Health Economic Models},
journal = {Value in Health},
volume = {26},
number = {12, Supplement },
pages = {S398},
year = {2023},
note = {ISPOR Europe 2023 Abstracts},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2023.09.2085},
url = {https://www.sciencedirect.com/science/article/pii/S1098301523052154},
author = {J.E. Poirrier and R. Bergemann}
}
@article{2024S154,
title = {500 Hyponatremia Virtual Patient Simulator: An innovative educational tool with generative artificial intelligence and physiologic models},
journal = {American Journal of Kidney Diseases},
volume = {83},
number = {4, Supplement 2},
pages = {S154},
year = {2024},
note = {National Kidney Foundation 2024 Spring Clinical Meeting Abstracts},
issn = {0272-6386},
doi = {https://doi.org/10.1053/j.ajkd.2024.01.503},
url = {https://www.sciencedirect.com/science/article/pii/S027263862400550X}
}
@article{SIMSEK2025e806,
title = {The predictive effect of nursing students' attitudes and acceptance towards artificial intelligence on their clinical competencies},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {3},
pages = {e806-e814},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.02.036},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725000824},
author = {Enes Şimşek and Aslı Akdeniz Kudubeş and Remziye {Semerci Şahin}},
keywords = {Acceptance, Artificial intelligence, Attitude, Clinical competency, Nursing student},
abstract = {Background
AI integration in education is gaining interest, including in nursing, as students seek formal training on its healthcare applications and limitations.
Aim
To evaluate the predictive effect of nursing students' attitudes and acceptance of artificial intelligence on their clinical competencies.
Methods
This descriptive-correlational study was conducted at 2 universities (February–June 2024) with 441 nursing students. Full-time students in clinical practice participated; those absent or on leave were excluded. The Nursing Students Competency Scale, General Attitudes to Artificial Intelligence Scale, and Generative Artificial Intelligence Acceptance Scale were used. Descriptive statistics and linear regression were used.
Results
The main factors affecting nursing students' clinical competence were “facilitating conditions,” “social influence,” and “negative attitudes” toward AI. A weak correlation was found between positive AI attitudes and acceptance, which explained 8.6% of the competency levels.
Conclusion
Positive perceptions of AI may increase competence, while skepticism may deepen engagement and critical learning. Strategies to improve the acceptance and use of AI are crucial to maximize its benefits in nursing education and practice.}
}
@article{BIGNAMI2025101078,
title = {Artificial intelligence in healthcare: Tailoring education to meet EU AI-Act standards},
journal = {Health Policy and Technology},
volume = {14},
number = {6},
pages = {101078},
year = {2025},
issn = {2211-8837},
doi = {https://doi.org/10.1016/j.hlpt.2025.101078},
url = {https://www.sciencedirect.com/science/article/pii/S2211883725001066},
author = {Elena Bignami and Luigino Jalale Darhour and Wolfgang Buhre and Maurizio Cecconi and Valentina Bellini},
keywords = {Artificial intelligence, AI-Act, Education, Policy},
abstract = {The integration of Artificial Intelligence (AI) in Intensive Care Units (ICUs) has the potential to transform critical care by enhancing diagnosis, management, and clinical decision-making. Generative and Predictive AI technologies offer new opportunities for personalized care and risk stratification, but their implementation must prioritize ethical standards, patient safety, and the sustainability of care delivery. With the EU AI-Act entering into force in February 2025, a structured and responsible adoption of AI is now imperative. This article outlines a strategic framework for ICU AI integration, emphasizing the importance of a formal declaration of intent by each unit, detailing current AI-use, implementation plans, and governance strategies. Central to this approach is the development of tailored AI education programs adapted to four distinct professional profiles, ranging from experienced clinicians with limited AI knowledge to new intensivists with strong AI backgrounds but limited clinical experience. Training must foster critical thinking, contextual interpretation, and a balanced relationship between AI tools and human judgment. A multidisciplinary support team should oversee ethical AI-use and continuous performance monitoring. Ultimately, aligning regulatory compliance with targeted education and practical implementation could enable a safe, effective, and ethically grounded use of AI in intensive care. This balanced approach would support a culture of transparency and accountability, while preserving the central role of human clinical reasoning and improving the overall quality of ICU care.}
}
@article{THANGARAJ20242340,
title = {EVIDENCE FROM RANDOMIZED CONTROLLED TRIAL TO REAL-WORLD PATIENTS USING ELECTRONIC HEALTH RECORD-ADAPTED DIGITAL TWINS: A NOVEL APPLICATION OF GENERATIVE ARTIFICIAL INTELLIGENCE},
journal = {Journal of the American College of Cardiology},
volume = {83},
number = {13, Supplement },
pages = {2340},
year = {2024},
note = {ACC.24},
issn = {0735-1097},
doi = {https://doi.org/10.1016/S0735-1097(24)04330-4},
url = {https://www.sciencedirect.com/science/article/pii/S0735109724043304},
author = {Phyllis Thangaraj and Sumukh Vasisht Shankar and Evangelos K. Oikonomou and Rohan Khera}
}
@article{JONES2025100557,
title = {I gotta use words when I talk to you: Primed suspension of disbelief in views on agency in relation to Artificial Intelligence},
journal = {Information and Organization},
volume = {35},
number = {1},
pages = {100557},
year = {2025},
issn = {1471-7727},
doi = {https://doi.org/10.1016/j.infoandorg.2025.100557},
url = {https://www.sciencedirect.com/science/article/pii/S147177272500003X},
author = {Matthew Jones},
keywords = {Agency, Artificial intelligence},
abstract = {The public launch of generative AI systems in 2022 has prompted considerable popular interest in their potential to transform work and to achieve the long-sought goal of machine intelligence. While the uncanny abilities of Large Language Models to produce fluent text on almost any subject lends these ideas some plausibility, they are based on debatable, if not erroneous, claims about the capabilities of generative AI. Although rarely presented in these terms, these claims may be seen to reflect a limited, substantive conception of the agency of AI systems. Alternative conceptualisations of agency from other disciplines are presented that may offer potentially more fruitful ways of thinking about agency in relation to AI. The way that conceptions of the agency of AI systems is shaped by the language used to describe their behaviour is highlighted and opportunities for alternative conceptions of agency to inform a more critical analysis of generative AI are identified.}
}
@article{ROBLES2025100685,
title = {Fundamentals of artificial intelligence},
journal = {Revista de Senología y Patología Mamaria},
volume = {38},
number = {4},
pages = {100685},
year = {2025},
issn = {0214-1582},
doi = {https://doi.org/10.1016/j.senol.2025.100685},
url = {https://www.sciencedirect.com/science/article/pii/S0214158225000210},
author = {Rafael Guzmán Robles},
keywords = {Artificial intelligence, Machine learning, Deep learning, Reinforcement learning, Generative AI, Inteligencia artificial, Aprendizaje automático, Aprendizaje profundo, Aprendizaje por refuerzo, IA generativa},
abstract = {Artificial Intelligence (AI) is revolutionizing various industries, with healthcare being one of the most impacted sectors. This article explores the fundamentals of AI, with a specific focus on machine learning, deep learning, and generative AI. Machine learning, a subset of AI, enables systems to identify patterns in large data sets, improving over time without being explicitly programmed. Deep learning, a more advanced subfield, uses multi-layered neural networks to process complex information. The advent of generative AI, such as GPT and GANs, has expanded the potential of AI to create new content autonomously, transforming areas like drug discovery and personalized medicine. The article also addresses the ethical considerations surrounding the use of AI, particularly concerning data privacy, algorithmic bias, and equitable access to AI-driven technologies. These considerations are essential for ensuring the responsible development and implementation of AI in healthcare.
Resumen
La Inteligencia Artificial (IA) está revolucionando varias industrias, siendo la sanidad uno de los sectores más afectados. Este artículo explora los fundamentos de la IA, centrándose específicamente en el aprendizaje automático, el aprendizaje profundo y la IA generativa. El aprendizaje automático, un subconjunto de la IA, permite a los sistemas identificar patrones en grandes conjuntos de datos, mejorando con el tiempo sin ser programados explícitamente. El aprendizaje profundo, un subcampo más avanzado, utiliza redes neuronales multicapa para procesar información compleja. La llegada de la IA generativa, como las GPT y las GAN, ha ampliado el potencial de la IA para crear nuevos contenidos de forma autónoma, transformando ámbitos como el descubrimiento de fármacos y la medicina personalizada. El artículo también aborda las consideraciones éticas que rodean el uso de la IA, en particular las relativas a la privacidad de los datos, el sesgo algorítmico y el acceso equitativo a las tecnologías impulsadas por la IA. Estas consideraciones son esenciales para garantizar el desarrollo y la aplicación responsables de la IA en la atención sanitaria.}
}
@article{GARG2024178,
title = {Generative artificial intelligence ChatGPT-4: A transformative epoch in the realm of psychiatric care of children with intellectual developmental disorders},
journal = {General Hospital Psychiatry},
volume = {90},
pages = {178-180},
year = {2024},
issn = {0163-8343},
doi = {https://doi.org/10.1016/j.genhosppsych.2024.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0163834324000859},
author = {Sunny Garg and Alka Chauhan},
keywords = {ChatGPT-4, Children, Educational scenarios, Generative artificial intelligence, Intellectual developmental disorders, Personalized learning}
}
@article{NIGRO20252390,
title = {Artificial Intelligence–Generated Answers to Patients’ Questions on Asthma: The Artificial Intelligence Responses on Asthma Study},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
volume = {13},
number = {9},
pages = {2390-2396},
year = {2025},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2025.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S2213219825004209},
author = {Mattia Nigro and Andrea Aliverti and Alessandra Angelucci and Fulvio Braido and Giorgio W. Canonica and Apostolos Bossios and Hilary Pinnock and Jeanette Boyd and Pippa Powell and Stefano Aliberti},
keywords = {Asthma, Artificial intelligence, AI, Reliability, Accuracy, Comprehensiveness, Understandability, Disease awareness, Personalized medicine},
abstract = {Background
Asthma is a prevalent chronic respiratory disease requiring ongoing patient education and individualized management. The increasing reliance on digital tools, particularly generative artificial intelligence (AI), to answer health-related questions has raised concerns about the accuracy, reliability, and comprehensibility of AI-generated information for people living with asthma.
Objective
To evaluate systematically the reliability, accuracy, comprehensiveness, and understandability of responses generated by three widely used artificial intelligence–based chatbots (ChatGPT, Bard, and Copilot) to common questions formulated by people with asthma.
Methods
In this cross-sectional study, 15 questions regarding asthma management were formulated by patients and categorized by difficulty. Responses from ChatGPT, Bard, and Copilot were evaluated by international experts for accuracy and comprehensiveness, and by patient representatives for understandability. Reliability was assessed through consistency testing across devices. We conducted a blinded evaluation.
Results
A total of 21 experts and 16 patient representatives participated in the evaluation. ChatGPT demonstrated the highest reliability (15 of 15 responses), accuracy (median score, 9.0; interquartile range [IQR], 7.0-9.0), and comprehensiveness (median score, 8.0; IQR, 8.0-9.0) compared with Bard and Copilot (P < .0001). Bard achieved superior scores in understandability (median score, 9.0; IQR, 8.0-10.0; P < .0001). Performance differences were consistent across question difficulty levels.
Conclusions
Artificial intelligence–driven chatbots can provide generally accurate and understandable responses to asthma-related questions. Variability in reliability and accuracy underscores the need for caution in clinical contexts. Artificial intelligence tools may complement but cannot replace professional medical advice in asthma management.}
}
@article{BERLINSKI2024102723,
title = {Artificial imaginaries: Generative AIs as an advanced form of capitalism},
journal = {Critical Perspectives on Accounting},
volume = {99},
pages = {102723},
year = {2024},
issn = {1045-2354},
doi = {https://doi.org/10.1016/j.cpa.2024.102723},
url = {https://www.sciencedirect.com/science/article/pii/S1045235424000224},
author = {Elise Berlinski and Jérémy Morales and Samuel Sponem},
keywords = {Generative AI, ChatGPT, Social imaginaries, Standardization, Domination},
abstract = {In this essay, we characterize three paradoxical imaginaries that structure the development of generative artificial intelligence (genAI). At the institutional level, these technologies develop in a context that celebrates openness and liberality. Yet, both in the US and in Europe, they serve to centralize power and resources. At the organizational level, while the imaginary is that these technologies make work more interesting, we show that they rather produce anxiety and a new class of precarious workers. At the epistemic level, generative artificial intelligence promises access to unlimited knowledge. This knowledge may appear robust, as these technologies become performative. However, the knowledge they produce is doubtful. Overall, these technologies centralize power and exclude, they standardize knowledge, and they produce, reproduce, amplify and extend various structures of domination.}
}
@article{RUSSELL2025102483,
title = {Toward amplifying the good in nursing education: A quality improvement study on implementing artificial intelligence-based assistants in a learning system},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102483},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102483},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001368},
author = {Regina G. Russell and Jules White and Allen Karns and Karely Rodriguez and Pamela R. Jeffries and Patricia Sengstack},
keywords = {Nursing education, Artificial intelligence, Generative AI, Large language models, Innovation, Systems thinking, Leadership, Change management, Quality improvement, Interprofessional education},
abstract = {ABSTRACT
Effective integration of artificial intelligence-based tools into nursing care and science will depend on aligned integration in nursing education. Our quality improvement study documents the process and short-term outcomes of introducing a generative AI-based tool into a nursing education system. Nursing school faculty and staff at one private, southeastern university (n = 364) piloted an internally constrained chatbot system for 2 months in 2024. Data were captured to evaluate the (a) costs of implementation, (b) use cases in nursing education, and (c) projected system impact. Costs were lower than $2 per month, per user. There were 148 diverse case reports from 35 unique users. On a separate survey, 35 respondents rated technology acceptability as 5.2/7.0. Projected impact is high (6.3/7.0), but not entirely positive (5.9/7.0). Benefits and challenges were identified. Nursing will need to invest expert time and community resources to evolve education systems along with these evolving technologies.}
}
@article{ZHOU2025114970,
title = {Artificial intelligence-assisted next-generation biomaterials: From design and preparation to medical applications},
journal = {Colloids and Surfaces B: Biointerfaces},
volume = {255},
pages = {114970},
year = {2025},
issn = {0927-7765},
doi = {https://doi.org/10.1016/j.colsurfb.2025.114970},
url = {https://www.sciencedirect.com/science/article/pii/S0927776525004771},
author = {Bixia Zhou and Xin Li and Yuchen Pan and Bingfang He and Bingbing Gao},
keywords = {Artificial Intelligence, Biomaterials, Machine Learning, Materials Design, Biomedical Applications},
abstract = {The Fourth Industrial Revolution (Industry 4.0) has marked a shift from traditional materials to the era of smart materials. The integration of artificial intelligence (AI) with biomaterials is transforming the biosensing and biomedical fields. Although AI-assisted biomaterial manufacturing holds significant promise, the design and synthesis of smart materials remain in the early stages. To accelerate the implementation of AI-assisted biomaterials in fields such as biomedicine and biological intelligent systems, various algorithms have been developed to predict material properties, enable material de novo design, and establish a foundation for the development of next-generation multifunctional biomaterials. This review presents a comprehensive overview of AI-assisted biomaterial design, property prediction, fabrication, and potential biomedical applications. Recent advances in AI-driven protein engineering relevant to materials science are summarized, followed by an analysis of AI's role in designing, predicting, and optimizing next-generation biomaterials. The influence of AI-assisted systems on the structural and functional properties of biosmart materials is also explored. Applications such as therapeutic diagnostics, electronic skin (e-skin), biosensing, and other biomedical technologies are highlighted. Finally, current challenges and future perspectives are discussed, with emphasis on the transformative potential of AI in advancing materials science and biomedicine, as well as its ability to address previously intractable problems.}
}
@article{WAMBATAGUIMDJE2024,
title = {Why Should Users Take the Risk of Sustainable Use of Generative Artificial Intelligence Chatbots:},
journal = {Journal of Global Information Management},
volume = {32},
number = {1},
year = {2024},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.365600},
url = {https://www.sciencedirect.com/science/article/pii/S106273752400043X},
author = {Serge-Lopez Wamba-Taguimdje and Samuel Fosso Wamba and Hossana Twinomurinzi},
keywords = {ChatGPT, GenAI-Chatbot, Artificial Intelligence, Risks, User Satisfaction, Sustainable Use},
abstract = {ABSTRACT
Despite the risks associated with generative AI (GenAI) chatbots, people increasingly use these technologies, which may seem contradictory. This study identified and explored factors and risks related to trust, perceived values, satisfaction, and sustainable use of GenAI chatbots. Relying on IS theories to build a stimulus-organism-response model, the authors tested a model using PLS-SEM with data from 393 ChatGPT users. The results show that user competence and autonomy dramatically increase a user's trust in ChatGPT, and trust improves hedonic value (HV), utilitarian value (UV), value-in-use, perceived task-technology fit (TTF), information accuracy, knowledge acquisition, perceived informativeness, and user satisfaction. In addition to trust, user satisfaction depends on HV, UV, and TTF. The sustainability use of ChatGPT depends on HV and satisfaction. However, perceived privacy concerns, perceived privacy risks, and privacy awareness do not affect consumer trust. There is a complete mediation between trust and sustainability, as well as HV and sustainability.}
}
@article{ZHANG2025101244,
title = {How can artificial intelligence help college students develop entrepreneurial ability? Evidence from China},
journal = {The International Journal of Management Education},
volume = {23},
number = {3},
pages = {101244},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101244},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725001144},
author = {Qianjun Zhang and Lixu Li and Chenli Xu and Yuanyuan Qi and Xiaorong Zhao},
keywords = {AI knowledge, Generative AI, Entrepreneurship, Creativity, College students},
abstract = {With AI rapidly transforming industries and creating new opportunities, college students are uniquely positioned to leverage artificial intelligence (AI) for entrepreneurial ventures. Nevertheless, despite the growing significance of AI knowledge, students frequently face challenges in connecting theoretical knowledge with practical use, which impedes their capacity to transform AI-driven insights into effective business strategies. Drawing on data from a survey of 1021 Chinese university students, this study investigates the connections between AI knowledge, two modes of generative AI usage (GAU), and entrepreneurial ability, with a special emphasis on the moderating influence of individual creativity. The results indicate that AI knowledge positively influences entrepreneurial ability. Interestingly, two GAU modes (i.e., depth and breadth) serve as important mediators in the relationship between AI knowledge and entrepreneurial ability. Surprisingly, individual creativity enhances the mediation effect of GAU depth between AI knowledge and entrepreneurial ability but does not enhance the mediation effect of GAU breadth between AI knowledge and entrepreneurial ability. This study advances existing research by uncovering the mechanisms and boundary conditions that facilitate the transformation of AI knowledge into substantive entrepreneurial ability. The findings also offer insights into improving instructional design in the age of AI.}
}
@article{NEVIERE2024S474,
title = {MSR184 Leveraging Generative Artificial Intelligence for Assessing the Quality of Network Meta-Analysis: Methodological Considerations and Early Findings},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S474-S475},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2418},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524052811},
author = {A Nevière and G Friedrich and K Papadimitropoulou and P {Le Nouveau} and A Gauthier}
}
@article{SCHLESSINGER2025,
title = {Artificial Intelligence in Cosmetic Dermatology and Dermatologic Surgery},
journal = {Dermatologic Clinics},
year = {2025},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000488},
author = {Daniel Isaac Schlessinger},
keywords = {Artificial intelligence, Large language model, Dermatologic surgery, Robotic surgery, Mohs surgery, Laser surgery, Hair transplantation, Basal cell carcinoma}
}
@article{THANG2025,
title = {The Current State and Future Prospects for Artificial Intelligence in Dermatology},
journal = {Dermatologic Clinics},
year = {2025},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000403},
author = {Christopher J. Thang and Caitlyn Duffy and Sara Khattab and Yevgeniy R. Semenov},
keywords = {Artificial intelligence, Machine learning, Deep learning, Medical dermatology, Dermatopathology, Artificial intelligence for health care, Artificial intelligence for dermatology}
}
@article{TSIAVOS2025103021,
title = {The digital transformation of the film industry: How Artificial Intelligence is changing the seventh art},
journal = {Telecommunications Policy},
volume = {49},
number = {8},
pages = {103021},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.103021},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125001181},
author = {Vasilis Tsiavos and Fotis Kitsios},
keywords = {Digital transformation, Artificial intelligence, Film industry},
abstract = {Although artificial intelligence has played a dominant role in the digital transformation of many industries and has been the focus of multiple academic studies, only a few researchers have explored the impact of AI on the film industry, even after the advances in large language models like ChatGPT and generative AI tools such as Sora. Questions regarding how the use of AI has affected the core functions of the film industry's value chain (Creation, Production, Dissemination and Exhibition) have only been partially or inadequately explored. This paper intends to address this research gap by conducting a systematic literature review of 74 relevant articles based on the Webster & Watson methodology, to be followed by a conceptual analysis of AI-related themes in the film industry. Our findings reveal that artificial intelligence has long played a role in the film industry, and its influence has only grown with recent advancements in AI, having an impact across the film industry's value chain. We also highlight emerging ethical concerns, such as authorship, creative integrity, and labor displacement that accompany AI's expanding role. Whilst our work contributes to the body of research on AI in the film industry, we also identify potential avenues of research that allow room for future exploration.}
}
@article{VIJAYAN2025e68,
title = {The state of generative artificial intelligence (GAI) in radiology and dentistry},
journal = {Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology},
volume = {139},
number = {3},
pages = {e68},
year = {2025},
issn = {2212-4403},
doi = {https://doi.org/10.1016/j.oooo.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S221244032400796X},
author = {Dr. Suvendra Vijayan and Dr. Anitha Potluri},
abstract = {Objective
This oral presentation proposes to explain the current state of generative artificial intelligence (GAI) in health care and education. We will also showcase a research project that used GAI to create radiographic images and another ongoing project exploring the potential of GAI in dental education and research.
Study Design
Research 1—A pilot study was conducted to enhance ultra-low dose cone beam computed tomographic images of dry skulls to diagnostically acceptable standards. The images were trained using a pix2pix deep generative model. Research 2—A pilot study is being conducted exploring the accuracy of case reports generated by ChatGPT. We queried ChatGPT to create hypothetical case reports and modified the queries to get the best possible output.
Results
Research 1—Preliminary results indicated that the synthesized images are comparable with images made with normal exposure. Research 2—Preliminary results indicate that ChatGPT can create a convincing and accurate case report. Limitations in use of citations were observed.
Conclusion
GAI like Open AI's ChatGPT, Google's Bard, and Microsoft's CoPilot have caused a massive shift in public knowledge of AI. GAI will have major impact in health care and education. GAI tools like ChatGPT have huge potential for use and misuse in educational and research spheres. Creating questions and explanation on complex topics can be done on these tools. Websites like MidJourney can create interesting and novel images. Radiographic images can be created using specific algorithms. We intend to demonstrate how to effectively use GAI like ChatGPT, describe ethical concerns and how to address and regulate them in academia, and identify innovative uses for AI and ChatGPT in dental care and education. GAI is a freight train with no breaks and as educators and healthcare practitioners we need to discuss and propose policies and safeguards for responsible use of AI.}
}
@article{GUERRA2023S410,
title = {MSR92 Can Artificial Intelligence (AI) Large Language Models (LLMS) Such as Generative Pre-Trained Transformer (GPT) Be Used to Automate Literature Reviews?},
journal = {Value in Health},
volume = {26},
number = {12, Supplement },
pages = {S410-S411},
year = {2023},
note = {ISPOR Europe 2023 Abstracts},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2023.09.2151},
url = {https://www.sciencedirect.com/science/article/pii/S1098301523052816},
author = {I. Guerra and J. Gallinaro and K. Rtveladze and A. Lambova and E. Asenova}
}
@article{ALCALAY2025105237,
title = {Can artificial intelligence models provide reliable medical counselling to fertility patients?},
journal = {Reproductive BioMedicine Online},
pages = {105237},
year = {2025},
issn = {1472-6483},
doi = {https://doi.org/10.1016/j.rbmo.2025.105237},
url = {https://www.sciencedirect.com/science/article/pii/S1472648325004444},
author = {Idan Alcalay and Ariel Weissman and Hadas Ganer Herman and Avi Tsafrir and Matan Friedman and Eran Weiner and Raoul Orvieto and Nikolaos P Polyzos and Michael H Dahan and Alex Polyakov and Robert Fischer and Sandro C Esteves and Baris Ata and Jason M Franasiak and Yossi Mizrachi},
keywords = {Artificial intelligence, experts, fertility, ART, counseling},
abstract = {Research question
Can generative AI models provide reliable counselling to fertility patients regarding real-world clinical questions.
Design
In this cross-sectional study, 12 clinical questions were developed to reflect common, real-life dilemmas encountered during fertility workup and treatment. Responses to each question were generated by two experienced fertility specialists, ChatGPT, and Gemini. Eight leading internationally recognized fertility experts, blinded to the source of each reply, independently rated all responses on a scale from 1 (strongly disagree) to 10 (strongly agree). Ratings were compared across all four repliers using non-parametric statistical tests.
Results
Replies authored by physicians received significantly higher overall scores than those generated by AI models (p<0.001). Median scores were highest for Doctor A (9.0), followed by Doctor B (8.0), then ChatGPT (7.0), and finally Gemini received the lowest score (4.5). The proportion of high-scoring responses (≥8) was greatest for Doctor A (70.8%), followed by Doctor B (56.3%), then ChatGPT (47.9%), and finally Gemini (35.4%) (p<0.001).
Conclusion
Experienced fertility specialists outperformed generative AI models in providing accurate responses to complex clinical questions. Despite the growing accessibility and sophistication of AI tools, their use for individualized fertility counseling remains limited. Continued refinement and clinical validation of AI tools are essential before they can be considered reliable for patient-specific guidance. At present, AI should be viewed as a complementary resource rather than a substitute for expert clinical judgment.}
}
@article{LI2025150926,
title = {Artificial Intelligence and Machine Learning in Transfusion Practice: An Analytical Assessment},
journal = {Transfusion Medicine Reviews},
volume = {39},
number = {4},
pages = {150926},
year = {2025},
note = {Horizons in Transfusion Medicine: Perspectives after the first quarter of the 21st century},
issn = {0887-7963},
doi = {https://doi.org/10.1016/j.tmrv.2025.150926},
url = {https://www.sciencedirect.com/science/article/pii/S0887796325000513},
author = {Na Li and Ruchika Goel and Sheharyar Raza and Kiarash Riazi and Jie Pan and Huong Quynh Nguyen and Andrew W. Shih and Adam D’Souza and Rounak Dubey and Aaron A.R. Tobian and Donald M. Arnold},
keywords = {Transfusion medicine, Artificial intelligence, Clinical decision support, Supervised learning, Unsupervised learning, Reinforcement learning, Generative artificial intelligence},
abstract = {Transfusion medicine is vital to healthcare and affects clinical outcomes, patient safety, and system resilience while addressing challenges such as blood shortages, donor variability, and rising costs. The integration of artificial intelligence (AI) and machine learning (ML) presents new opportunities to improve clinical decision-making and operational effectiveness in this field. This structured narrative review identified and evaluated studies applying AI and ML in transfusion medicine. A search of PubMed and Scopus for articles published between January 2018 and April 2025 yielded 565 publications. Studies were included if they applied AI or ML techniques, focused on transfusion management or decision support, and were evaluated using electronic health records or expert review. Four exemplar studies were selected, each representing a distinct AI paradigm: supervised, unsupervised, reinforcement, and generative learning. These studies were critically appraised for methodological rigor, clinical relevance, and potential for implementation in practice. The reviewed studies reflected a clear shift from traditional analytic methods toward more advanced computational approaches to improve prediction accuracy, optimize resource allocation, and support clinical decision-making. Three overarching themes emerged: the need to balance model complexity with interpretability and clinical feasibility; the impact of data quality and preprocessing on model performance and fairness; and the barriers to broader applicability and cross-institutional deployment. As technological barriers continue to decline, future challenges will increasingly center on privacy regulations, infrastructure constraints, and aligning model complexity with practical utility. Thoughtful integration of these considerations through scalable, clinical-grade, and transparent solutions will be critical in realizing the full potential of AI and ML in transfusion medicine.}
}
@article{CHIU2024100239,
title = {Erratum to “Future research recommendations for transforming higher education with generative AI” [Computers and Education: Artificial Intelligence 6 (June 2024) 100197]},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100239},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100239},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000420},
author = {Thomas K.F. Chiu}
}
@article{DIEN2023108595,
title = {Generative artificial intelligence in publishing - Reflection and discussion},
journal = {Biological Psychology},
volume = {181},
pages = {108595},
year = {2023},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108595},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123001126},
author = {Joseph Dien and Thomas Ritz},
keywords = {Plagiarism, Large Language Models, ChatGPT, Artificial Intelligence, Academic Misconduct}
}
@article{DENIA2025103266,
title = {AI narratives model: Social perception of artificial intelligence},
journal = {Technovation},
volume = {146},
pages = {103266},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103266},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000987},
author = {Elena Denia},
keywords = {Artificial intelligence, Science communication, Science fiction, Storytelling, Public attitudes, Public engagement, Public understanding, Public narratives},
abstract = {Narratives surrounding Artificial Intelligence (AI) shape its societal reception, technological development, and regulatory framing. This article proposes a theoretical model to interpret these narratives, especially in the context of growing public engagement with generative AI technologies. The model is structured along three key coordinates: apocalypse, assistance and transcendence. Transitions between them are understood through two dominant narrative frames: the Pandora's Box frame (associated with loss of control), and the Social Progress frame (associated with the improvement of human life), each tending toward dystopian and utopian extremes, respectively. Based on this model, two questions are addressed: What types of AI stories predominate in popular culture? And do audiences actually align with them? To answer these, two empirical analyses are conducted. First, a review of the 300 highest-grossing science fiction films in North America reveals a rich variety of narratives across the entire spectrum, rather than clustering around opposing extremes. Second, focus group discussions with categorized audiences of varying levels of familiarity with AI technology show that they align progressively along the narrative spectrum: the general public tends toward apocalyptic framings, the interested public (in science and technology) focuses on assistance narratives, and the engaged public embraces improvement scenarios. This sequential distribution suggests a strong correlation between AI proximity and narrative positioning, with greater engagement associated with more positive —yet nuanced— views of AI. The model opens multiple avenues for future research, including the use of wider data sources, cross-cultural comparisons, longitudinal studies, tracking of narrative shifts, and focused analyses of more complex representations.}
}
@article{JAISWAL202057,
title = {Towards an Artificial Intelligence Aided Design Approach: Application to Anime Faces with Generative Adversarial Networks},
journal = {Procedia Computer Science},
volume = {168},
pages = {57-64},
year = {2020},
note = {“Complex Adaptive Systems”Malvern, PennsylvaniaNovember 13-15, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.257},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920303963},
author = {Devendra Prakash Jaiswal and Srishti Kumar and Youakim Badr},
keywords = {Generative Adversarial Networks, Super-Resolution, Image Generation, Artificial Neural Networks, Engineering Design},
abstract = {Ever since the inception of Machine Learning and Artificial Intelligence, the basic motto for most of research works has been to bring the machines at par with human intelligence. Designing new products and artifacts is one of the many fields where it is very difficult to enable computing machines replicate human creativity and innovativeness. Design processes in engineering fields as well as in arts follow methodical series of steps to create new products. Due to high demands of customized products and services, competitors tend to shorten the time-to-market periods, using advanced Computer-Aided Design programs. These programs play important roles to assist designers in digitizing blueprints and automating repetitive tasks. However, they fail to boost designer creativity by generating or suggesting new ideas or designs based on existing products or their variants. In order to boost creativity in the entertainment industry, we propose in this paper a new approach based on unsupervised learning techniques to create variants of a given artifact or product blueprints. Within the field of designing new cartoon characters, our proposed approach relies on Generative Adversarial Neural Networks [1] to create new anime or cartoon faces on their own without any human intervention. It learns features and characteristics from an image training dataset and combines them to create new features and thus builds a new image which is not present in the training dataset. This applied approach attempts to not only help artists and designers to have a preview of the possible new and unique avatars but also would prevent any copyright infringements.}
}
@article{IBARRAMUNOZ2025100818,
title = {Artificial intelligence in the food and bioprocess industries: Addressing food security challenges},
journal = {Food and Humanity},
volume = {5},
pages = {100818},
year = {2025},
issn = {2949-8244},
doi = {https://doi.org/10.1016/j.foohum.2025.100818},
url = {https://www.sciencedirect.com/science/article/pii/S2949824425003222},
author = {Lizbeth Alejandra Ibarra-Muñoz and Giselle Guadalupe Resendiz-Acosta and Roberto Muñoz-García and Litzy Yazmin Alvarado-Mata and Jazel Doménica Sosa-Martínez and Lourdes Morales-Oyervides and Julio Montañez and Nagamani Balagurusamy},
keywords = {Generative artificial intelligence, Predictive artificial intelligence, Bioprocess optimization, Food safety, Food security},
abstract = {Exponential population growth and increasing global food demand present significant challenges to food security, including risk of food shortages, declining quality and adverse environmental consequences associated with food production. Thus, emerging technologies are being applied to enhance and address challenges within production and safety of food. In this review, the potential of Artificial Intelligence (AI) is being explored as an emerging tool towards food industry and bioprocess concerns such as fermentation parameters, quality control contamination detection, food safety management and bioprocess optimization. By leveraging advanced AI techniques, such as Machine Learning (ML), Deep Learning (DL), Artificial Neural Networks (ANN), and Generative Adversarial Networks (GAN). However ethical implications, such as transparency, liability, AI autonomy and corporation’s awareness, remain critical. Despite its transformative potential, challenges like scalability, data availability, and public perception must be addressed for AI full integration into the food industry. Future perspectives highlight AI’s expanding role in preproduction, processing, and distribution, additionally AI is supported by advancements in synthetic biology and predictive modeling.}
}
@article{DIPAOLA2018158,
title = {Informing artificial intelligence generative techniques using cognitive theories of human creativity},
journal = {Procedia Computer Science},
volume = {145},
pages = {158-168},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S187705091832310X},
author = {Steve DiPaola and Liane Gabora and Graeme McCaig},
keywords = {Deep Learning, Computational Creativity, Cognitive Science},
abstract = {The common view that our creativity is what makes us uniquely human suggests that incorporating research on human creativity into generative deep learning techniques might be a fruitful avenue for making their outputs more compelling and human-like. Using an original synthesis of DeepDream-based convolutional neural networks and cognitive based computational art rendering systems, we show how honing theory, intrinsic motivation, and the notion of a “seed incident” can be implemented computationally, and demonstrate their impact on the resulting generative art. Conversely, we discuss how explorations in deep learning convolutional neural net generative systems can inform our understanding of human creativity. We conclude with ideas for further cross-fertilization between AI based computational creativity and psychology of creativity.}
}
@article{MAGDIN2025107309,
title = {Literature review: Current trends and advances in the use of artificial intelligence for ensuring the safety and efficiency of gas pipeline operations},
journal = {Results in Engineering},
volume = {28},
pages = {107309},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.107309},
url = {https://www.sciencedirect.com/science/article/pii/S259012302503364X},
author = {Martin Magdin},
keywords = {Artificial intelligence, Machine learning, Leak detect, Predictive maintenance, Gas pipeline},
abstract = {The use of artificial intelligence (AI) in gas pipeline monitoring and maintenance represents a significant advancement in the energy industry. This article provides an overview of current trends and AI technologies applied in fault detection, failure prediction, and gas transportation optimization. Key methods include machine learning, deep neural networks, numerical simulations, and digital twins. Research highlights the importance of integrating AI with the physical properties of materials for localizing and assessing corrosion defects. A bibliometric analysis reveals that most studies focus on the application of neural networks, support vector machines, and Bayesian networks in predictive maintenance. Despite significant progress, challenges remain, such as the lack of high-quality datasets, high implementation costs, and regulatory barriers. Future research trends focus on the integration of AI with SCADA systems, improving predictive models, and the broader use of generative neural networks for data synthesis. This review of research trends from 2020 to 2025 underscores the importance of artificial intelligence in the transportation sector and highlights its potential for further development in enhancing the reliability and safety of energy infrastructures.}
}
@article{DIEN2023108621,
title = {Editorial: Generative artificial intelligence as a plagiarism problem},
journal = {Biological Psychology},
volume = {181},
pages = {108621},
year = {2023},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108621},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123001382},
author = {Joseph Dien},
keywords = {Plagiarism, Large language models, ChatGPT, Artificial intelligence, Academic misconduct},
abstract = {There is increasing concern and consternation about generative artificial intelligence (AI) programs and its potential impact on academia. This editorial addresses the potential impact of such programs on scientific publishing as it relates to the journal Biological Psychology. Using chatGPT as an example, it makes the case that a prime concern is its implications for facilitating plagiarism. It briefly outlines what is known about the algorithm of the GPT text model, and also the implications of its chatGPT front end, on being able to establish appropriate credit for ideas in text that it outputs. It is concluded that, at least for Biological Psychology, the expectation is that authors will be transparent about AI usage, will declare when AI is the source of an idea, and will redouble efforts to seek out and cite prior claims to ideas in the published literature when AI is involved.}
}
@article{BIRKHOLZ2025102520,
title = {Navigating artificial intelligence in nursing: An ethical exploration of benefits, risks, and educational shifts},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102520},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102520},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001733},
author = {Lorri Birkholz and Michael Martin and Brenda Barnum and Linda Breslin and Shika Kalevor},
keywords = {Artificial intelligence, Nursing, Nursing ethics, Nursing care, Academic integrity},
abstract = {A significant challenge of generative artificial intelligence (AI) is the gap between technological advancements and policies to guide their ethical use. The integration of AI in all aspects of nursing is poised to revolutionize the delivery of nursing care to patients. As such, nursing practice and educational programs will be required to adapt to these advancing technologies while maintaining the core tenets and ethical values inherent in the profession. Schools, colleges, and universities will be called upon to act to safeguard the value of education and the sanctity of the nursing profession Ultimately, it will be the responsibility of nurses to make sure technological advances, including AI, do not compromise learning or the human interactions and relationships that are essential to providing patient-centered care. The purpose of this article is to explore the ethical implications for the nursing profession of these advances as currently known and understood.}
}
@article{ALI2022,
title = {Combating COVID-19 Using Generative Adversarial Networks and Artificial Intelligence for Medical Images: Scoping Review},
journal = {JMIR Medical Informatics},
volume = {10},
number = {6},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/37365},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422001740},
author = {Hazrat Ali and Zubair Shah},
keywords = {augmentation, artificial intelligence, COVID-19, diagnosis, generative adversarial networks, diagnostic, lung image, imaging, data augmentation, X-ray, CT scan, data scarcity, image data, neural network, clinical informatics},
abstract = {Background
Research on the diagnosis of COVID-19 using lung images is limited by the scarcity of imaging data. Generative adversarial networks (GANs) are popular for synthesis and data augmentation. GANs have been explored for data augmentation to enhance the performance of artificial intelligence (AI) methods for the diagnosis of COVID-19 within lung computed tomography (CT) and X-ray images. However, the role of GANs in overcoming data scarcity for COVID-19 is not well understood.
Objective
This review presents a comprehensive study on the role of GANs in addressing the challenges related to COVID-19 data scarcity and diagnosis. It is the first review that summarizes different GAN methods and lung imaging data sets for COVID-19. It attempts to answer the questions related to applications of GANs, popular GAN architectures, frequently used image modalities, and the availability of source code.
Methods
A search was conducted on 5 databases, namely PubMed, IEEEXplore, Association for Computing Machinery (ACM) Digital Library, Scopus, and Google Scholar. The search was conducted from October 11-13, 2021. The search was conducted using intervention keywords, such as “generative adversarial networks” and “GANs,” and application keywords, such as “COVID-19” and “coronavirus.” The review was performed following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) guidelines for systematic and scoping reviews. Only those studies were included that reported GAN-based methods for analyzing chest X-ray images, chest CT images, and chest ultrasound images. Any studies that used deep learning methods but did not use GANs were excluded. No restrictions were imposed on the country of publication, study design, or outcomes. Only those studies that were in English and were published from 2020 to 2022 were included. No studies before 2020 were included.
Results
This review included 57 full-text studies that reported the use of GANs for different applications in COVID-19 lung imaging data. Most of the studies (n=42, 74%) used GANs for data augmentation to enhance the performance of AI techniques for COVID-19 diagnosis. Other popular applications of GANs were segmentation of lungs and superresolution of lung images. The cycleGAN and the conditional GAN were the most commonly used architectures, used in 9 studies each. In addition, 29 (51%) studies used chest X-ray images, while 21 (37%) studies used CT images for the training of GANs. For the majority of the studies (n=47, 82%), the experiments were conducted and results were reported using publicly available data. A secondary evaluation of the results by radiologists/clinicians was reported by only 2 (4%) studies.
Conclusions
Studies have shown that GANs have great potential to address the data scarcity challenge for lung images in COVID-19. Data synthesized with GANs have been helpful to improve the training of the convolutional neural network (CNN) models trained for the diagnosis of COVID-19. In addition, GANs have also contributed to enhancing the CNNs’ performance through the superresolution of the images and segmentation. This review also identified key limitations of the potential transformation of GAN-based methods in clinical applications.}
}
@article{MILES2024S478,
title = {MSR201 Optimising Performance of Generative Artificial Intelligence (GenAI) in Systematic Literature Review (SLR) Screening Using PICOS Criteria},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S478},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2435},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524052987},
author = {G Miles and L Giles and B.C. Kerr and B Norman and GC Sibbring}
}
@article{ZHAO2025106245,
title = {Artificial intelligence in rock mechanics},
journal = {International Journal of Rock Mechanics and Mining Sciences},
volume = {195},
pages = {106245},
year = {2025},
issn = {1365-1609},
doi = {https://doi.org/10.1016/j.ijrmms.2025.106245},
url = {https://www.sciencedirect.com/science/article/pii/S1365160925002229},
author = {Gao-Feng Zhao and Yuhang Wu},
keywords = {Artificial intelligence, Machine learning, Rock mechanics, Large language model},
abstract = {Artificial Intelligence (AI) has great potential to transform rock mechanics by tackling its inherent complexities, such as anisotropy, nonlinearity, discontinuousness, and multiphase nature. This review explores the evolution of AI, from basic neural networks like the BP model to advanced architectures such as Transformers, and their applications in areas like microstructure reconstruction, prediction of mechanical parameters, and addressing engineering challenges such as rockburst prediction and tunnel deformation. Machine learning techniques, particularly Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs), have been crucial in automating tasks like fracture detection and efficiently generating 3D digital rock models. However, the effectiveness of AI in rock mechanics is limited by data scarcity and the need for high-quality datasets. Hybrid approaches, such as combining physics-informed neural networks (PINNs) with traditional numerical methods, offer promising solutions for solving governing equations. Additionally, Large Language Models (LLMs) are emerging as valuable tools for code generation and decision-making support. Despite these advancements, challenges remain, including issues with reproducibility, model interpretability, and adapting AI models to specific domains. Future progress will hinge on the availability of improved datasets, greater interdisciplinary collaboration, and the integration of spatial intelligence frameworks to bridge the gap between AI's theoretical potential and its practical application in rock engineering.}
}
@article{HERRERATAPIAS20251184,
title = {Legal Hallucinations and the Adoption of Artificial Intelligence in the Judiciary},
journal = {Procedia Computer Science},
volume = {257},
pages = {1184-1189},
year = {2025},
note = {The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.158},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925008956},
author = {Beliña Annery Herrera-Tapias and Diego {Hernández Guzmán}},
keywords = {Artificial Intelligence, AI, Generative Pretrained Transformers, GPTs, Large Language Models, LLMs, Judiciary, Due Process},
abstract = {This article analyses the use of artificial intelligence in the judiciary, with a focus on Judgment T-343/24 of the Constitutional Court of Colombia. The judgment validates the use of artificial intelligence tools in judicial decision-making, provided they serve as supportive rather than substitutive instruments for judges. This paper highlights the potential of artificial intelligence in improving judicial efficiency and accuracy while also technically addressing the challenges posed by AI-generated "legal hallucinations," where large language models produce credible but incorrect outputs. Through qualitative legal analysis, the study explores the implications of integrating artificial intelligence in the judiciary in addressing those challenges while emphasizing the preservation of the right to a due process.}
}
@article{ENSLIN2025265,
title = {Past, Present, and Future: A History Lesson in Artificial Intelligence},
journal = {Gastrointestinal Endoscopy Clinics of North America},
volume = {35},
number = {2},
pages = {265-278},
year = {2025},
note = {Artificial Intelligence in Endoscopy},
issn = {1052-5157},
doi = {https://doi.org/10.1016/j.giec.2024.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1052515724000850},
author = {Sarah Enslin and Vivek Kaul},
keywords = {Artificial intelligence, Machine learning, Deep learning, Computer-aided detection, Computer-aided diagnosis, Generative artificial intelligence}
}
@article{ABBARA2025105131,
title = {Artificial intelligence and infectious diseases: Scope and perspectives},
journal = {Infectious Diseases Now},
volume = {55},
number = {7},
pages = {105131},
year = {2025},
issn = {2666-9919},
doi = {https://doi.org/10.1016/j.idnow.2025.105131},
url = {https://www.sciencedirect.com/science/article/pii/S2666991925001101},
author = {S. Abbara and Y. Crabol and J. Goupil {de Bouillé} and A. Dinh and D. Morquin},
keywords = {Infectious diseases, Artificial intelligence, Generative artificial intelligence, Machine learning, Clinical decision support},
abstract = {Artificial intelligence (AI) is set to permeate every facet of infectious disease practice—from prevention and public health surveillance to epidemic management and bedside care. Routine care data (laboratory results, medication orders, progress notes) and research-generated datasets now fuel state-of-the-art machine-learning (ML) pipelines that sharpen diagnosis, prognosis, antimicrobial stewardship, and, by combining both sources, accelerate drug discovery. In diagnostics, deep networks that now flag pneumonia or tuberculosis on chest images are increasingly able to identify—and localize—virtually more infectious processes throughout the body, while simultaneously predicting pathogen identity and antimicrobial resistance from routine microbiology. Prognostic models trained on Electronic Health Records surpass traditional scores in anticipating clinical deterioration or postoperative sepsis, enabling earlier targeted interventions. Predictive analytics can also personalize antimicrobial dosing by fusing real-time drug-monitoring data. Large language models (LLMs) build upon these advances by transforming unstructured clinical narratives into structured phenotypes suitable for predictive modeling, automatically summarizing patient encounters, generating synthetic cohorts for rare conditions, and providing real-time conversational decision support at the patient’s bedside. Despite rapid progress, real-world deployment faces hurdles: high computational and licensing costs, vendor-specific implementation constraints, limited cross-site model transferability, and fragmented governance of safety, bias, and cybersecurity risks. Rigorous, lifecycle-based evaluation frameworks—covering external validation, cost-effectiveness analysis, and post-deployment monitoring—are required to ensure safe, equitable, and sustainable AI adoption. This review synthesizes current applications, evidential strengths, and unresolved challenges, and proposes a translational roadmap aligning technical innovation with clinical and regulatory realities.}
}
@article{HARKEY2025100687,
title = {Artificial Intelligence in Osteoarthritis Research: Summary of the 2025 OARSI Pre-Congress Workshop},
journal = {Osteoarthritis and Cartilage Open},
pages = {100687},
year = {2025},
issn = {2665-9131},
doi = {https://doi.org/10.1016/j.ocarto.2025.100687},
url = {https://www.sciencedirect.com/science/article/pii/S2665913125001232},
author = {Matthew S. Harkey and Kerry E. Costello and Bella Mehta and Chunyi Wen and Anne-Marie Malfait and Henning Madry and Brooke Patterson},
keywords = {Generative AI, Biomechanics, Imaging biomarkers, Large language models, Ethics},
abstract = {ABSTRACT
Objective
Artificial intelligence (AI) is transforming musculoskeletal research, offering new approaches to diagnosis, prognosis, and patient management in osteoarthritis (OA). However, implementation and ethical challenges persist. This manuscript summarizes insights from the OARSI 2025 Pre-Congress Workshop on Artificial Intelligence in Osteoarthritis Research, highlighting opportunities and challenges in applying AI across biomechanics, imaging, and clinical research domains.
Design
The workshop, organized by the OARSI Early Career Investigator Committee and co-chaired by Drs. Matthew Harkey and Brooke Patterson, convened experts to discuss the use of AI in real-world biomechanics data collection, radiomics for imaging-based biomarkers, and large language models (LLMs) for clinical and research applications. Emphasis was placed on the need for interdisciplinary collaboration and ethical oversight.
Results
In biomechanics, AI-driven markerless motion capture and wearable sensors enable scalable, ecologically valid data collection, though issues such as class imbalance, data privacy, and model interpretability remain. In imaging, radiomics and deep learning models show promise for early OA detection and progression prediction but face challenges in domain adaptation and external validation. In clinical research, LLMs can streamline documentation and thematic analysis but must address concerns around bias, data security, and transparency. Across domains, transparency, reproducibility, and ethical use of AI were emphasized as critical for maintaining scientific rigor.
Conclusions
Cross-disciplinary collaboration and AI literacy are essential to responsibly advance AI integration in OA research. The workshop’s collective insights call for ethical, patient-centered approaches that leverage AI’s strengths while preserving research integrity and trust.}
}
@article{SEZGIN2025,
title = {Era of Generalist Conversational Artificial Intelligence to Support Public Health Communications},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/69007},
url = {https://www.sciencedirect.com/science/article/pii/S143888712500086X},
author = {Emre Sezgin and Ahmet Baki Kocaballi},
keywords = {messaging apps, public health communication, language models, artificial intelligence, AI, generative AI, conversational AI},
abstract = {The integration of artificial intelligence (AI) into health communication systems has introduced a transformative approach to public health management, particularly during public health emergencies, capable of reaching billions through familiar digital channels. This paper explores the utility and implications of generalist conversational artificial intelligence (CAI) advanced AI systems trained on extensive datasets to handle a wide range of conversational tasks across various domains with human-like responsiveness. The specific focus is on the application of generalist CAI within messaging services, emphasizing its potential to enhance public health communication. We highlight the evolution and current applications of AI-driven messaging services, including their ability to provide personalized, scalable, and accessible health interventions. Specifically, we discuss the integration of large language models and generative AI in mainstream messaging platforms, which potentially outperform traditional information retrieval systems in public health contexts. We report a critical examination of the advantages of generalist CAI in delivering health information, with a case of its operationalization during the COVID-19 pandemic and propose the strategic deployment of these technologies in collaboration with public health agencies. In addition, we address significant challenges and ethical considerations, such as AI biases, misinformation, privacy concerns, and the required regulatory oversight. We envision a future with leverages generalist CAI in messaging apps, proposing a multiagent approach to enhance the reliability and specificity of health communications. We hope this commentary initiates the necessary conversations and research toward building evaluation approaches, adaptive strategies, and robust legal and technical frameworks to fully realize the benefits of AI-enhanced communications in public health, aiming to ensure equitable and effective health outcomes across diverse populations.}
}
@article{RUIZ2025104293,
title = {Artificial intelligence-created personal statements compared with applicant-written personal statements: a survey of obstetric anesthesia fellowship program directors in the United States},
journal = {International Journal of Obstetric Anesthesia},
volume = {61},
pages = {104293},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2024.104293},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X24003054},
author = {A.M. Ruiz and M.B. Kraus and K.W. Arendt and D.R. Schroeder and E.E. Sharpe},
keywords = {Artificial intelligence, Generative AI, Medical education, Obstetric anesthesia, Personal statements, Fellowship},
abstract = {Background
A personal statement is a common requirement in medical residency and fellowship applications. Generative artificial intelligence may be used to create a personal statement for these applications.
Methods
Two personal statements were created using OpenAI’s Chat Generative Pre-trained Transformer (ChatGPT) and two applicant-written statements were collected. A survey was sent to obstetric anesthesia fellowship program directors in the United States to assess the perceived readability, authenticity, and originality of the four personal statements. In addition, the survey assessed perceptions of applicants who use artificial intelligence to write a personal statement, including their integrity, work ethic, reliability, intelligence, and English proficiency.
Results
Surveyed fellowship directors could not accurately discern whether statements were applicant-written or artificial intelligence-generated. The artificial intelligence-generated personal statements were rated as more readable and original than the applicant-written statements. Most program directors were moderately or extremely concerned about the applicant’s integrity, work ethic, and reliability if they suspected the applicant utilized ChatGPT.
Conclusions
Program directors could not accurately discern if the statements were written by a person or artificial intelligence and would have concerns about an applicant suspected of using artificial intelligence. Medical training programs may benefit from outlining their expectations regarding applicants’ use of artificial intelligence.}
}
@article{WEN2025,
title = {EdgeAIGC: Model caching and resource allocation for Edge Artificial Intelligence Generated Content},
journal = {Digital Communications and Networks},
year = {2025},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2025.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352864825001142},
author = {Wu Wen and Yibin Huang and Xinxin Zhao and Peiying Zhang and Kai Liu and Guowei Shi},
keywords = {Generative AI, Edge Model Caching, Resource Allocation, Edge Intelligence},
abstract = {With the rapid development of Generative Artificial Intelligence technology, the traditional cloud-based centralized model training and inference face significant limitations due to high transmission latency and costs, which restrict user-side in-situ Artificial Intelligence Generated Content (AIGC) service requests. To this end, we propose the Edge Artificial Intelligence Generated Content (EdgeAIGC) framework, which can effectively solve the problems brought by cloud computing by implementing in-situ processing of services close to the data source through edge computing. However, AIGC models usually have a large parameter scale and complex computing requirements, which poses a huge challenge to the storage and computing resources of edge devices. This paper focuses on the edge intelligence model caching and resource allocation problems in the EdgeAIGC framework, aiming to improve the cache hit rate and resource utilization of edge devices for models by optimizing the model caching strategy and resource allocation scheme, and realize in-situ AIGC service processing. With the optimization objectives of minimizing service request response time and execution cost in resource-constrained environments, we employ the Twin Delayed Deep Deterministic Policy Gradient algorithm for optimization. Experimental results show that, compared with other methods, our model caching and resource allocation strategies can effectively improve the cache hit rate by at least 41.06% and reduce the response cost.}
}
@article{LIM2025,
title = {The art of medical synthesis: Where Chinese medical wisdom intersects with artificial intelligence},
journal = {Journal of Traditional Chinese Medical Sciences},
year = {2025},
issn = {2095-7548},
doi = {https://doi.org/10.1016/j.jtcms.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S209575482500078X},
author = {Enoch Chi Ngai Lim and Nga Chong Lisa Cheng and Chi Eung Danforn Lim},
keywords = {Artificial intelligence, Chinese medicine, Western medicine, Regulation, Ethics},
abstract = {Generative artificial intelligence (AI), specifically large language models, such as DeepSeek, has accelerated the digital transformation of healthcare systems in both developing and developed countries. The use of AI in diagnostics, image processing and interpretation, treatment personalization, clinical documentation, and drug discovery is an example of the implementation of AI in Western medicine. The need for evidence-based studies and a standardized approach to scientific medicine aligns well with these applications. AI can leave a lasting impact on the Chinese medicine (CM) landscape by increasing expectations and presenting new challenges. The analogy between the CM-specific diagnostic methods and syndrome differentiation, which is holistic, pattern-oriented, patient-centered, and clinical data analysis, is significant at multiple levels. These qualities pose challenges for AI usage in CM, which heavily relies on structured data and pattern recognition. Despite these adversities, AI can still be used in CM through data standardization, prediction formulation, and treatment planning, provided that the integration of this tool considers the primary principles of CM and adheres to ethical and regulatory considerations. This review examines the dichotomous approach to health and medicine in the contexts of AI and CM, highlighting the evolving potential, inherent limitations, and ethical and regulatory issues associated with the application of AI to CM. It provides a foundation for developing technologically progressive yet culturally and philosophically sensitive strategies that are in harmony with traditional clinical values.}
}
@article{WENGREEN2024A70,
title = {Dietetic Students' Knowledge and Perceptions of Their Use of Generative Artificial Intelligence Now and in the Future},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {124},
number = {10, Supplement },
pages = {A70},
year = {2024},
note = {2024 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2024.07.064},
url = {https://www.sciencedirect.com/science/article/pii/S2212267224006245},
author = {H. Wengreen and S. Bevan and K. Kraus}
}
@article{WANG2025100606,
title = {Opportunities and perspectives of artificial intelligence in electrocatalysts design for water electrolysis},
journal = {Energy and AI},
volume = {22},
pages = {100606},
year = {2025},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2025.100606},
url = {https://www.sciencedirect.com/science/article/pii/S2666546825001387},
author = {Qing Wang and Lizhen Wu and Qiang Zheng and Liang An},
keywords = {Artificial intelligence, Electrocatalysts, Water electrolysis, Multiscale design, Automated experimentation},
abstract = {As a key pathway for green hydrogen production, water electrolysis is expected to play a central role in the future energy landscape. However, its large-scale deployment is hindered by challenges related to cost, performance, and durability. The emergence of artificial intelligence (AI) has transformed this field by offering powerful and efficient tools for the design and optimization of electrocatalysts. This review outlines an AI-driven multiscale design framework, highlighting its role at the microscopic scale for identifying atomic-level active sites and key descriptors, at the mesoscopic scale for structural and morphological characterization, and at the macroscopic scale for multi-objective optimization and intelligent control. This multiscale framework demonstrates the potential of AI to accelerate the development of next-generation electrocatalysts. In addition, the integration of generative AI and automated experimental techniques is highlighted as promising strategies to further enhance electrocatalyst discovery and promote the practical implementation of water electrolysis technologies.}
}
@article{SENGUL2025104516,
title = {The effect of artificial intelligence literacy on self-directed learning skills: The mediating role of attitude towards artificial intelligence: A study on nursing and midwifery students},
journal = {Nurse Education in Practice},
volume = {88},
pages = {104516},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104516},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325002732},
author = {Tuba SENGUL and Seda SARIKOSE and Betül UNCU and Nurten KAYA},
keywords = {Artificial intelligence, Artificial intelligence literacy, Self-directed learning, Nursing education, Midwifery education, Attitude to artificial intelligence},
abstract = {Aim
This study investigates the impact of generative artificial intelligence literacy (GAIL) on self-directed learning skills (SDL) among nursing and midwifery students. Additionally, it examines whether general attitudes toward artificial intelligence (GAAI) mediate this relationship.
Background
Artificial intelligence (AI) has the potential to support the development of clinical decision-making and problem-solving skills in nursing and midwifery education, particularly by enhancing students’ self-directed learning abilities.
Methods
A cross-sectional, descriptive and correlational study design was used. The study was conducted in three universities in Türkiye between January and February 2025. 656 nursing and midwifery students participated, selected through cluster sampling. Data were collected using the GAIL, GAAI and SDL scales. The survey form included descriptive questions regarding participants' socio-demographic characteristics and AI usage patterns. Structural equation modeling was conducted to analyze direct and indirect relationships among variables.
Results
A significant positive effect of GAILS on GAAIS was found (β = 0.75, p < .01). GAILS also had a direct and significant effect on SDLS (β = 0.60, p < .01). However, GAAIS did not mediate the relationship between GAILS and SDLS (β = 0.02, p > .05).
Conclusions
AI literacy significantly enhances SDL in nursing and midwifery students. However, positive attitudes toward AI do not independently foster SDL, highlighting the need for structured AI education in healthcare curricula. Future studies should explore long-term AI literacy interventions to assess their impact on academic outcomes and their potential contributions to clinical reasoning and decision-making skills.}
}
@article{LEWALLEN2025,
title = {Impact of artificial intelligence in vision science: A systematic review of progress, emerging trends, data domain quantification, and critical gaps},
journal = {Survey of Ophthalmology},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2025.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0039625725001717},
author = {Colby F. Lewallen and Davide Ortolan and Dominik Reichert and Ruchi Sharma and Kapil Bharti},
keywords = {artificial intelligence, vision science, ophthalmic imaging, multimodal AI, generative AI, Diabetic Retinopathy, Age-related Macular Degeneration},
abstract = {The prominence of artificial intelligence (AI) is growing exponentially, yet its implementation across research domains is uneven. To quantify AI trends in vision science, we evaluated over 100,000 PubMed article metadata spanning 35 years. Using Medical Subject Headings (MeSH) terms, we analyzed trends across four prominent ocular diseases: age-related macular degeneration, diabetic retinopathy, glaucoma, and cataract. Most articles utilized research techniques from at least one of the following domains: biological models, molecular profiling, image-based analysis, and clinical outcomes. Our quantification reveals that AI prominence is disproportionally concentrated in the image-based analysis domain, and, additionally, among 4 diseases evaluated, AI prevalence in cataract research is lagging. Contributing factors towards these disparities include insufficient data standardization, complex data structures, limited data availability, unresolved ethical concerns, and not gaining meaningful improvements over human-based interpretations. By mapping where AI thrives and where it lags, we offer a quantitative reference for funding agencies, clinicians, and vision scientists. Connecting various research domains with multimodal and generative AI could improve diagnostic utility; enabling earlier diagnosis, personalized therapy, reduced healthcare costs, and accelerate innovation. Future work should move AI in vision science beyond image-centric pattern recognition toward integrative, mechanistic analyses that explain – rather than merely detect – disease.}
}
@article{STEVENS2025100831,
title = {A Comparison of Artificial Intelligence Platforms in the Utility of Answering Frequently Asked Questions About Carpal Tunnel Syndrome: A Cross-Sectional Study},
journal = {Journal of Hand Surgery Global Online},
volume = {7},
number = {6},
pages = {100831},
year = {2025},
issn = {2589-5141},
doi = {https://doi.org/10.1016/j.jhsg.2025.100831},
url = {https://www.sciencedirect.com/science/article/pii/S2589514125001513},
author = {Calista Stevens and Mehreen Pasha and Dashun Liu and Andrew Block and Anthony Parrino and Craig Rodner},
keywords = {Carpal tunnel syndrome, Generative artificial intelligence, Hand, Orthopedic surgery},
abstract = {Purpose
The rise of artificial intelligence (AI) in health care comes with increasing concerns about the use and integrity of the information it generates. Chat Generative Pre-Trained Transformer (ChatGPT) 3.5, Google Gemini, and Bing Copilot are free AI chatbot platforms that may be used for answering medical questions and disseminating medical information. Given that carpal tunnel syndrome accounts for 90% of all neuropathies, it is important to understand the accuracy of the information patients may be receiving. The purpose of this study is to determine the use and accuracy of responses generated by ChatGPT, Google Gemini, and Bing Copilot in answering frequently asked questions about carpal tunnel syndrome.
Methods
Two independent authors scored responses using the DISCERN tool. DISCERN consists of 15 questions assessing health information on a five-point scale, with total scores ranging from 15 to 75 points. Then, a two-factor analysis of variance was conducted, with scorer and chatbot type as the factors.
Results
One-way analysis of variance revealed no significant difference in DISCERN scores among the three chatbots. The chatbots each scored in the “fair” range, with means of 45 for ChatGPT, 48 for Bing Copilot, and 46 for Google Gemini. The average Journal of the American Medical Association score for ChatGPT and Google Gemini surpassed that of Bing Copilot, with averages of 2.3, 2.3, and 1.8, respectively.
Conclusions
ChatGPT, Google Gemini, and Bing Copilot platforms generated relatively reliable answers for potential patient questions about carpal tunnel syndrome. However, users should continue to be aware of the shortcomings of the information provided, given the lack of citations, potential for misconstrued information, and perpetuated biases that inherently come with using such platforms. Future studies should explore the response quality for less common orthopedic pathologies and assess patient perceptions of response readability to determine the value of AI as a patient resource across the medical field.
Type of study/level of evidence
Cross-sectional study V}
}
@article{SHASTRI20247668,
title = {Use of Generative Artificial Intelligence for Development of Plain Language Summaries: A Blinded Assessment of Education Preferences of the Sickle Cell Disease Community},
journal = {Blood},
volume = {144},
pages = {7668},
year = {2024},
note = {66th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2024-206965},
url = {https://www.sciencedirect.com/science/article/pii/S0006497124104934},
author = {Oliver Shastri and Orlando Agrippa and Valerie Moss and Eleanor Millard and Lianne More and Eleanor Rose Brown and Seraj Sharif and Chris Finch},
abstract = {Introduction: Sickle cell disease (SCD) is an inherited condition that reduces life expectancy and has a profound impact on quality of life. Assessment of social media conversations in the SCD community in the UK highlighted health inequities, including issues with access to emergency care, low levels of healthcare professional empathy, and racial bias/stigmatization (Shastri O, et al. ASH 2023; abstract 1057). This emphasizes the urgent unmet need for additional education. Use of generative artificial intelligence (GenAI) to facilitate the development of medical content, including plain language summaries (PLS) of research may increase efficiency, reduce resource cost and ultimately improve accessibility to educational information across a range of audiences. We assessed the ability of GenAI to develop a PLS of our social media listening study. Methods: We developed 3 written versions of a PLS of this study: human-written by a medical writer, AI-generated, and hybrid AI-human, where a person living with SCD edited the AI version for readability. Each was ~300-400 words and with a target reading age of 12 years. The AI PLS was developed using Pfizer's GenAI tool, MAIA (Medical AI assistant). A video version of each written PLS was developed using the AI tool, Synthesia. People with SCD and their carers (≥18 years of age) were recruited via telephone to complete an online survey to assess the understandability of the 3 written PLS and preference for written versus video PLS. Participants were presented with 1 of the 3 written PLS at random and asked to assess how easily they understood it on a 5-point scale (1=very difficult; 2=difficult; 3=neither difficult nor easy; 4=easy; 5=very easy). They were then asked 3 multiple-choice questions to gauge their understanding. Participants then rated the other 2 written PLS and were asked to rank all 3 in order of most easily understood. Finally, participants watched the video version of their top-rated written PLS and stated which format they preferred. Participants were blinded to PLS source. The Flesch-Kincaid calculator (https://goodcalculators.com/flesch-kincaid-calculator/) was used to provide an objective measure of readability for each PLS. Results: Of 93 participants, there were 88 living with SCD and 5 caring for someone with SCD. The AI versions of the PLS achieved similar scores for understandability to the human-written version: mean ± standard deviation understandability scores were 4.1 ± 0.9 (human), 4.0 ± 0.9 (AI), and 3.9 ± 0.8 (AI-hybrid). Overall, 81% of participants identified the human PLS as easy or very easy to read, similar to 76% for the AI PLS, and 74% for the AI-hybrid PLS. Overall, 41 participants (44%) ranked the human PLS in first place for understandability, 31 (33%) the AI PLS, and 21 (23%) the AI-hybrid PLS. For the multiple-choice questions, results were similar regardless of which PLS participants saw first, with over 85% correctly identifying the main findings of the study and the conclusions of the author; however, 63% incorrectly thought the data on which the PLS was based were obtained from interviewing people affected by SCD rather than social media listening. Fifty-four participants (58%) preferred the video PLS over the written PLS, 27 participants (29%) preferred the written PLS and 12 (13%) had no preference. Flesch-Kincaid scores for the three PLS were as follows: human (reading ease score, 62; reading level, 8th to 9th grade); AI (reading ease score, 58; reading level, 10th to 12th grade); AI-hybrid (reading ease score, 63; reading level, 8th to 9th grade). Conclusion: There is a clear need for additional resources and education in SCD, which may be supported by the development of PLS. The limited studies that have assessed the capabilities of AI to generate PLS to date have focussed on clinical research. We have now expanded this to assess use of AI to develop PLS from a social media listening study that evaluated real-world experiences of the UK SCD community. Our study suggests that GenAI can generate PLS that are as informative as conventional, human-written PLS, and achieve similar readability scores as judged by people living with SCD in the UK (mean 4.1 for human-written, 4.0 for AI and 3.9 for AI-hybrid). We propose that GenAI may offer an alternative to conventional human-written PLS, providing a time- and resource-efficient solution to increase accessibility to educational resources.}
}
@article{BAKER2024101054,
title = {Student Perceptions of Generative Artificial Intelligence in Didactic Patient Presentations},
journal = {American Journal of Pharmaceutical Education},
volume = {88},
number = {9},
pages = {101054},
year = {2024},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2024.101054},
url = {https://www.sciencedirect.com/science/article/pii/S0002945924107735},
author = {Carrie N. Baker and Jordan Powe and Sophia Jones and Emily Ghassemi and Riley Bowers}
}
@article{KHENE2024160,
title = {Development of a Personalized Chat Model Based on the European Association of Urology Oncology Guidelines: Harnessing the Power of Generative Artificial Intelligence in Clinical Practice},
journal = {European Urology Oncology},
volume = {7},
number = {1},
pages = {160-162},
year = {2024},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2023.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S2588931123001396},
author = {Zine-Eddine Khene and Pierre Bigot and Romain Mathieu and Morgan Rouprêt and Karim Bensalah}
}
@article{AULENBACHER2025,
title = {Development and Reliability Assessment of an Artificial Intelligence-Driven Urticaria Support Chatbot, AIDUS},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
year = {2025},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2025.07.047},
url = {https://www.sciencedirect.com/science/article/pii/S2213219825007585},
author = {Felix Aulenbacher and Annika Gutsche and Benedict Bihlmaier and Hanna Bonnekoh and Ivan Cherrez-Ojeda and Joachim W. Fluhr and Pavel Kolkhir and Markus Magerl and Martin Metz and Polina Pyatilova and Frank Siebenhaar and Torsten Zuberbier and Sophia Neisinger},
keywords = {Artificial intelligence, chronic urticaria, ChatGPT},
abstract = {ABSTRACT
Background
Chronic urticaria (CU) severely impairs patients’ quality of life. Correctly diagnosing and treating CU can take years, meaning patients seek answers from the Internet to manage their condition.
Objective
We aimed to build a chatbot, AIDUS (Artificial Intelligence-Driven Urticaria Support), for patients with CU and treating physicians and evaluate its reliability in providing high-quality CU-specific information compared with Chat Generative Pre-Trained Transformer (ChatGPT)-3.5 and ChatGPT-4o.
Methods
AIDUS was developed by an expert committee of urticaria and artificial intelligence specialists using JavaScript and OpenAI’s ChatGPT large language model. PubMed was systematically reviewed to ensure AIDUS contained high-quality information. The chatbot was populated exclusively with selected peer-reviewed CU publications authored by the Charité University, Berlin research group, published after 2014. Two hundred and fifty-four publications were integrated using ChatGPT-3.5 as the underlying algorithm. A set of 100 validated questions was developed based on current CU knowledge to evaluate the performance of AIDUS. The program was run on the same questions several times and compared for consistency. Performance was tested with different chunk- and overlap-size settings to optimize AIDUS’s efficiency and accuracy.
Results
AIDUS outperformed general ChatGPT models in terms of accuracy, consistency, and stability in answering CU-specific questions. AIDUS demonstrated higher average accuracy (94.6%) across multiple test runs compared with ChatGPT-3.5 (42.6%) and ChatGPT-4o (85.7%).
Conclusion
AIDUS provides reliable, high-quality information about CU, addressing patients’ and physicians’ needs for accurate, relevant answers based on peer-reviewed medical literature. AIDUS remains a means of assistance and does not replace consultation with a physician.}
}
@article{AGARWAL20241121,
title = {Ethics of using generative pretrained transformer and artificial intelligence systems for patient prior authorizations},
journal = {Journal of the American Academy of Dermatology},
volume = {90},
number = {5},
pages = {1121-1122},
year = {2024},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2023.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0190962223007284},
author = {Aneesh Agarwal and Benjamin Stoff},
keywords = {AI, artificial intelligence, dermatology, ethics, generative pretrained transformer, GPT, prior authorization}
}
@article{SOHN202061,
title = {Artificial intelligence in the fashion industry: consumer responses to generative adversarial network (GAN) technology},
journal = {International Journal of Retail & Distribution Management},
volume = {49},
number = {1},
pages = {61-80},
year = {2020},
issn = {0959-0552},
doi = {https://doi.org/10.1108/IJRDM-03-2020-0091},
url = {https://www.sciencedirect.com/science/article/pii/S0959055220000820},
author = {Kwonsang Sohn and Christine Eunyoung Sung and Gukwon Koo and Ohbyung Kwon},
keywords = {Artificial intelligence (AI), Generative adversarial networks (GANs), Consumption value theory, AI aversion, Fashion consumer behaviour},
abstract = {Purpose
This study examines consumers' evaluations of product consumption values, purchase intentions and willingness to pay for fashion products designed using generative adversarial network (GAN), an artificial intelligence technology. This research investigates differences between consumers' evaluations of a GAN-generated product and a non-GAN-generated product and tests whether disclosing the use of GAN technology affects consumers' evaluations.
Design/methodology/approach
Sample products were developed as experimental stimuli using cycleGAN. Data were collected from 163 members of Generation Y. Participants were assigned to one of the three experimental conditions (i.e. non-GAN-generated images, GAN-generated images with disclosure and GAN-generated images without disclosure). Regression analysis and ANOVA were used to test the hypotheses.
Findings
Functional, social and epistemic consumption values positively affect willingness to pay in the GAN-generated products. Relative to non-GAN-generated products, willingness to pay is significantly higher for GAN-generated products. Moreover, evaluations of functional value, emotional value and willingness to pay are highest when GAN technology is used, but not disclosed.
Originality/value
This study evaluates the utility of GANs from consumers' perspective based on the perceived value of GAN-generated product designs. Findings have practical implications for firms that are considering using GANs to develop products for the retail fashion market.}
}
@article{MATSUBARA2025172,
title = {Research misconduct: Use of generative artificial intelligence in writing may lower the threshold},
journal = {European Journal of Obstetrics & Gynecology and Reproductive Biology},
volume = {304},
pages = {172-173},
year = {2025},
issn = {0301-2115},
doi = {https://doi.org/10.1016/j.ejogrb.2024.11.038},
url = {https://www.sciencedirect.com/science/article/pii/S030121152400650X},
author = {Shigeki Matsubara and Daisuke Matsubara}
}
@article{MUNIR2025102370,
title = {Taking the plunge together: A student-led faculty learning seminar series on artificial intelligence},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {8},
pages = {102370},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102370},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725000917},
author = {Faria Munir and Elma Abdulbaki and Zeba Saiyad and Heather Ipema},
keywords = {Artificial intelligence, Drug information, Higher education, Pharmacy, Faculty, Pharmacy students, Learning series},
abstract = {Objective
This pilot study explored the effectiveness of a student-led faculty development series by evaluating two key outcomes: the capacity of students to deliver meaningful professional development sessions to faculty and the impact of these sessions on faculty perceptions of generative artificial intelligence (AI).
Methods
In a flipped classroom model, two pharmacy students and 12 faculty members engaged in a semester-long learning series on AI. Each week, students presented on a selected topic followed by discussions that facilitated self-directed learning, including decision-making and project management. Faculty perceptions of AI were evaluated before and after the series using an anonymous survey tool (Technology Acceptance Model Edited to Assess ChatGPT Adoption, TAME-ChatGPT). Respondents created a self-chosen code to link their responses. Additionally, students completed a questionnaire to gauge their reflective thinking after the series.
Results
Faculty participation averaged 7 members per session. Twelve faculty completed the pre-survey, while 8 faculty completed the post-survey. Among those who had used ChatGPT (n = 4 pre [33 %], n = 2 post [25 %]), scores for usefulness increased, while concerns about risks decreased. In contrast, faculty who had not used ChatGPT (n = 8 pre [67 %], n = 6 post [75 %]) reported unchanged or improved scores for ease of use and reduced anxiety. Both students responded positively to the reflective thinking questionnaire.
Conclusion
This pilot study demonstrated that a student-led faculty learning series effectively fostered mutual collaborative learning, benefiting both faculty and students. Pharmacy students, often an underutilized resource, can play a valuable role in faculty development. Colleges of pharmacy may enhance faculty engagement by integrating student-led initiatives into their programs.}
}
@article{MACKENZIE20239,
title = {Surprising Advances in Generative Artificial Intelligence Prompt Amazement—and Worries},
journal = {Engineering},
volume = {25},
pages = {9-11},
year = {2023},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2023.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095809923001613},
author = {Dana Mackenzie}
}
@article{WEBBER2025,
title = {The Future of Artificial Intelligence in Medical Education and Continuing Medical Education},
journal = {Primary Care: Clinics in Office Practice},
year = {2025},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000715},
author = {Chase J. Webber and Pat Whitworth and Shane P. Stenner},
keywords = {Artificial intelligence, Medical education, Continuing medical education, Generative AI, Large language models, Competency-based education, AI literacy}
}
@article{HEIKKILA202418,
title = {Human intelligence versus artificial intelligence in classifying economics research articles: exploratory evidence},
journal = {Journal of Documentation},
volume = {81},
number = {7},
pages = {18-30},
year = {2024},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-05-2024-0104},
url = {https://www.sciencedirect.com/science/article/pii/S0022041825000050},
author = {Jussi T.S. Heikkilä},
keywords = {JEL codes, Artificial intelligence, Large language models, Search costs, Bounded rationality},
abstract = {Purpose
We compare human intelligence to artificial intelligence (AI) in the choice of appropriate Journal of Economic Literature (JEL) codes for research papers in economics.
Design/methodology/approach
We compare the JEL code choices related to articles published in the recent issues of the Journal of Economic Literature and the American Economic Review and compare these to the original JEL code choices of the authors in earlier working paper versions and JEL codes recommended by various generative AI systems (OpenAI’s ChatGPT, Microsoft’s Copilot, Google’s Gemini) based on the abstracts of the articles.
Findings
There are significant discrepancies and often limited overlap between authors’ choices of JEL codes, editors’ choices as well as the choices by contemporary widely used AI systems. However, the observations suggest that generative AI can augment human intelligence in the micro-task of choosing the JEL codes and, thus, save researchers time.
Research limitations/implications
Rapid development of AI systems makes the findings quickly obsolete.
Practical implications
AI systems may economize on classification costs and (semi-)automate the choice of JEL codes by recommending the most appropriate ones. Future studies may apply the presented approach to analyze whether the JEL code choices between authors, editors and AI systems converge and become more consistent as humans increasingly interact with AI systems.
Originality/value
We assume that the choice of JEL codes is a micro-task in which boundedly rational decision-makers rather satisfice than optimize. This exploratory experiment is among the first to compare human intelligence and generative AI in choosing and justifying the choice of optimal JEL codes.}
}
@article{MAY2024155,
title = {Would Uro_Chat, a Newly Developed Generative Artificial Intelligence Large Language Model, Have Successfully Passed the In-Service Assessment Questions of the European Board of Urology in 2022?},
journal = {European Urology Oncology},
volume = {7},
number = {1},
pages = {155-156},
year = {2024},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2023.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2588931123001785},
author = {Matthias May and Katharina Körner-Riffard and Martin Marszalek and Klaus Eredics}
}
@article{ECKARDT20232268,
title = {Mimicking Clinical Trials with Synthetic Acute Myeloid Leukemia Patients Using Generative Artificial Intelligence},
journal = {Blood},
volume = {142},
pages = {2268},
year = {2023},
note = {65th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2023-179817},
url = {https://www.sciencedirect.com/science/article/pii/S0006497123088705},
author = {Jan-Niklas Eckardt and Waldemar Hahn and Christoph Röllig and Sebastian Stasik and Uwe Platzbecker and Carsten Müller-Tidow and Hubert Serve and Claudia D Baldus and Christoph Schliemann and Kerstin Schäfer-Eckart and Maher Hanoun and Martin Kaufmann and Andreas Burchert and Christian Thiede and Johannes Schetelig and Martin Bornhäuser and Markus Wolfien and Jan Moritz Middeke},
abstract = {Data sharing is often hindered by concerns of patient privacy, regulatory aspects, and proprietary interests thereby impeding scientific progress and establishing a gatekeeping mechanism in clinical medicine since obtaining large data sets is costly and time-consuming. We employed two different generative artificial intelligence (AI) technologies: CTAB-GAN+ and Normalizing Flows (NFlow) to synthesize clinical trial data based on pooled patient data from four previous multicenter clinical trials of the German Study Alliance Leukemia (AML96, AML2003, AML60+, SORAML) that enrolled adult patients (n=1606) with acute myeloid leukemia (AML) who received intensive induction therapy. As a generative adversarial network (GAN), CTAB-GAN+ consists of two adversarial networks: a generator producing synthetic samples from random noise and a discriminator aiming to distinguish between real and synthetic samples. The model converges as the discriminator can no longer reliably differentiate between real or synthetic data. Contrastingly, NFlow consists of a sequence of invertible transformations (flows) starting from a simple base distribution and gradually adding complexity to better mirror the training data. Both models were trained on tabular data including demographic, laboratory, molecular genetic and cytogenetic patient variables. Detection of molecular alterations in the original cohort was performed via next-generation sequencing (NGS) using the TruSight Myeloid Sequencing Panel (Illumina, San Diego, CA, USA) with a 5% variant-allele frequency (VAF) mutation calling cut-off. For cytogenetics, standard techniques for chromosome banding and fluorescence-in-situ-hybridization (FISH) were used. Hyperparameter tuning of generative models was conducted using the Optuna Framework. For each model, we used a total of 70 optimization trials to optimize a custom score inspired by TabSynDex which assesses both the resemblance of the synthetic data to real training data and its utility. Pairwise analyses were conducted between the original and both synthetic data sets, respectively. All tests were carried out as two-sided tests using a significance level α of 0.05. Table 1 summarizes baseline patient characteristics and outcome for both synthetic cohorts compared to the original cohort. Firstly, we found both models to adequately represent patient features, albeit that some individual variables showed a statistically significant deviation from the original cohort. It is important to note that for such a large sample size (n=1606 for each cohort), even miniscule differences can be rendered statistically significant notwithstanding any meaningful clinical difference. Interestingly, variables that deviated from the original distribution were different for both models indicating model architecture to play a vital role in sample representation: While CTAB-GAN+ showed significant deviations for both age and sex, NFlow showed significant deviations for AML status. Complete remission rate was similar between original (70.7%, odds ratio [OR]: 2.41) and CTAB-GAN+ (73.7%, OR: 2.81, p=0.059) and NFlow (69.1%, OR: 2.24, p=0.356). For event-free survival (EFS), which was not included as a target in hyperparameter tuning, both networks deviated significantly from the original cohort (original: median 7.2 months, HR: 1.36; CTAB-GAN+: median 12.8 months, HR 0.74, p<0.001; NFlow: median 9.0 months, HR: 0.87, p=0.001). Overall survival (OS) was well represented by NFlow compared to the original cohort, while CTAB-GAN+ showed a significant deviation (original: median 17.5 months, HR: 1.14; CTAB-GAN+: median 19.5 months, HR 0.88, p<0.001; NFlow: median 16.2 months, HR: 1.00, p=0.055). Both models showed an adequate graph representation in Kaplan-Meier analysis (Figure 1). Here, we demonstrate using two different generative AI technologies that synthetic data generation provides an attractive solution to circumvent issues in current standards of data collection and sharing. It effectively allows for bypassing logistical, organizational, and financial burdens, as well as regulatory and ethical concerns. Ultimately, this enables explorative research inquiries into previously inaccessible data sets and offers the prospect of fully synthetic control arms in prospective clinical trials.}
}
@incollection{KHALEEL20262,
title = {Future Proofing the Integrity of Assessments Within Business Management Studies for the Age of Artificial Intelligence},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {2-8},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00330-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013003303},
author = {Fawad Khaleel and Patrick Harte and Alija Avdukic},
keywords = {Academic dishonesty, Academic integrity, Artificial intelligence, Assessment design, Complexity of assessment design, Coursework, Plagiarism, Word count},
abstract = {The content generative artificial intelligence is developing rapidly, and it is challenging the old norms of assessment design within the HEIs. This chapter discusses the impact of AI on the academic integrity, as we argue that with a slight shift within the assessment design, we can address the academic integrity concerns that surfacing within the higher education. This chapter provides practical and useable guidelines that could be used to reduce the breaches of academic integrity within business management programmes at HEIs. These guidelines focus on word count for coursework, complexity of assessment question and social dynamics of assessment design.}
}
@article{COLBRAN2023105008,
title = {Generative artificial intelligence in Journal of Biological Chemistry},
journal = {Journal of Biological Chemistry},
volume = {299},
number = {8},
pages = {105008},
year = {2023},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2023.105008},
url = {https://www.sciencedirect.com/science/article/pii/S0021925823020367},
author = {Roger J. Colbran and Alex Toker}
}
@article{KSHETRI2024102716,
title = {Generative artificial intelligence in marketing: Applications, opportunities, challenges, and research agenda},
journal = {International Journal of Information Management},
volume = {75},
pages = {102716},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102716},
url = {https://www.sciencedirect.com/science/article/pii/S026840122300097X},
author = {Nir Kshetri and Yogesh K. Dwivedi and Thomas H. Davenport and Niki Panteli},
keywords = {ChatGPT, Customer engagement, Customer experience, Generative AI, Personalization},
abstract = {While all functional areas in organizations are benefiting from the recent development in generative artificial intelligence (GAI), marketing has been particularly affected positively by this breakthrough innovation. However, scholars have not paid attention to the transformative impacts GAI has on marketing activities. This editorial article aims to fill this void. It outlines the current state of generative artificial intelligence in marketing. The article discusses the facilitators and barriers for the use of generative artificial intelligence in marketing. It highlights the effectiveness of insights generated by GAI in personalizing content and offerings and argues that marketing content generated by GAI is likely to be more personally relevant than that produced by earlier generations of digital technologies. The article explains how higher efficiency and productivity of marketing activities can be achieved by using GAI to create marketing content. It also describes the roles of insights and marketing content generated by GAI to improve the sales lead generation process. Implications for research, practice and policy are also discussed.}
}
@article{SRIDHARAN2025101965,
title = {Artificial intelligence in colloid and interface science: Current research, challenges and future directions},
journal = {Current Opinion in Colloid & Interface Science},
pages = {101965},
year = {2025},
issn = {1359-0294},
doi = {https://doi.org/10.1016/j.cocis.2025.101965},
url = {https://www.sciencedirect.com/science/article/pii/S1359029425000718},
author = {Simha Sridharan and Tom Bailey and Agnese Marcato and Elena Simone and Nicholas Watson},
keywords = {Artificial Intelligence, Machine Learning, Colloid Science, Interface Science},
abstract = {Artificial intelligence (AI) and Machine learning (ML) are transforming colloid and interface science by enabling predictive modelling, autonomous experimentation, and accelerated material design. This review highlights recent advances organised in four topics: (1) prediction of basic physical properties; (2) image analysis; (3) process design, monitoring and optimisation; and (4) morphology and phase behaviour prediction. AI models have improved the prediction accuracy of interfacial tension, critical micelle concentration, foam stability, and complex structure–function relationships, in particular, integrated generative AI approaches support the design of new surfactants and emulsifiers. Image analysis has automated microstructural characterisation and enabled real-time quality control, while AI-enhanced process design has delivered digital twins, closed-loop optimisation, and sustainability-oriented workflows. Morphology and phase behaviour prediction has combined simulation-driven neural networks with generative approaches to accelerate material discovery. The future of AI applications in colloids will be shaped by experimental database design and standardisation, hybrid AI methods integrating physics and surrogate modelling, and AI agents leveraging large language models for literature mining, data curation, and experimental optimisation. Together, these developments promise to establish data-rich, physics informed, and increasingly autonomous research ecosystems for colloids and interface science, accelerating material understanding and design.}
}
@article{DABBAGH2025389,
title = {The Role of Artificial Intelligence in Medicine with a Special Focus on Anesthesiology and Perioperative Care},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3},
pages = {389-403},
year = {2025},
note = {Artificial Intelligence in Anesthesiology},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1932227525000278},
author = {Ali Dabbagh and A. Sassan Sabouri},
keywords = {Intelligence, Artificial learning, Turing test, Machine learning, Learning models, Generative AI, Large language mode, Prediction model}
}
@article{CHEEMA2025,
title = {The Future of Artificial Intelligence and Artificial Intelligence in Primary Care: Challenges and Opportunities},
journal = {Primary Care: Clinics in Office Practice},
year = {2025},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000727},
author = {Alyscia Miriam Cheema},
keywords = {Artificial intelligence in primary care, Primary care practice training with artificial intelligence, Future impacts of AI on primary care, Challenges with AI in primary care}
}
@article{SALMAN2024S776,
title = {ID: 4120624 Building Patient Archetypes to Analyze Willingness to Change using New Technologies: Generative Artificial Intelligence with the Goal of More Optimally Influencing Change in Patient Behaviors with Atrial Fibrillation},
journal = {Heart Rhythm},
volume = {21},
number = {9, Supplement },
pages = {S776-S777},
year = {2024},
note = {HRX AbstracX 2024},
issn = {1547-5271},
doi = {https://doi.org/10.1016/j.hrthm.2024.07.043},
url = {https://www.sciencedirect.com/science/article/pii/S1547527124029904},
author = {S. Salman and I. Tripuraneni and K. Lingineni and A. Vemulapalli and S. Venigalla and A. Tripuraneni}
}
@article{MULAT2025107232,
title = {Application of artificial intelligence in microbial drug discovery: Unlocking new frontiers in biotechnology},
journal = {Journal of Microbiological Methods},
volume = {237},
pages = {107232},
year = {2025},
issn = {0167-7012},
doi = {https://doi.org/10.1016/j.mimet.2025.107232},
url = {https://www.sciencedirect.com/science/article/pii/S0167701225001484},
author = {Mulugeta Mulat and Riza Jane S. Banicod and Nazia Tabassum and Aqib Javaid and Tae-Hee Kim and Young-Mog Kim and Fazlurrahman Khan},
keywords = {Artificial intelligence, Antimicrobial resistance, Microbial pathogens, Genomics, Drug discovery},
abstract = {Artificial intelligence (AI) is revolutionizing antimicrobial drug discovery by delivering major improvements in precision, innovation, and efficiency for combating bacterial, fungal, and viral pathogens. Traditional approaches to developing treatments for microbial infections are often hampered by high costs, lengthy timelines, and frequent failures. Modern AI technologies, particularly deep learning, machine learning, computational biology, and big data analytics, provide robust solutions to these challenges by analyzing large-scale biological datasets to predict molecular interactions, identify promising treatment candidates, and expedite both preclinical and clinical development. Innovative techniques such as generative adversarial networks for novel compound discovery, reinforcement learning for optimizing antimicrobial candidates, and natural language processing for extracting knowledge from biomedical literature are now vital to infectious disease research. These approaches facilitate early toxicity prediction, microbial target identification, virtual screening, and the development of more individualized therapies. Notwithstanding these advances, challenges remain, including inconsistent data quality, limited interpretability, and unresolved ethical or legal concerns. This review examines recent advancements in AI applications for microbial drug discovery, with a focus on de novo molecular design, ligand- and structure-based screening, and AI-enabled biomarker identification. Remaining application barriers and promising future directions in AI-driven antimicrobial drug development are also elucidated. Collectively, these innovations are poised to accelerate the discovery of new therapies, reduce costs, and enhance patient outcomes in the fight against infectious diseases.}
}
@article{HABER2025100196,
title = {CanvasHero: The role of artificial intelligence in cultivating resilience among children and youth using the 6-part story method in mass war trauma},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100196},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100196},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000805},
author = {Yuval Haber and Inbar Levkovich and Iftach Tzafrir and Karny Gigi and Dror Yinon and Dorit Hadar Shoval and Zohar Elyoseph},
keywords = {Resilience, Mass trauma, Displaced population, Children and youth, AI tools, Imagination},
abstract = {Background
The potential of Generative Artificial Intelligence (GenAI) to promote mental health is of great interest. Specifically, there is growing interest in integrating applied GenAI into psychotherapy or into the teacher/parent-child relationship. This paper describes CanvasHero, a GenAI tool that was developed following the devastating attacks on Israel in October 2023. It aims to promote resilience in children and adolescents who were evacuated from their homes due to the war. CanvasHero serves as a proof of concept for integrating GenAI as an additional element that can enrich and deepen interpersonal interaction.
Tool description
CanvasHero utilizes the BASIC Ph model and 6-Part Story Method for assessing and bolstering coping skills, aided by the interactive scaffolding and synthetic abilities of the GenAI. Key stages comprise (1) collaborative narrative construction between child, meaningful adult, and the GAI; (2) analysis of resilience themes; and (3) generative visualization representing the child's story through DALL-E's imaging capabilities.
Implementation protocol
The CanvasHero is optimally designed for children ages 7–16 under adult supervision, with the HEART Checklist developed to structure this process. Sessions typically occur remotely via videoconference, or in person.
Intended outcomes
CanvasHero aims to create a playful space for processing stress and trauma, identifies resilience resources, and strengthens these capabilities. At the same time, risks in GenAI integration are mitigated via human oversight and an ethics-focused design.
Conclusion
CanvasHero exemplifies a GenAI application that can assist during wartime, serving as a psycho-educational mediator and facilitating an imaginative and playful space between children and meaningful adults. Further studies are required to evaluate effectiveness and potential risks.}
}
@article{RICHTER2023385,
title = {Foot and Ankle Surgery declares use of generative artificial intelligence like Chat Generative Pre-trained Transformer (ChatGPT) for scientific publications},
journal = {Foot and Ankle Surgery},
volume = {29},
number = {5},
pages = {385-386},
year = {2023},
issn = {1268-7731},
doi = {https://doi.org/10.1016/j.fas.2023.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1268773123000802},
author = {Martinus Richter}
}
@article{ALDREABI2025100456,
title = {Unveiling the dynamics of generative AI adoption: A business intelligence analysis through topic modeling-based bibliometric study},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100456},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100456},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000967},
author = {Hanadi Aldreabi and Mohammad Alhur and Manaf Al-Okaily and Dhia Qasim and Nisreen K. Dahdoul and Fadi S. Shiyyab},
keywords = {AI tools, ChatGPT, Generative AI, Educational technology, Business intelligence, Bibliometric study},
abstract = {Generative Artificial Intelligence (GenAI) has gained notable attention in educational literature, with supporters and critics expressing varying opinions. Despite its popularity, only a few reviews are available on the subject, with limitations such as small sample sizes and limited scope. This study aims to clarify the major themes influencing the discussion on GenAI in educational contexts. It employs a strong Business Intelligence paradigm and uses bibliometric analysis and topic modeling focusing on the R program's structural topic model (STM) Package, VOSviewer, and bibliometric software. The results highlight the esteem of GenAI in education and evidence of international collaboration in the research process dedicated to enhancing the rapidly evolving field of GenAI. The scientometric indexes indicate that the diversity of journals has the significant impact on GenAI in education. While Lotka's Law suggests that the field is still in its early stages, the collaborative network demonstrates strong connections among researchers, a positive indicator of future progress. Moreover, the STM method has identified nine pivotal topics grouped into three categories relating to GenAI in education. By shedding light on these emerging themes, this study provides educators and researchers with valuable insights into the future of GenAI in education.}
}
@article{MOROSKY20254,
title = {Practical applications of artificial intelligence chatbots in obstetrics and gynecology medical education},
journal = {American Journal of Obstetrics and Gynecology},
volume = {233},
number = {1},
pages = {4-11},
year = {2025},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2025.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0002937825002285},
author = {Christopher M. Morosky and Laura Baecher-Lind and Katherine T. Chen and Angela Fleming and Shireen Madani Sims and Helen Kang Morgan and Celeste S. Royce and Tammy Sonn and Alyssa Stephenson-Famy and Jill Sutton and Jonathan Schaffir and Rashmi Bhargava},
keywords = {artificial intelligence, biases, chatbot, ChatGPT, data privacy, faculty development, feedback, hallucinations, informed approach, integration, large language models, learning objectives, medical education, mentorship, responsible use, teaching},
abstract = {Generative artificial intelligence chatbots are sophisticated conversational artificial intelligence tools that have the capability to interpret natural language inputs and produce responses that closely resemble human speech. Artificial intelligence chatbots hold significant promise in revolutionizing medical education by offering invaluable support across various educational domains, including teaching, learning, and assessment. Their practical applications span a wide spectrum, from aligning learning objectives and simplifying administrative tasks to facilitating feedback, aiding faculty development, and supporting mentorship initiatives. However, alongside their potential benefits, concerns exist regarding data privacy, inherent biases, and occasional errors termed “hallucinations,” underscoring the imperative for a cautious and informed approach to their integration within educational settings. It therefore becomes essential for medical educators and academic institutions to proactively engage with artificial intelligence technologies like chatbots, not only to leverage their benefits but also to critically assess and address associated challenges such as bias, privacy, and misinformation. By thoughtfully integrating artificial intelligence tools, medical educators can determine where these technologies are most beneficial, implement safeguards against potential harms, and explore innovative applications to enhance medical education.}
}
@article{WANG2025147,
title = {Understanding users’ effective use of generative conversational AI from a media naturalness perspective: a hybrid structural equation modeling-artificial neural network (SEM-ANN) approach},
journal = {Data Science and Management},
volume = {8},
number = {2},
pages = {147-159},
year = {2025},
issn = {2666-7649},
doi = {https://doi.org/10.1016/j.dsm.2024.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S266676492400047X},
author = {Kun Wang and Yaobin Lu and Zhao Pan},
keywords = {Generative conversational AI, Content naturalness, Style naturalness, Effective use, SEM-ANN method},
abstract = {Although generative conversational artificial intelligence (AI) can answer questions well and hold conversations as a person, the semantic ambiguity inherent in text-based communication poses challenges to effective use. Effective use reflects the users’ utilization of generative conversational AI to achieve their goals, which has not been previously studied. Drawing on the media naturalness theory, we examined how generative conversational AI’s content and style naturalness affect effective use. A two-wave survey was conducted to collect data from 565 users of generative conversational AI. Two techniques were used in this study. Initially, partial least squares structural equation modeling (PLS-SEM) was applied to determine the variables that significantly affected the mechanisms (i.e., cognitive effort and communication ambiguity) and effective use. Secondly, an artificial neural network model was used to evaluate the relative importance of the significant predictors of mechanisms and effective use identified from the PLS-SEM analysis. The results revealed that the naturalness of content and style differed in their effects on cognitive effort and communication ambiguity. Additionally, cognitive effort and communication ambiguity negatively affected effective use. This study advances the literature on effective use by uncovering the psychological mechanisms underlying effective use and their antecedents. In addition, this study offers insights into the design of generative conversational AI.}
}
@article{RAYAGONZALEZ2025110375,
title = {High-precision prototype for garlic apex reorientation based on artificial intelligence models},
journal = {Computers and Electronics in Agriculture},
volume = {235},
pages = {110375},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.110375},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925004818},
author = {Luis Enrique Raya-González and Víctor Alfonso Alcántar-Camarena and Alberto Saldaña-Robles and Edgar Francisco Duque-Vazquez and Guillermo Tapia-Tinoco and Noé Saldaña-Robles},
keywords = {Deep learning, Machine learning, Transfer learning, Image analysis,  L},
abstract = {Sowing and harvesting are the most expensive operations in garlic cultivation (Allium sativum L.). For mechanized sowing to be feasible, the garlic clove must be placed in the soil with the apex pointing upwards, otherwise, yield can be reduced by up to 23%. In this context, artificial intelligence (AI) emerges as a viable solution to address these issues, particularly artificial neural networks (ANN). This research presents the development and evaluation of a garlic apex orientation device, which utilizes AI models adapted to all types of garlic clove shapes. The evaluated models are support vector machine (SVM), random forest (RF), ANN, convolutional neural network (CNN), and transfer learning (TL). To increase the number of available images for training, a generative adversarial network (GAN) was used. Three different databases were used to train models to determine achieved the best performance in terms of model accuracy. The databases used are the original database, an augmentation version of the original database incorporating images generated by the GAN model, and only images generated by the GAN model. The results show that the best model (ANN) achieves a validation accuracy of 99.74% when using an augmentation of the original database with artificial images generated by the GAN model.}
}
@article{WALTERS2024S626,
title = {SA62 Evaluating Generative Artificial Intelligence (GenAI) in Health Technology Assessment (HTA) Content Generation: A Proof-of-Concept Using Canadian Agency for Drugs and Technologies in Health (CADTH) Reimbursement Dossier Forms},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S626},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.3143},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524060066},
author = {J. Walters and I. Guerra and K. Rtveladze and J. Joseph and R. Shankar and T. Wiemken and P.A. Dubé and T.C. Woodward}
}
@article{DISSANAYAKE2025101222,
title = {Artificial intelligence and management Education: Bibliometric analysis},
journal = {The International Journal of Management Education},
volume = {23},
number = {3},
pages = {101222},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101222},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725000928},
author = {Hiranya Dissanayake and Otilia Manta and Anuradha Iddagoda and Maria Palazzo},
keywords = {Artificial intelligence, Management education, Bibliometric analysis, ChatGPT, Collaborative analysis, Thematic analysis},
abstract = {A group of technologies known as artificial intelligence allow computers to carry out a number of sophisticated tasks, including as seeing, comprehending, and translating spoken and written language, analyzing data, and formulating suggestions. The significance of AI lies in its ability to boost productivity, automate processes, better decision-making, and stimulate innovation in a variety of sectors. Education is essential for societal advancement, economic success, and personal development because it promotes critical thinking and creativity while providing chances for better employment, informed citizenship, and a satisfying existence. This study aims to assess the development and application of AI in management education through a bibliometric analysis. It explores publication trends, author influence, collaborative networks, keyword evolution, and thematic structures to uncover intellectual landscape and future directions of this emerging field. The study offers insights into the transformative role of AI, especially generative technologies like ChatGPT, in reshaping business and management education worldwide.}
}
@article{ENCARNACAO2025106872,
title = {Artificial intelligence in wound care education: Scoping review},
journal = {Nurse Education Today},
volume = {155},
pages = {106872},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106872},
url = {https://www.sciencedirect.com/science/article/pii/S0260691725003090},
author = {Rúben Encarnação and José Alves and Ana Marques and João Neves-Amado and Paulo Alves},
keywords = {Artificial intelligence, Education, Health Education, Nursing Education Research, Review, Wounds, Injuries},
abstract = {Background
Artificial intelligence is transforming healthcare education, offering innovative teaching and skill development approaches. However, its implementation and effectiveness in wound care education remain unclear.
Objective
To map and analyze the available evidence on the potential impact of artificial intelligence in wound care education, identify knowledge gaps, and provide recommendations for future research.
Design/methods
This scoping review followed the Joanna Briggs Institute guidelines for scoping reviews and the PRISMA-ScR guidelines. The search was first conducted in December 2023 and updated on 30 November 2024 across the following databases: CINAHL Ultimate, MEDLINE, Cochrane Library, Academic Search Complete, Scientific Electronic Library Online (Scielo), Scopus, and Web of Science. Grey literature was accessed through Scientific Open Access Scientific Repositories of Portugal (RCAAP), ProQuest Dissertations and Theses, OpenAIRE, and Open Dissertations. Additional searches were performed in Google Scholar and specific journals, including the International Wound Journal, Skin Research and Technology, Journal of Wound Care, and Wound Repair and Regeneration. Eligibility criteria encompassed any study design exploring the use of artificial intelligence in wound care education, published in English, Portuguese, or Spanish, with no restrictions on publication date.
Results
This review revealed diverse artificial intelligence applications in wound care education, including adaptive e-learning platforms, virtual and augmented reality simulations, generative artificial intelligence for educational content, and diagnostic and treatment tools. These technologies offer personalized learning experiences, real-time feedback, and interactive engagement to enhance clinical skills. Despite their promise, most studies lacked empirical validation, highlighting significant gaps in integrating artificial intelligence into wound care education.
Conclusions
This review highlights artificial intelligence's transformative potential to revolutionize wound care education by fostering interactive and evidence-based learning environments. This work highlights the need for collaboration among educators, policymakers, and researchers. Future research is needed to ensure effective, ethical, and equitable integration of artificial intelligence in wound care education.}
}