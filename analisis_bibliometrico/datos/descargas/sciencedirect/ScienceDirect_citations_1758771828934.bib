@article{PALLOTTINO2025109919,
title = {Applications and perspectives of Generative Artificial Intelligence in agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {230},
pages = {109919},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.109919},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925000250},
author = {Federico Pallottino and Simona Violino and Simone Figorilli and Catello Pane and Jacopo Aguzzi and Giacomo Colle and Eugenio {Nerio Nemmi} and Alessandro Montaghi and Damianos Chatzievangelou and Francesca Antonucci and Lavinia Moscovini and Alessandro Mei and Corrado Costa and Luciano Ortenzi},
keywords = {GAI, GAN, NLP, LLMs, ChatGPT, Microsoft Copilot},
abstract = {Artificial Intelligence (AI) applications related to agriculture have recently gained in use and attention. They are indeed valuable tools for interpreting data, improving production chains, and optimizing the use of natural resources. Among AI models, the most recent and promising area is represented by Generative Artificial Intelligence (GAI). After an initial description of its general model architectures, this work aims to review its practical uses and potentials in the following individual sectors: agriculture, precision farming, and animal farming, as well as interdisciplinary applications. The literature search was carried out using the SCOPUS, Google Scholar, and Web of Science databases. GAI holds immense potential for revolutionizing agriculture, offering solutions ranging from precision farming to pest management and supply chain optimization. Though some applications can extend beyond efficiency gains, and hallucinations occurrence i.e. false output information presented as fact, remains an open issue, GAI can be decisive for tasks like improving training datasets, refining models, and facilitating time series analysis. This review extensively describes the vital importance of these tasks for agriculture, precision and animal farming, caused by the rise of new technologies. As a result, by embracing and responsibly implementing GAI applications, it is possible to create a more sustainable and resilient future for agriculture and precision farming. GAI have the capacity to extract specific information from big data systems, offering huge potential to meet a growing global population demand and consequent environmental challenges for the future.}
}
@article{HUNG2025103005,
title = {Factors driving user behavior and value creation with text-to-image generative artificial intelligence (AI): A systems theory perspective},
journal = {Technology in Society},
volume = {83},
pages = {103005},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103005},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25001952},
author = {Chih-Lung Hung and Jen-Her Wu and Po-Chuen Chiang and Qi Li and Yi-Cheng Chen},
keywords = {Text-to-image generative AI, Systems theory, Compatibility, Synergy, User value},
abstract = {The rise of image-generative AI has made it a crucial tool for image creators, gaining popularity in fields such as cartography, design, and photography. As users increasingly rely on AI for image creation, understanding the factors that drive user value becomes essential. Drawing on systems theory, this study proposes a conceptual framework to examine the relationships among integration effort, compatibility, synergy, and value creation. Data from 531 AI image creators supported our hypotheses, revealing that: (1) integration effort significantly enhances both compatibility and synergy; (2) compatibility positively influences synergy; (3) synergy directly and positively impacts user value creation; and (4) synergy serves as a critical mediator in the relationships between the two enablers—compatibility and integration effort—and user value creation, with compatibility also partially mediating the link between integration effort and synergy. These results extend systems theory by integrating it more deeply with the resource-based view and highlighting synergy as a pivotal factor that not only directly drives user value creation but also mediates the effects of compatibility and integration effort. Furthermore, the study empirically confirms that user value can be conceptualized through three key constructs: efficiency, effectiveness, and innovation.}
}
@article{JIN2025100467,
title = {Mechanisms of enhancing learning with unequal preparation: An experimental study on generative artificial intelligence use and proficiency in programming learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100467},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100467},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001079},
author = {Yuan Jin and Wei He and Jun Shen and Jingyun Hu},
keywords = {Generative artificial intelligence (GenAI), Learning preparation, GenAI proficiency, Learning outcomes, Experimental study},
abstract = {Prior learning preparation, encompassing learners' prior knowledge, resources, and readiness for learning new material, plays a critical role in a new learning process. Unequal learning preparation commonly exists among learners with varying socioeconomic and academic backgrounds, and can further exacerbate the educational divide. By reducing learning cost and providing less prepared learners with personalized delivery of information and knowledge, Generative Artificial Intelligence (GenAI) may help mitigate disparities in learning preparation. In this study, we investigate the roles of learners' use of GenAI in their learning processes, considering varying levels of learners’ prior learning preparation and proficiency in GenAI use. Specifically, we examine the effects of the use of GenAI tools on learning outcomes through its impacts on perceived informational benefit, learning cost, and knowledge fit in the focal learning process, moderated by learning preparation and GenAI proficiency of learners. Based on an experiment in a programming learning context, we find that although GenAI use significantly reduces learning cost, especially for less prepared learners, the cost reduction effect has not been translated into improved learning outcomes. We find no significant moderating effects of learning preparation on how GenAI use affects informational benefit and knowledge fit, further showing that GenAI tools have not yet been effectively utilized to help less prepared learners or reduce the educational divide. As indicated by the significant moderating roles of GenAI proficiency, to fully leverage the power of GenAI, improving GenAI proficiency can be crucial to ensure learning effectiveness for learners with different levels of learning preparation.}
}
@article{MABWE2025820,
title = {Generative artificial intelligence chatbots in investment decision-making: a phantom menace or a new hope?},
journal = {Foresight},
volume = {27},
number = {4},
pages = {820-863},
year = {2025},
issn = {1463-6689},
doi = {https://doi.org/10.1108/FS-06-2024-0122},
url = {https://www.sciencedirect.com/science/article/pii/S1463668925000082},
author = {Kumbirai Mabwe and Nasir Aminu and Stanislav Hristov Ivanov and Diyan Dimov},
keywords = {Generative AI, ChatGPT, Bard, Gemini, Bing, Large language models, Chatbots, Investment recommendations},
abstract = {Purpose
This study aims to investigate the relevance, accuracy, specificity and justification of investment recommendations of generative artificial intelligence (GenAI) chatbots for different investment capitals and countries (UK and Bulgaria).
Design/methodology/approach
A two-stage mixed methods approach was used. Prompts were queried into OpenAI’s ChatGPT, Microsoft Bing and Google Bard (now Gemini). Finance and investment practitioners and finance and investment lecturers assessed the chatbots’ recommendations through an online questionnaire using a five-point Likert scale. The Chi-squared test, Wilcoxon-signed ranks test, Mann–Whitney U test and Friedman test were used for data analysis to compare GenAIs’ recommendations for the UK and Bulgaria across different amounts of investment capital and to assess the consistency of the chatbots.
Findings
GenAI chatbots’ responses were found to perform medium-to-high in terms of relevance, accuracy, specificity and justification. For the UK sample, the amount of investment had a marginal effect but prompt timing had an interesting impact. Unlike the British sample, the GenAI application, prompt timing and investment amount did not significantly influence the Bulgarian respondents’ evaluations. While the mean responses of the British sample were slightly higher, these differences were not statistically significant, indicating that ChatGPT, Bing and Bard performed similarly in both the UK and Bulgaria.
Originality/value
The study assesses the relevance, accuracy, specificity and justification of GenAI chatbots’ investment recommendations for two different periods, investment amounts and countries.}
}
@article{ROBINSON2025212,
title = {Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {307},
pages = {212-220},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2024.12.059},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425000216},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines},
keywords = {AI, Artificial intelligence, ChatGPT, Generative AI, Large language models},
abstract = {Artificial intelligence (AI) is rapidly being used in medicine due to its advanced capabilities in image and video recognition, clinical decision support, surgical education, and administrative task automation. Large language models such as OpenAI’s Generative Pretrained Transformer (GPT)-4 and Google’s Bard have particularly revolutionized text generation, offering substantial benefits for the academic surgeon, including aiding in manuscript and grant writing. However, integrating AI into academic surgery necessitates addressing ethical concerns such as bias, transparency, and intellectual property. This paper provides guidelines and recommendations based on current literature around the opportunities and ethical challenges of AI in academic surgery. We discuss the underlying mechanisms of large language models, their potential biases, and the importance of responsible usage. Furthermore, we explore the ethical implications of AI in clinical documentation, highlighting improved efficiency and necessary privacy concerns. This review also addresses the critical issue of intellectual property dilemmas posed by AI-generated innovations in university settings. Finally, we propose guidelines for the responsible adoption of AI in academic and clinical environments, stressing the need for transparency, ethical training, and robust governance frameworks to ensure AI enhances, rather than undermines, academic integrity and patient care.}
}
@article{ZHANG2026104392,
title = {The double-edged impact of generative artificial intelligence dependence on service innovation in the hospitality industry: A self-regulation perspective},
journal = {International Journal of Hospitality Management},
volume = {132},
pages = {104392},
year = {2026},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104392},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925003202},
author = {Zhenduo Zhang and Yanyu Dai and Jianing Guo and Haonan Zhang and Yifei Shen and Huan Xiao},
keywords = {Generative artificial intelligence dependence, Problem-solving pondering, Affective rumination, Service innovation, Conscientiousness, Neuroticism},
abstract = {To date, studies on the relationship between generative artificial intelligence (GenAI) dependence and service innovation have yielded inconsistent results. Drawing on self-regulation theory, we examine how and when GenAI dependence promotes or inhibits service innovation in the hospitality industry. Three studies were conducted to examine how GenAI is used in hospitality management and test the conceptual model: a three-wave questionnaire survey (N = 333), a quasi-field experiment (N = 227), and an in-depth interview (N = 11). The results indicate that GenAI dependence promotes service innovation by decreasing affective rumination, and this beneficial indirect path is amplified by employees’ neuroticism. Meanwhile, GenAI dependence inhibits service innovation by decreasing problem-solving pondering, and this unfavourable indirect path is weakened by employees’ conscientiousness. This exploration of when and how the use of GenAI either promotes or inhibits service innovation broadens our understanding of the consequences of GenAI dependence in the hospitality management field.}
}
@article{WANG2024102744,
title = {Green entrepreneurship success in the age of generative artificial intelligence: The interplay of technology adoption, knowledge management, and government support},
journal = {Technology in Society},
volume = {79},
pages = {102744},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102744},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002926},
author = {Shaofeng Wang and Hao Zhang},
keywords = {Generative artificial intelligence, Green entrepreneurship, Knowledge management, Green innovation, Government support, Resource orchestration theory},
abstract = {This study investigates the integral role of generative artificial intelligence (GAI) in enhancing green entrepreneurship success, focusing on the interconnected dynamics of GAI adoption, green knowledge management, innovation, and government support. Despite the growing interest in GAI, existing research lacks an understanding of how GAI fosters green entrepreneurship success, particularly in green knowledge management and innovation pathways. Utilizing a robust theoretical framework grounded in resource orchestration and knowledge management theories, we examine the influence of GAI on acquiring and applying green knowledge and its subsequent impact on fostering green innovation. The study examines how government funding moderates these correlations. Employing PLS-SEM and fsQCA, the research elucidates complex interrelationships and causal paths. The findings reveal that GAI significantly enhances green knowledge management capabilities, which drives green innovation and entrepreneurship success. Additionally, government support plays a crucial role in amplifying these effects. This study contributes to technological change and social transformation discourse, offering practical insights for decision-makers and stakeholders in green entrepreneurship and policy-making.}
}
@article{YANG2025,
title = {Reinforcement learning-based generative artificial intelligence for novel pesticide design},
journal = {Journal of Advanced Research},
year = {2025},
issn = {2090-1232},
doi = {https://doi.org/10.1016/j.jare.2025.02.030},
url = {https://www.sciencedirect.com/science/article/pii/S2090123225001286},
author = {Ruoqi Yang and Biao Li and Jin Dong and Zhuomei Cai and Hongyan Lin and Fan Wang and Guangfu Yang},
keywords = {Generative model, Reinforcement learning, Pesticide design, 4-hydroxyphenylpyruvate dioxygenase},
abstract = {Introduction
Pesticides play a pivotal role in ensuring food security, and the development of green pesticides is an inevitable trend in global agricultural progress. Although deep learning-based generative models have revolutionized de novo drug design in pharmaceutical research, their application in pesticide research and development remains unexplored.
Objectives
This study aims to pioneer the application of generative artificial intelligence to pesticide design by proposing a reinforcement learning-based framework for obtaining pesticide-like molecules with high binding affinity.
Methods
This framework comprises two key components: PestiGen-G, which systematically explores the pesticide-like chemical space using a character-based generative model coupled with the REINFORCE algorithm; and PestiGen-S, which combines a fragment-based generative model with the Monte Carlo Tree Search algorithm to generate molecules that stably bind to the specific target protein.
Results
Experimental results show that the molecules generated by PestiGen have superior pesticide-likeness and binding affinity compared to those generated by existing methods. In addition, we employ an active learning strategy to reduce the false-positive rate of the generated molecules. Finally, through collaboration with domain experts, we successfully designed a novel 4-hydroxyphenylpyruvate dioxygenase inhibitor (YH23768) with favorable enzyme inhibition and herbicidal potency.
Conclusion
This proof-of-concept study highlights the utility of PestiGen as a valuable tool for pesticide design. The web server based on the model is freely available at https://dpai.ccnu.edu.cn/PestiGen/.}
}
@article{LIU2025114513,
title = {A friend or a foe? The effect of generative artificial intelligence on creator contributions on original work sharing platforms},
journal = {Decision Support Systems},
volume = {197},
pages = {114513},
year = {2025},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2025.114513},
url = {https://www.sciencedirect.com/science/article/pii/S0167923625001149},
author = {Shan Liu and Wenxuan Hu and Baojun Gao},
keywords = {Generative artificial intelligence, Copyright infringement, Original work sharing platform, Crowding out, Protective motivation theory},
abstract = {While generative artificial intelligence (GAI) is increasingly used to create content, it is often criticized for collecting and training private data and induces potential copy infringement issue. This dilemma leaves a question of whether GAI increases or decreases creators' work sharing. Drawn on protection motivation theory, this study examines how the launch of a GAI system affects creators' contributions on an original work sharing platform. We discover that GAI poses a threat to drawing-category creators, leading to a significant crowding-out effect on their contributions. Specifically, compared with that of non-drawing-category creators, the work sharing of drawing-category creators decreases by 19.64 % and 14.29 % within a short period after the launch and removal of the GAI system, respectively. We discover that creators' protective behavior is driven by GAI-related copyright infringement. Compared with creators without copyright protection, those with copyright protection are more inclined to cease contributions or even leave the platform. We further find that among copyright-protected creators, top creators, evidenced by their acquisition of a large number of supporters or platform honor titles, exhibit more pronounced responses to protect their works due to their higher coping efficacy. Notably, this threat reduces creators' sharing behavior or even lead to their exit from the platform. Nevertheless, such reduction is likely to gradually recover once the threat subsides. Overall, our findings have important implications for whether and how platform managers adopt GAI systems, especially in an original work sharing context.}
}
@article{SIMMS2025106544,
title = {Generative artificial intelligence (AI) literacy in nursing education: A crucial call to action},
journal = {Nurse Education Today},
volume = {146},
pages = {106544},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2024.106544},
url = {https://www.sciencedirect.com/science/article/pii/S0260691724004544},
author = {Rachel C. Simms},
keywords = {Artificial intelligence, Nursing education, Educational technology, Ethics, Nursing},
abstract = {Introduction
Generative artificial intelligence (AI) is revolutionizing healthcare, necessitating corresponding advancements in nursing education to ensure that future nurses are equipped for a technologically driven environment. This article explores the imperative integration of generative AI literacy in nursing education.
Implications for nurse educators
The article delves into the practical challenges and opportunities presented by generative AI in nursing. It underscores the need for educators to adapt curricula and teaching methods to effectively incorporate generative AI learning, ensuring students are proficient in generative AI technologies and aware of their ethical implications.
Generative AI literacy
Defined as a core educational requirement, this section highlights the skills and knowledge that nurse educators must impart. It encompasses the ability to critically assess AI-generated content, understand the underlying technologies, and responsibly apply this knowledge in clinical settings.
Conclusion
The article concludes by emphasizing the urgency of integrating generative AI literacy into nursing education. It advocates for a proactive approach to curriculum development and calls for global collaboration and standardization in AI education to address the diverse and evolving needs of healthcare.}
}
@article{FLEURENCE2025175,
title = {Generative Artificial Intelligence for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations: An ISPOR Working Group Report},
journal = {Value in Health},
volume = {28},
number = {2},
pages = {175-183},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.3846},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524067548},
author = {Rachael L. Fleurence and Jiang Bian and Xiaoyan Wang and Hua Xu and Dalia Dawoud and Mitchell Higashi and Jagpreet Chhatwal},
keywords = {artificial intelligence, economic modeling methods, generative AI, large language models, real world evidence, systematic reviews},
abstract = {Objectives
To provide an introduction to the uses of generative artificial intelligence (AI) and foundation models, including large language models, in the field of health technology assessment (HTA).
Methods
We reviewed applications of generative AI in 3 areas: systematic literature reviews, real-world evidence, and health economic modeling.
Results
(1) Literature reviews: generative AI has the potential to assist in automating aspects of systematic literature reviews by proposing search terms, screening abstracts, extracting data, and generating code for meta-analyses; (2) real-world evidence: generative AI can facilitate automating processes and analyze large collections of real-world data, including unstructured clinical notes and imaging; (3) health economic modeling: generative AI can aid in the development of health economic models, from conceptualization to validation. Limitations in the use of foundation models and large language models include challenges surrounding their scientific rigor and reliability, the potential for bias, implications for equity, as well as nontrivial concerns regarding adherence to regulatory and ethical standards, particularly in terms of data privacy and security. Additionally, we survey the current policy landscape and provide suggestions for HTA agencies on responsibly integrating generative AI into their workflows, emphasizing the importance of human oversight and the fast-evolving nature of these tools.
Conclusions
Although generative AI technology holds promise with respect to HTA applications, it is still undergoing rapid developments and improvements. Continued careful evaluation of their applications to HTA is required. Both developers and users of research incorporating these tools, should familiarize themselves with their current capabilities and limitations.}
}
@article{VISSAK2025436,
title = {Applying generative artificial intelligence applications for academic research on firms’ nonlinear internationalization},
journal = {Review of International Business and Strategy},
volume = {35},
number = {4},
pages = {436-484},
year = {2025},
issn = {2059-6014},
doi = {https://doi.org/10.1108/RIBS-10-2024-0120},
url = {https://www.sciencedirect.com/science/article/pii/S2059601425000037},
author = {Tiia Vissak and Lasse Torkkeli},
keywords = {Nonlinear internationalization, De-internationalization, Re-internationalization, Internationalization, Generative artificial intelligence (GenAI) tools, GenAI tools in research},
abstract = {Purpose
This study aims to critically evaluate the applicability of generative artificial intelligence (GenAI) tools for academic research in international business (IB), specifically focusing on the topic of firms’ nonlinear internationalization. It assesses these tools’ key performance dimensions: correctness, hallucinations and thoroughness.
Design/methodology/approach
This research adopts an exploratory approach, examining a comprehensive set of GenAI tools: eight chatbots and four AI-driven applications designed for academic purposes. The evaluation focuses on the capabilities and limitations of these tools in generating accurate research-related content for IB scholars.
Findings
This study finds that while GenAI tools capture some aspects of nonlinear internationalization, they often produce partially accurate and/or biased results. Common issues include providing fictitious sources, incorrect publication data and vague or incorrect answers. Thus, substantial development is still needed for GenAI tools to become reliable for scientific research.
Practical implications
Researchers should use GenAI tools with caution, verifying the accuracy of generated content and citations independently. A cautious approach is crucial to maintain the integrity and quality of academic research.
Social implications
This study raises awareness about ethical and practical challenges of using AI in academia, including issues related to plagiarism and misinformation. It underscores the importance of critical evaluation when using GenAI tools for research.
Originality/value
This paper contributes to the emerging literature on the role of GenAI in academic research by providing a critical assessment of the usability and limitations of current tools in studying complex IB phenomena. By using nonlinear internationalization as an example, it demonstrates how GenAI may support or hinder IB scholarship.}
}
@article{TADOKORO2025663,
title = {On the effective co-creation of CAD models by leveraging generative artificial intelligence},
journal = {Procedia CIRP},
volume = {134},
pages = {663-668},
year = {2025},
note = {58th CIRP Conference on Manufacturing Systems 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.02.181},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125005608},
author = {Fuwa Tadokoro and Angkush Kumar Ghosh and Sharifu Ura},
keywords = {Computer-Aided Design, Generative Artificial Intelligence, Co-creation, Prompt Tuning, Modular Decomposition, Information, Complexity},
abstract = {Collaboration between humans and generative artificial intelligence (GenAI) can result in effective problem-solving methods for smart manufacturing. From this point of view, this study presents how to solve computer-aided design (CAD) problems using GenAI-human collaboration, where a GenAI tool generates structured code (syntax) for CAD while a designer articulates the design intent (semantics). The focus is to see how the information type, model complexity, and prompt structure collectively affect the collaboration. A set of case studies demonstrate that a modular modeling approach with low-level information improves prompt efficiency and modeling accuracy, especially in complex scenarios. This strategy also enables novice and expert users to collaborate with GenAI in solving challenging real-world CAD tasks effectively. The findings support the development of advanced human-AI co-creation systems and encourage future research in areas such as reverse engineering, multi-part assemblies, and collaborative CAD workflows coupled with complex design constraints.}
}
@article{SUPPAN2025,
title = {Performance of 3 Conversational Generative Artificial Intelligence Models for Computing Maximum Safe Doses of Local Anesthetics: Comparative Analysis},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/66796},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000419},
author = {Mélanie Suppan and Pietro Elias Fubini and Alexandra Stefani and Mia Gisselbaek and Caroline Flora Samer and Georges Louis Savoldelli},
keywords = {local anesthetic, dose calculation, toxicity, performance, conversational generative artificial intelligence, artificial intelligence, anesthesiology, comparative analysis, anesthetics, LA, generative artificial intelligence, ChatGPT, Copilot, Gemini, artificial intelligence models, machine learning, neural network, LLM, NLP, natural language processing, large language model, AI, ML},
abstract = {Background
Generative artificial intelligence (AI) is showing great promise as a tool to optimize decision-making across various fields, including medicine. In anesthesiology, accurately calculating maximum safe doses of local anesthetics (LAs) is crucial to prevent complications such as local anesthetic systemic toxicity (LAST). Current methods for determining LA dosage are largely based on empirical guidelines and clinician experience, which can result in significant variability and dosing errors. AI models may offer a solution, by processing multiple parameters simultaneously to suggest adequate LA doses.
Objective
This study aimed to evaluate the efficacy and safety of 3 generative AI models, ChatGPT (OpenAI), Copilot (Microsoft Corporation), and Gemini (Google LLC), in calculating maximum safe LA doses, with the goal of determining their potential use in clinical practice.
Methods
A comparative analysis was conducted using a 51-item questionnaire designed to assess LA dose calculation across 10 simulated clinical vignettes. The responses generated by ChatGPT, Copilot, and Gemini were compared with reference doses calculated using a scientifically validated set of rules. Quantitative evaluations involved comparing AI-generated doses to these reference doses, while qualitative assessments were conducted by independent reviewers using a 5-point Likert scale.
Results
All 3 AI models (Gemini, ChatGPT, and Copilot) completed the questionnaire and generated responses aligned with LA dose calculation principles, but their performance in providing safe doses varied significantly. Gemini frequently avoided proposing any specific dose, instead recommending consultation with a specialist. When it did provide dose ranges, they often exceeded safe limits by 140% (SD 103%) in cases involving mixtures. ChatGPT provided unsafe doses in 90% (9/10) of cases, exceeding safe limits by 198% (SD 196%). Copilot’s recommendations were unsafe in 67% (6/9) of cases, exceeding limits by 217% (SD 239%). Qualitative assessments rated Gemini as “fair” and both ChatGPT and Copilot as “poor.”
Conclusions
Generative AI models like Gemini, ChatGPT, and Copilot currently lack the accuracy and reliability needed for safe LA dose calculation. Their poor performance suggests that they should not be used as decision-making tools for this purpose. Until more reliable AI-driven solutions are developed and validated, clinicians should rely on their expertise, experience, and a careful assessment of individual patient factors to guide LA dosing and ensure patient safety.}
}
@article{HUANG2025100526,
title = {Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow model for urban digital twin},
journal = {Environmental Science and Ecotechnology},
volume = {24},
pages = {100526},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2025.100526},
url = {https://www.sciencedirect.com/science/article/pii/S2666498425000043},
author = {Jeffrey Huang and Simon Elias Bibri and Paul Keel},
keywords = {Sustainable smart cities, Generative artificial intelligence, Generative spatial artificial intelligence, Foundation models, Large flow model, Urban digital twin, Urban planning and design},
abstract = {Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.}
}
@article{KUMAR2025115160,
title = {Generative artificial intelligence (GenAI) revolution: A deep dive into GenAI adoption},
journal = {Journal of Business Research},
volume = {189},
pages = {115160},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.115160},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324006647},
author = {Aman Kumar and Amit Shankar and Linda D. Hollebeek and Abhishek Behl and Weng Marc Lim},
keywords = {Artificial intelligence, Generative artificial intelligence, Generative AI, GenAI, Adoption, Behavioral reasoning theory, Mixed methods},
abstract = {This study examines key reasons (for and against) that influence business-to-business (B2B) managers’ intention to adopt generative artificial intelligence (GenAI). We also investigate how GenAI adoption influences firm performance, along with the moderating effect of ethical leadership. Study 1 undertakes a series of in-depth interviews, yielding a set of hypotheses that are tested in Study 2. A total of 277 responses was collected from respondents in the USA, the UK, Canada, India, Australia, Malaysia, and Japan to test the proposed model using structural equation modeling. The findings highlight that need for uniqueness, information completeness, convenience, and deceptiveness significantly impact GenAI adoption. The results also highlight that GenAI adoption boosts firm performance. Finally, ethical leadership was found to moderate the effect of GenAI adoption on firm performance. This study enriches the GenAI, technology adoption, and behavioral reasoning theory literatures while also providing pertinent insights for firms intending to adopt GenAI.}
}
@article{BUI2025101392,
title = {Exploring value co-creation and co-destruction between consumers & generative artificial intelligence (GAI) in travel},
journal = {Tourism Management Perspectives},
volume = {58},
pages = {101392},
year = {2025},
issn = {2211-9736},
doi = {https://doi.org/10.1016/j.tmp.2025.101392},
url = {https://www.sciencedirect.com/science/article/pii/S2211973625000571},
author = {Hien Thu Bui and Viachaslau Filimonau and Hakan Sezerel},
keywords = {Emerging technology, Generative artificial intelligence, Travel assistance, Value co-creation, Value co-destruction, ChatGPT},
abstract = {Little is known about the (dis)benefits of using generative artificial intelligence (GAI) with travel-related purposes, which hinders an understanding of the value co-created and co-destructed in the process of its use by tourists. This mixed methods study explored and examined the key factors in value co-creation and co-destruction when using a popular GAI's conversational interface, ChatGPT, in tourism. The results indicate that the key perceived utility of ChatGPT is in travel planning and time saving, and the main perceived shortcomings are its limited knowledge and inaccurate responses. The study pinpoints the importance of refining and developing GAI collaboratively by all tourism stakeholders given that perceived value co-creation outweighs value co-destruction.}
}
@article{LIU20251202,
title = {Environmental Assessment and Improvement of Factory Building Designs based on Generative Artificial Intelligence},
journal = {Procedia CIRP},
volume = {135},
pages = {1202-1207},
year = {2025},
note = {32nd CIRP Conference on Life Cycle Engineering (LCE2025)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.12.119},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125004184},
author = {Shengyu Liu and Sipke Hoekstra and Sebastian Thiede},
keywords = {Generative Artificial Intelligence, Life Cycle Assessment, Factory},
abstract = {The paper explores an innovative approach to evaluate the environmental impact of factory buildings at early design stages. Generative design, a cutting-edge computational technique, is employed to generate multiple factory building design alternatives based on user and case specific boundary conditions, e.g. related to material flow and space restrictions. This paper aims to integrate generative design principles with environmental assessment metrics to improve factory buildings for minimal environmental footprint, e.g. driven through energy demand. Thus, a framework that combines the generative factory design approach with key environmental assessment parameters is introduced. The effectiveness of generative design in enhancing the environmental performance of factory buildings is demonstrated with a case study. A comparative analysis of different designs highlights main influencing factors, as well as trade-offs and synergies between different manufacturing system performances and environmental oriented objectives. With that, the paper underlines the value of generative design as a transformative tool in sustainable factory design and provides actionable insights for architects, engineers, and policymakers aiming to develop greener industrial facilities.}
}
@article{METZGER2025103313,
title = {Generative artificial intelligence augmenting SME financial management},
journal = {Technovation},
volume = {147},
pages = {103313},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103313},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225001452},
author = {Michael Metzger and Seán O'Reilly and Ciarán {Mac an Bhaird}},
keywords = {Financial management, SMEs, Artificial intelligence, Digital technologies, Predictive modelling, Going concern},
abstract = {This study investigates the potential for entrepreneurs to leverage advances in technological innovation, specifically generative Artificial Intelligence (AI), to build management capability to mitigate business and financial risks. Drawing on theories of Technology Affordances and Constraints and the Resource-Based View (RBV) of the firm, recognising that small and medium-sized enterprises (SMEs) are inherently resource-constrained. We examine how AI-generated financial diagnostics can empower SMEs by generating accessible, real-time analysis and insights, thus bolstering the management function and increasing chances of survival and growth. Using a dataset of 1,150 UK SMEs spanning eight years of financial statements, we test a large language model (LLM) prediction assessment and analyse the potential for SMEs to utilise the technology, notwithstanding enterprise-specific constraints. We conclude that AI may be a very effective tool for smaller enterprises to augment the financial management function, although its efficacy hinges on organisational readiness, competence in interpreting data, and the will to act on automated red-flag alerts. These findings offer practical guidance for SMEs seeking to enhance their financial management processes in today's digital era.}
}
@article{RASHIDI2025100663,
title = {Statistics of Generative Artificial Intelligence and Nongenerative Predictive Analytics Machine Learning in Medicine},
journal = {Modern Pathology},
volume = {38},
number = {3},
pages = {100663},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100663},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002436},
author = {Hooman H. Rashidi and Bo Hu and Joshua Pantanowitz and Nam Tran and Silvia Liu and Alireza Chamanzar and Mert Gur and Chung-Chou H. Chang and Yanshan Wang and Ahmad Tafti and Liron Pantanowitz and Matthew G. Hanna},
keywords = {BiLingual Evaluation Understudy, accuracy, precision, F1 score, receiver operating characteristic area under the curve, perplexity},
abstract = {The rapidly evolving landscape of artificial intelligence (AI) and machine learning (ML) in medicine has prompted medical professionals to increasingly familiarize themselves with related topics. This also demands grasping the underlying statistical principles that govern their design, validation, and reproducibility. Uniquely, the practice of pathology and medicine produces vast amount of data that can be exploited by AI/ML. The emergence of generative AI, especially in the area of large language models and multimodal frameworks, represents approaches that are starting to transform medicine. Fundamentally, generative and traditional (eg, nongenerative predictive analytics) ML techniques rely on certain common statistical measures to function. However, unique to generative AI are metrics such as, but not limited to, perplexity and BiLingual Evaluation Understudy score that provide a means to determine the quality of generated samples that are typically unfamiliar to most medical practitioners. In contrast, nongenerative predictive analytics ML often uses more familiar metrics tailored to specific tasks as seen in the typical classification (ie, confusion metrics measures, such as accuracy, sensitivity, F1 score, and receiver operating characteristic area under the curve) or regression studies (ie, root mean square error and R2). To this end, the goal of this review article (as part 4 of our AI review series) is to provide an overview and a comparative measure of statistical measures and methodologies used in both generative AI and traditional (ie, nongenerative predictive analytics) ML fields along with their strengths and known limitations. By understanding their similarities and differences along with their respective applications, we will become better stewards of this transformative space, which ultimately enables us to better address our current and future needs and challenges in a more responsible and scientifically sound manner.}
}
@article{CAMPELLONE2025,
title = {Safety and User Experience of a Generative Artificial Intelligence Digital Mental Health Intervention: Exploratory Randomized Controlled Trial},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/67365},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125007381},
author = {Timothy R Campellone and Megan Flom and Robert M Montgomery and Lauren Bullard and Maddison C Pirner and Aaron Pavez and Michelle Morales and Devin Harper and Catherine Oddy and Tom O'Connor and Jade Daniels and Stephanie Eaneff and Valerie L Forman-Hoffman and Casey Sackett and Alison Darcy},
keywords = {generative AI, digital mental health intervention, user experience, RCT, randomized, controlled trials, randomized controlled trial, chatbots, artificial intelligence, AI, user relationship, user satisfaction, user safety, user, exploratory, relationship, satisfaction, safety, generative, DMHI, mental health, digital health},
abstract = {Background
General awareness and exposure to generative artificial intelligence (AI) have increased recently. This transformative technology has the potential to create a more dynamic and engaging user experience in digital mental health interventions (DMHIs). However, if not appropriately used and controlled, it can introduce risks to users that may result in harm and erode trust. At the time of conducting this trial, there had not been a rigorous evaluation of an approach to safely implementing generative AI in a DMHI.
Objective
This study aims to explore the user relationship, experience, safety, and technical guardrails of a DMHI using generative AI compared with a rules-based intervention.
Methods
We conducted a 2-week exploratory randomized controlled trial (RCT) with 160 adult participants randomized to receive a generative AI (n=81) or rules-based (n=79) version of a conversation-based DMHI. Self-report measures of the user relationship (client satisfaction, working alliance bond, and accuracy of empathic listening and reflection) and experience (engagement metrics, adverse events, and technical guardrail success) were collected. Descriptions and validation of technical guardrails for handling user inputs (eg, detecting potentially concerning language and off-topic responses) and model outputs (eg, not providing medical advice and not providing a diagnosis) are provided, along with examples to illustrate how they worked. Safety monitoring was conducted throughout the trial for adverse events, and the success of technical guardrails created for the generative arm was assessed post trial.
Results
In general, the majority of measures of user relationship and experience appeared to be similar in both the generative and rules-based arms. The generative arm appeared to be more accurate at detecting and responding to user statements with empathy (98% accuracy vs 69%). There were no serious or device-related adverse events, and technical guardrails were shown to be 100% successful in posttrial review of generated statements. A majority of participants in both groups reported an increase in positive sentiment (62% and 66%) about AI at the end of the trial.
Conclusions
This trial provides initial evidence that, with the right guardrails and process, generative AI can be successfully used in a digital mental health intervention (DMHI) while maintaining the user experience and relationship. It also provides an initial blueprint for approaches to technical and conversational guardrails that can be replicated to build a safe DMHI.
Trial Registration
ClinicalTrials.gov NCT05948670; https://clinicaltrials.gov/study/NCT05948670}
}
@article{BARROSO2025501667,
title = {Application of generative artificial intelligence chatbots in the field of anesthesia},
journal = {Revista Española de Anestesiología y Reanimación (English Edition)},
volume = {72},
number = {6},
pages = {501667},
year = {2025},
issn = {2341-1929},
doi = {https://doi.org/10.1016/j.redare.2025.501667},
url = {https://www.sciencedirect.com/science/article/pii/S2341192925001179},
author = {A. Barroso and R. Casans}
}
@article{RIANTO2025104427,
title = {Generative artificial intelligence for fire scenario analysis in complex building design layouts},
journal = {Fire Safety Journal},
volume = {155},
pages = {104427},
year = {2025},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2025.104427},
url = {https://www.sciencedirect.com/science/article/pii/S0379711225000918},
author = {Shandy Rianto and Yanfu Zeng and Xinyan Huang and Xinzheng Lu},
keywords = {Intelligent design, Fire safety engineering, Generative AI, Building fire simulation, Computational fluid dynamics},
abstract = {Performance-based fire safety design requires thoroughly evaluating building fire scenarios to ensure comprehensive fire safety. However, conventional Computational Fluid Dynamics (CFD) fire simulations are computationally intensive and time-consuming, limiting the number of scenarios that can be practically analyzed. This study addresses these challenges by using generative artificial intelligence (AI) to predict fire scenes in realistic multi-room building layouts, characterized by complex shapes and intricate wall partitions. Three generative AI models for image generation are employed for this purpose: GAN-based pix2pix and pix2pixHD, as well as the diffusion model. These models were trained on an extensive dataset of CFD fire simulations to generate near-ceiling smoke movement and temperature distribution outcomes. When tested on new unseen building layouts, these models demonstrated remarkable accuracy and provided near real-time assessments. The diffusion model achieved the highest accuracy (>94 %) while requiring the more computational time. The high performance of these models highlights the potential of using generative AI to enhance fire safety engineering by enabling faster and more comprehensive fire risk assessments.}
}
@article{PAN2025110175,
title = {Enhanced feedback analysis of vertical load reliability parameters for airplane landing gear using an improved generative adversarial network and explainable artificial intelligence techniques},
journal = {Engineering Applications of Artificial Intelligence},
volume = {145},
pages = {110175},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110175},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625001757},
author = {Weihuang Pan and Yunwen Feng and Cheng Lu and Jiaqi Liu and Jingcui Liang},
keywords = {Landing gear vertical load, Operation reliability, Improved generative adversarial Network, Explainable artificial intelligence, Feedback analysis, Shapley Additive explanations, Data generation},
abstract = {Effective feedback analysis of critical equipment data is essential for improving performance and optimizing design parameters in aviation systems. This study presents a novel framework that integrates an improved generative adversarial network (GAN) with explainable artificial intelligence techniques (XAI) to evaluate the reliability of the vertical load for airplane landing gear. By utilizing limited data from the Quick Access Recorder (QAR), the improved GAN generates extensive synthetic data to expand the dataset and strengthen the analysis. Each parameter's importance and influence on vertical load reliability are then evaluated through the Shapley Additive Explanations (SHAP) method, a key approach in XAI. Validation using landing gear data from a typical civil airplane demonstrates the effectiveness of this method and confirms the viability of explainable artificial intelligence for parametric feedback analysis. The results highlight the impact of each parameter on vertical load reliability, providing valuable insights to support enhanced design and operational efficiency of landing gear.}
}
@article{TAIWO2025100316,
title = {Making waves: Generative artificial intelligence in water distribution networks: Opportunities and challenges},
journal = {Water Research X},
volume = {28},
pages = {100316},
year = {2025},
issn = {2589-9147},
doi = {https://doi.org/10.1016/j.wroa.2025.100316},
url = {https://www.sciencedirect.com/science/article/pii/S2589914725000155},
author = {Ridwan Taiwo and Abdul-Mugis Yussif and Tarek Zayed},
keywords = {Digital water systems, Generative artificial intelligence, Smart water distribution networks, Retrieval-augmented generation, ChatGPT, Reclaimed WDNs, RAG, Multimodal AI},
abstract = {Water distribution networks (WDNs) face increasing challenges from aging infrastructure, population growth, and climate change, necessitating innovative technological solutions. This study examines the integration of Generative Artificial Intelligence (GenAI) in WDNs, including both conventional and reclaimed water systems. Through a comprehensive analysis of current literature and emerging applications, the study identifies key opportunities in near-future applications focusing on enhancing information retrieval through advanced document processing, improving water quality management via real-time monitoring and visualization, implementing predictive maintenance strategies through pattern recognition, and optimizing real-time operational control through adaptive algorithms. Results also demonstrate that GenAI can transform WDN operations through advanced visualization, scenario generation, and adaptive optimization capabilities, particularly in far-future applications such as demand forecasting, emergency response, and network design optimization. The analysis reveals significant challenges, including data quality and availability issues, particularly in non-English speaking regions, scalability constraints in large-scale networks, the critical need for water professionals with hybrid expertise in both traditional engineering and AI systems, and complex regulatory requirements that vary significantly across the globe. The study also explores unique applications in reclaimed WDNs, particularly in quality control, treatment optimization, and stakeholder engagement. These findings provide water utilities, policymakers, and researchers with valuable insights for implementing GenAI technologies while balancing technological advancement with human expertise and social responsibility.}
}