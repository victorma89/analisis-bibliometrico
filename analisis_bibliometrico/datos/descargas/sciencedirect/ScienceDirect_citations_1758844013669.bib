@article{HABER2024,
title = {The Artificial Third: A Broad View of the Effects of Introducing Generative Artificial Intelligence on Psychotherapy},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/54781},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000544},
author = {Yuval Haber and Inbar Levkovich and Dorit Hadar-Shoval and Zohar Elyoseph},
keywords = {psychoanalysis, generative artificial intelligence, psychotherapy, large language models, narcissism, narcissist, narcissistic, perception, perceptions, critical thinking, transparency, autonomy, mental health, interpersonal, LLM, LLMs, language model, language models, artificial intelligence, generative, AI, ethic, ethics, ethical},
abstract = {This paper explores a significant shift in the field of mental health in general and psychotherapy in particular following generative artificial intelligence’s new capabilities in processing and generating humanlike language. Following Freud, this lingo-technological development is conceptualized as the “fourth narcissistic blow” that science inflicts on humanity. We argue that this narcissistic blow has a potentially dramatic influence on perceptions of human society, interrelationships, and the self. We should, accordingly, expect dramatic changes in perceptions of the therapeutic act following the emergence of what we term the artificial third in the field of psychotherapy. The introduction of an artificial third marks a critical juncture, prompting us to ask the following important core questions that address two basic elements of critical thinking, namely, transparency and autonomy: (1) What is this new artificial presence in therapy relationships? (2) How does it reshape our perception of ourselves and our interpersonal dynamics? and (3) What remains of the irreplaceable human elements at the core of therapy? Given the ethical implications that arise from these questions, this paper proposes that the artificial third can be a valuable asset when applied with insight and ethical consideration, enhancing but not replacing the human touch in therapy.}
}
@article{PARK20242355,
title = {Has generative artificial intelligence solved inverse materials design?},
journal = {Matter},
volume = {7},
number = {7},
pages = {2355-2367},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400242X},
author = {Hyunsoo Park and Zhenzhu Li and Aron Walsh},
abstract = {Summary
The directed design and discovery of compounds with pre-determined properties is a long-standing challenge in materials research. We provide a perspective on progress toward achieving this goal using generative models for chemical compositions and crystal structures based on a set of powerful statistical techniques drawn from the artificial intelligence community. We introduce the central concepts underpinning generative models of crystalline materials. Coverage is provided of early implementations for inorganic crystals based on generative adversarial networks and variational autoencoders through to ongoing progress involving autoregressive and diffusion models. The influence of the choice of chemical representation and the generative architecture is discussed, along with metrics for quantifying the quality of the hypothetical compounds produced. While further developments are required to enable realistic predictions drawn from richer structure and property datasets, generative artificial intelligence is already proving to be complementary to traditional materials design strategies.}
}
@article{WAISBERG20251,
title = {Generative artificial intelligence in ophthalmology},
journal = {Survey of Ophthalmology},
volume = {70},
number = {1},
pages = {1-11},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000444},
author = {Ethan Waisberg and Joshua Ong and Sharif Amit Kamran and Mouayad Masalkhi and Phani Paladugu and Nasif Zaman and Andrew G. Lee and Alireza Tavakkoli},
keywords = {Generative adversarial networks, Deep learning, ChatGPT, GPT4, Artificial ophthalmic image synthesis, AI, Machine learning},
abstract = {Generative artificial intelligence (AI) has revolutionized medicine over the past several years. A generative adversarial network (GAN) is a deep learning framework that has become a powerful technique in medicine, particularly in ophthalmology for image analysis. In this paper we review the current ophthalmic literature involving GANs, and highlight key contributions in the field. We briefly touch on ChatGPT, another application of generative AI, and its potential in ophthalmology. We also explore the potential uses for GANs in ocular imaging, with a specific emphasis on 3 primary domains: image enhancement, disease identification, and generating of synthetic data. PubMed, Ovid MEDLINE, Google Scholar were searched from inception to October 30, 2022, to identify applications of GAN in ophthalmology. A total of 40 papers were included in this review. We cover various applications of GANs in ophthalmic-related imaging including optical coherence tomography, orbital magnetic resonance imaging, fundus photography, and ultrasound; however, we also highlight several challenges that resulted in the generation of inaccurate and atypical results during certain iterations. Finally, we examine future directions and considerations for generative AI in ophthalmology.}
}
@article{CHARLES2025177508,
title = {AI in action: Changes to student perceptions when using generative artificial intelligence for the creation of a multimedia project-based assessment},
journal = {European Journal of Pharmacology},
volume = {998},
pages = {177508},
year = {2025},
issn = {0014-2999},
doi = {https://doi.org/10.1016/j.ejphar.2025.177508},
url = {https://www.sciencedirect.com/science/article/pii/S0014299925002626},
author = {Kellie A. Charles and Arsalan Yousuf and Han Chow Chua and Slade Matthews and Joanna Harnett and Tina Hinton},
keywords = {Science education, Pharmacology education, Artificial intelligence, AI, ChatGPT},
abstract = {Introduction
New modes of assessments are needed to evaluate of the authenticity of student learning in an artificial intelligence (AI) world. In mid-2023, we piloted a new assessment type; a collaborative group multimedia assessment with AI allowance. The aim of the research study was to explore the experiences of students using AI in a multimedia assessment. We further aimed to determine whether these use cases changed student perceptions of the ways AI can be used in learning and assessment.
Methods
Students enrolled in a capstone Pharmacology interdisciplinary unit (n = 40) were included in an exploratory, qualitative case study methodology. Thematic analysis using an AI role-based conceptual framework was used to explore student perceptions of AI use prior to and during their projects from logbooks documenting the assessment process.
Results
AI was initially perceived by students as having a personal tutor-style role, which aligned with the taxonomy with AI acting as an Arbiter (49 %), Oracle (41 %) and Quant (10 %). In contrast to their earlier perceptions, AI was only used in a limited manner in the early stages of assessment in the idea generation in the role as an Oracle (86 %) or in data analytic purposes as a Quant (14 %), (n = 14 cases in 5 groups). No student group used AI to generate written text for the final assessment.
Discussion
Tension between perceived and actual use of AI is indicative of the uncertainty faced by students with the allowance of AI within assessments. Clear guidance for educators and students about how to assess the AI-supported learning process is needed to ensure the integrity of the assessment system.}
}
@article{DEMIREL2025101127,
title = {Late gadolinium enhancement cardiovascular magnetic resonance with generative artificial intelligence},
journal = {Journal of Cardiovascular Magnetic Resonance},
volume = {27},
number = {1},
pages = {101127},
year = {2025},
issn = {1097-6647},
doi = {https://doi.org/10.1016/j.jocmr.2024.101127},
url = {https://www.sciencedirect.com/science/article/pii/S1097664724011542},
author = {Omer Burak Demirel and Fahime Ghanbari and Christopher W. Hoeger and Connie W. Tsao and Adele Carty and Long H. Ngo and Patrick Pierce and Scott Johnson and Kathryn Arcand and Jordan Street and Jennifer Rodriguez and Tess E. Wallace and Kelvin Chow and Warren J. Manning and Reza Nezafat},
keywords = {Late gadolinium enhancement, Highly accelerated, Deep learning},
abstract = {ABSTRACT
Background
Late gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) imaging enables imaging of scar/fibrosis and is a cornerstone of most CMR imaging protocols. CMR imaging can benefit from image acceleration; however, image acceleration in LGE remains challenging due to its limited signal-to-noise ratio. In this study, we sought to evaluate a rapid two-dimensional (2D) LGE imaging protocol using a generative artificial intelligence (AI) algorithm with inline reconstruction.
Methods
A generative AI-based image enhancement was used to improve the sharpness of 2D LGE images acquired with low spatial resolution in the phase-encode direction. The generative AI model is an image enhancement technique built on the enhanced super-resolution generative adversarial network. The model was trained using balanced steady-state free-precession cine images, readily used for LGE without additional training. The model was implemented inline, allowing the reconstruction of images on the scanner console. We prospectively enrolled 100 patients (55 ± 14 years, 72 males) referred for clinical CMR at 3T. We collected three sets of LGE images in each subject, with in-plane spatial resolutions of 1.5 × 1.5-3-6 mm2. The generative AI model enhanced in-plane resolution to 1.5 × 1.5 mm2 from the low-resolution counterparts. Images were compared using a blur metric, quantifying the perceived image sharpness (0 = sharpest, 1 = blurriest). LGE image sharpness (using a 5-point scale) was assessed by three independent readers.
Results
The scan times for the three imaging sets were 15 ± 3, 9 ± 2, and 6 ± 1 s, with inline generative AI-based images reconstructed time of ∼37 ms. The generative AI-based model improved visual image sharpness, resulting in lower blur metric compared to low-resolution counterparts (AI-enhanced from 1.5 × 3 mm2 resolution: 0.3 ± 0.03 vs 0.35 ± 0.03, P < 0.01). Meanwhile, AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images showed similar blur metric (0.30 ± 0.03 vs 0.31 ± 0.03, P = 1.0) Additionally, there was an overall 18% improvement in image sharpness between AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images in the subjective blurriness score (P < 0.01).
Conclusion
The generative AI-based model enhances the image quality of 2D LGE images while reducing the scan time and preserving imaging sharpness. Further evaluation in a large cohort is needed to assess the clinical utility of AI-enhanced LGE images for scar evaluation, as this proof-of-concept study does not provide evidence of an impact on diagnosis.}
}
@article{ZHAO2024100043,
title = {Advancing microplastic analysis in the era of artificial intelligence: From current applications to the promise of generative AI},
journal = {Nexus},
volume = {1},
number = {4},
pages = {100043},
year = {2024},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2024.100043},
url = {https://www.sciencedirect.com/science/article/pii/S295016012400041X},
author = {Bu Zhao and Ruth E. Richardson and Fengqi You},
keywords = {microplastics, artificial intelligence, machine learning, deep learning, generative AI},
abstract = {Summary
The proliferation of microplastics (MPs) in aquatic and terrestrial environments poses significant threats to ecosystems and human health. Over the past 20 years, significant efforts have been dedicated to understanding the distribution, sources, and impacts of MPs. However, traditional methods for the detection and analysis of MPs rely on labor-intensive and time-consuming techniques, often lacking the needed precision. Recently, artificial intelligence (AI) has emerged as a transformative tool in environmental science, offering innovative solutions to enhance the efficiency and accuracy of MP analysis. Despite significant scientific advancements, there is a lack of critical review that consolidates the key applications of AI in MP analysis, synthesizes knowledge gained, and navigates for future research directions. This review is the first to thoroughly explore the exciting role of AI across the entire life cycle of MP analysis—from collection to characterization, dynamic modeling, impact assessment, and management of MP pollution. Specifically, AI-driven autonomous drones and robotics have emerged as promising solutions to revolutionize MP collection practices. Computer vision systems provide robust solutions for the identification and quantification of MPs in diverse environmental matrices. Additionally, data-driven modeling using machine-learning and deep-learning techniques facilitates accurate evaluation of MP pollution levels and their impacts, facilitating the design of effective management strategies. Despite these advancements, several knowledge gaps remain, including data scarcity and quality issues; the readiness of the AI models; and model interpretability, transparency, and reproducibility issues. Addressing these gaps requires the development of standardized protocols for improved data infrastructure, the adoption of more advanced and groundbreaking AI tools (such as generative AI), and the encouraging of multidisciplinary collaborations. Through these efforts, AI has the potential to revolutionize MP research, leading to a more comprehensive and effective response to MP pollution.}
}
@article{BERA20258735,
title = {Accurate prediction of the kinetic sequence of physicochemical states using generative artificial intelligence††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d5sc00108k},
journal = {Chemical Science},
volume = {16},
number = {20},
pages = {8735-8751},
year = {2025},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d5sc00108k},
url = {https://www.sciencedirect.com/science/article/pii/S2041652025006327},
author = {Palash Bera and Jagannath Mondal},
abstract = {Capturing the time evolution and predicting kinetic sequences of states of physicochemical systems present significant challenges due to the precision and computational effort required. In this study, we demonstrate that ‘Generative Pre-trained Transformer (GPT)’, an artificial intelligence model renowned for machine translation and natural language processing, can be effectively adapted to predict the dynamical state-to-state transition kinetics of biologically relevant physicochemical systems. Specifically, by using sequences of time-discretized states from Molecular Dynamics (MD) simulation trajectories akin to the vocabulary corpus of a language, we show that a GPT-based model can learn the complex syntactic and semantic relationships within the trajectory. This enables GPT to predict kinetically accurate sequences of states for a diverse set of biomolecules of varying complexity, at a much quicker pace than traditional MD simulations and with a better efficiency than other baseline time-series prediction approaches. More significantly, the approach is found to be equally adept at forecasting the time evolution of out-of-equilibrium active systems that do not maintain detailed balance. An analysis of the mechanism inherent in GPT reveals the crucial role of the ‘self-attention mechanism’ in capturing the long-range correlations necessary for accurate state-to-state transition predictions. Together, our results highlight generative artificial intelligence's ability to generate kinetic sequences of states of physicochemical systems with statistical precision.}
}
@article{GOFMAN2025S260,
title = {HTA74 Transforming Global Value Dossier (GVD) Drafting: Creation with a Generative Artificial Intelligence (Gen AI)-Driven Coauthoring Accelerator},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S260},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1085},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525012100},
author = {Larisa Gofman and Jevin G. Meyerink and Sheetal Sharma}
}
@article{WENG2024100315,
title = {Personality traits for self-regulated learning with generative artificial intelligence: The case of ChatGPT},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100315},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100315},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001188},
author = {Xiaojing Weng and Qi Xia and Zubair Ahmad and Thomas K.F. Chiu},
keywords = {GenAI, Personality traits, Self-regulated learning, Instructional design, Higher education},
abstract = {Personality traits and educational technology may affect how well students utilise their abilities and strategies to achieve their learning objectives and potential. As generative artificial intelligence (GenAI) is creating new learning experiences, understanding the impact of five representative personality traits on students' self-regulated learning (SRL) while learning with GenAI tools can help to predict which personality traits indicate better self-regulation when learning with this innovative educational technology. Such a prediction can help educators to design effective learning activities by providing educational experiences that cater to students' different personality traits for specific learning objectives in the GenAI context. This study explored how variations in five representative personality traits affect students’ SRL performance when learning with ChatGPT. It used an explanatory approach based on structural equation modelling with a path analysis design. Four hundred and nine university students participated in the study and finished a self-reported questionnaire with validated items that are driven by previous studies. The results revealed that the personality traits of openness, extraversion, and agreeableness were significant predictors of all three stages of SRL; conscientiousness was a significant predictor of the forethought and self-reflection stages; and neuroticism failed to predict any of the three stages of SRL. These results may be attributable to the subjective nature of personality traits and the cognitive characteristics of SRL skills. The findings enrich the literature on SRL by introducing personality traits and GenAI as innovative perspectives and suggesting corresponding strategies for supporting different stages of SRL.}
}
@article{BARCAUI2023100101,
title = {Who is better in project planning?Generative artificial intelligence or project managers?},
journal = {Project Leadership and Society},
volume = {4},
pages = {100101},
year = {2023},
issn = {2666-7215},
doi = {https://doi.org/10.1016/j.plas.2023.100101},
url = {https://www.sciencedirect.com/science/article/pii/S2666721523000224},
author = {André Barcaui and André Monat},
keywords = {Generative, Artificial intelligence, Project management},
abstract = {This paper presents a comparative study of generative artificial intelligence (AI), specifically the GPT-4 model, and a human project manager in the context of a project plan development. The study's objective was to analyze the content and structure of a project plan prepared by this disruptive new technology and its human counterpart, focusing on the digital technology sector. Through a primarily qualitative methodology, the study scrutinizes critical aspects of each part of the project plan, including scope preparation, schedule development, cost estimation, resources evaluation, quality planning, stakeholder mapping, communication planning, and risk analysis. The results indicate unique strengths and weaknesses for both AI-generated and human-generated project plans, revealing them as complementary in the project planning process. It also emphasizes the continued importance of human expertise in refining AI outputs and harnessing the full potential of AI through the process known as prompt engineering. In conclusion, this study illustrates the potential synergy between human experience and AI in project planning, suggesting the careful integration of human and AI capabilities is key to developing robust and trustworthy project plans.}
}
@article{ARCEURRIZA2025104234,
title = {From familiarity to acceptance: The impact of Generative Artificial Intelligence on consumer adoption of retail chatbots},
journal = {Journal of Retailing and Consumer Services},
volume = {84},
pages = {104234},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104234},
url = {https://www.sciencedirect.com/science/article/pii/S096969892500013X},
author = {Marta Arce-Urriza and Raquel Chocarro and Mónica Cortiñas and Gustavo Marcos-Matás},
keywords = {Generative artificial intelligence, Chatbot adoption, Retail technology, Consumer familiarity, Privacy risk, Service robot acceptance model (SRAM)},
abstract = {This study investigates the influence of Generative Artificial Intelligence (GenAI) on consumer adoption of retail chatbots, focusing on how GenAI impacts key adoption determinants, the role of familiarity and assessing its effects across different stages of the customer journey. We conducted two waves of surveys, one pre- and one post-GenAI integration, to compare consumer perceptions across three customer service tasks. Using the Service Robot Acceptance Model (SRAM) as a framework, we found that GenAI enhances consumer perceptions of chatbot usefulness, human-likeness, and familiarity, thereby increasing adoption intentions. However, trust remains largely unchanged, and privacy concerns have risen post-GenAI. Additionally, the relationships remain stable across customer journey stages, with familiarity playing a key role. Our findings extend SRAM to the retail context with GenAI, offering new insights into the temporal stability of chatbot adoption factors. It underscores familiarity's dual role (direct and indirect) in fostering adoption, while highlighting that GenAI impacts specific aspects of consumer interaction. These findings provide insights for retailers to leverage GenAI-powered chatbots to enhance customer engagement and satisfaction.}
}
@article{GUPTA2024100232,
title = {Adoption and impacts of generative artificial intelligence: Theoretical underpinnings and research agenda},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {1},
pages = {100232},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000211},
author = {Ruchi Gupta and Kiran Nair and Mahima Mishra and Blend Ibrahim and Seema Bhardwaj},
keywords = {ChatGPT, Adoption, Generative AI, Chatbots},
abstract = {Large language models (LLMs) have received considerable interest in the field of natural language processing (NLP) owing to their remarkable ability to generate clear, consistent, and contextually relevant materials. Among the numerous LLMs, ChatGPT (Generative Pre-trained Transformer for Chatbots) is emerging as a prominent prospective tool for developing conversational agents such as chatbots. However, there is a need for a clear conceptual understanding of ChatGPT's potential implications for the industry and its role in marketing. This study explores the adoption of ChatGPT in marketing and examines theories that may influence its adoption by marketers and consumers, as well as its implications for marketers. This study discusses how ChatGPT may allow for more personalized and engaging content, better customer experience, and improved ROI. However, adoption also brings challenges, including ethical considerations and the need for new skill development. This study also discusses future research opportunities for the adoption of ChatGPT and other generative artificial intelligence technologies in marketing. The goal is to provide insights for organizations that consider implementing these technologies, and to contribute to the literature on the adoption of Artificial Intelligence (AI) and the use of Generative AI in marketing.}
}
@article{BRUNS2024103790,
title = {Do you create your content yourself? Using generative artificial intelligence for social media content creation diminishes perceived brand authenticity},
journal = {Journal of Retailing and Consumer Services},
volume = {79},
pages = {103790},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103790},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924000869},
author = {Jasper David Brüns and Martin Meißner},
keywords = {Generative artificial intelligence, Content creation, Brand authenticity, Algorithm aversion, Social media},
abstract = {Recent studies have demonstrated the potential of generative artificial intelligence (GenAI) in enhancing marketing content. However, its impact on consumer behavior has remained empirically untested. In response to social media platforms mandating the disclosure of GenAI content, we investigate how followers perceive brands that use GenAI for content creation. Drawing from literature on algorithm aversion and brand authenticity, the results of three experimental studies indicate that brands' GenAI adoption induces negative attitudinal and behavioral follower reactions. These effects are mediated by followers' perceptions of brand authenticity and can be triggered by GenAI disclosure. Negative reactions are attenuated if GenAI is used to assist humans in content creation rather than to replace them through automation. Our findings underscore the need for nuance in brands’ GenAI adoption to unlock economic benefits without compromising on relationships with consumers.}
}
@article{MOULAEI2024105474,
title = {Generative artificial intelligence in healthcare: A scoping review on benefits, challenges and applications},
journal = {International Journal of Medical Informatics},
volume = {188},
pages = {105474},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105474},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001370},
author = {Khadijeh Moulaei and Atiye Yadegari and Mahdi Baharestani and Shayan Farzanbakhsh and Babak Sabet and Mohammad {Reza Afrash}},
keywords = {Generative artificial intelligence, Health, Artificial intelligence},
abstract = {Background
Generative artificial intelligence (GAI) is revolutionizing healthcare with solutions for complex challenges, enhancing diagnosis, treatment, and care through new data and insights. However, its integration raises questions about applications, benefits, and challenges. Our study explores these aspects, offering an overview of GAI's applications and future prospects in healthcare.
Methods
This scoping review searched Web of Science, PubMed, and Scopus . The selection of studies involved screening titles, reviewing abstracts, and examining full texts, adhering to the PRISMA-ScR guidelines throughout the process.
Results
From 1406 articles across three databases, 109 met inclusion criteria after screening and deduplication. Nine GAI models were utilized in healthcare, with ChatGPT (n = 102, 74 %), Google Bard (Gemini) (n = 16, 11 %), and Microsoft Bing AI (n = 10, 7 %) being the most frequently employed. A total of 24 different applications of GAI in healthcare were identified, with the most common being “offering insights and information on health conditions through answering questions” (n = 41) and “diagnosis and prediction of diseases” (n = 17). In total, 606 benefits and challenges were identified, which were condensed to 48 benefits and 61 challenges after consolidation. The predominant benefits included “Providing rapid access to information and valuable insights” and “Improving prediction and diagnosis accuracy”, while the primary challenges comprised “generating inaccurate or fictional content”, “unknown source of information and fake references for texts”, and “lower accuracy in answering questions”.
Conclusion
This scoping review identified the applications, benefits, and challenges of GAI in healthcare. This synthesis offers a crucial overview of GAI's potential to revolutionize healthcare, emphasizing the imperative to address its limitations.}
}
@article{HAASE2023100066,
title = {Artificial muses: Generative artificial intelligence chatbots have risen to human-level creativity},
journal = {Journal of Creativity},
volume = {33},
number = {3},
pages = {100066},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000250},
author = {Jennifer Haase and Paul H.P. Hanel},
keywords = {Creativity, Originality, AI, Generative artificial intelligence},
abstract = {A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: alpa.ai, Copy.ai, ChatGPT (versions 3 and 4), Studio.ai, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 % of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being “truly” creative.}
}
@article{BEWERSDORFF2025102601,
title = {Taking the next step with generative artificial intelligence: The transformative role of multimodal large language models in science education},
journal = {Learning and Individual Differences},
volume = {118},
pages = {102601},
year = {2025},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102601},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024001948},
author = {Arne Bewersdorff and Christian Hartmann and Marie Hornberger and Kathrin Seßler and Maria Bannert and Enkelejda Kasneci and Gjergji Kasneci and Xiaoming Zhai and Claudia Nerdel},
keywords = {Artificial Intelligence, Large Language Models (LLMs), ChatGPT, Multimodal learning, Cognitive Theory of Multimedia Learning, Science education},
abstract = {The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences. However, the advent of Multimodal Large Language Models (MLLMs) like GPT-4 Vision, capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. This paper derives a theoretical framework for integrating MLLMs into multimodal learning. This framework serves to explore the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios. Possible applications for MLLMs range from content creation to tailored support for learning, fostering engagement in scientific practices, and providing assessments and feedback. These applications are not limited to text-based and uni-modal formats but can be multimodal, thus increasing personalization, accessibility, and potential learning effectiveness. Despite the many opportunities, challenges such as data protection and ethical considerations become salient, calling for robust frameworks to ensure responsible integration. This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educators' roles, ensuring an effective and ethical use of AI in science education. It calls for further research to explore the nuanced implications of MLLMs for educators and to extend the discourse beyond science education to other disciplines. Through developing a theoretical framework for the integration of MLLMs into multimodal learning and exploring the associated potentials, challenges, and future implications, this paper contributes to a preliminary examination of the transformative role of MLLMs in science education and beyond.}
}
@article{ASSAD2024677,
title = {Enhancing sustainability in manufacturing through cognitive digital twins powered by generative artificial intelligence},
journal = {Procedia CIRP},
volume = {130},
pages = {677-682},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.147},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124013040},
author = {Fadi Assad and John Patsavellas and Konstantinos Salonitis},
keywords = {ChatGPT, Cognitive manufacturing, digital twin, generative artificial intelligence, Internet of Things, sustainable manufacturing},
abstract = {The rise of Industry 4.0 has brought new advancements in manufacturing, with a focus on integrating digital technologies to optimise processes and increase sustainability. Cognitive Digital Twins (CDTs) are emerging as a powerful paradigm in this area. They leverage advanced analytics, artificial intelligence (AI), and machine learning to create dynamic, real-time representations of physical manufacturing systems. This paper explores how CDTs can improve sustainability within the manufacturing sector. It proposes integrating generative artificial intelligence (GenAI) into the platforms that operate these digital twins to grant them cognitive capabilities. The work introduces a method for mapping and integrating energy consumption data to an Internet of Things (IoT) platform that includes the digital twin and a generative AI language model, such as ChatGPT. This proposed approach serves as a stepping stone towards unlocking the full potential of CDTs. It empowers manufacturers to achieve higher levels of sustainability and environmental responsibility.}
}
@article{MAYOL2025109496,
title = {Generative artificial intelligence and scientific publishing: Turning noise into trust},
journal = {Surgery},
volume = {183},
pages = {109496},
year = {2025},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2025.109496},
url = {https://www.sciencedirect.com/science/article/pii/S0039606025003484},
author = {Julio Mayol and Caitlin W. Hicks and Steven D. Wexner}
}
@article{RAWLINSON2025,
title = {Generative Artificial Intelligence to Automate the Adaptation of Excel Health Economic Models and Word Technical Reports},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S109830152502399X},
author = {William Rawlinson and Siguroli Teitsson and Tim Reason and Bill Malcolm and Andy Gimblett and Sven L. Klijn},
keywords = {artificial intelligence, large language models},
abstract = {Objectives
In health economics and outcomes research (HEOR), many repetitive tasks could be performed by large language models (LLMs), including adapting Excel-based health economic models and associated Word technical reports to a new setting. However, it is vital to develop robust methods so that the LLM delivers at least human-level accuracy.
Methods
We developed LLM-based pipelines to automate parameter value adaptations for Excel-based models and subsequent reporting of the model results. Chain-of-thought prompting, ensemble shuffling, and task decomposition were used to enhance the accuracy of the LLM-generated content. We tested the pipelines by adapting 3 Excel-based models (2 cost-effectiveness models [CEMs] and 1 budget impact model [BIM]) and their associated technical reports. The quality of reporting was evaluated by 2 expert health economists.
Results
The accuracy of parameter value adaptations was 100% (147 of 147), 100% (207 of 207), and 98.7% (158 of 160) for the 2 CEMs and 1 budget impact model, respectively. The parameter value adaptations were performed without human intervention in 195 seconds, 245 seconds, and 189 seconds. For parameter value adaptations, the application programming interface costs associated with running the pipeline were $13.36, $6.48, and $2.65. The accuracy of report adaptations was 94.4% (17 of 18), 100% (54 of 54), and 95.1% (39 of 41), respectively. The report adaptations were performed in 128 seconds, 336 seconds, and 286 seconds. For report adaptations, the application programming interface costs associated with running the pipeline were $1.53, $4.24, and $4.05.
Conclusions
LLM-based toolchains have the potential to accurately and rapidly perform routine adaptations of Excel-based CEMs and technical reports at a low cost. This could expedite health technology assessments and improve patient access to new treatments.}
}
@article{ANNA2025105129,
title = {AI-driven digital humans for E-contact: A pre-registered study on reducing intergroup bias with generative artificial intelligence},
journal = {Acta Psychologica},
volume = {258},
pages = {105129},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105129},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825004421},
author = {Manfredi Anna and Puzella Giulio and David Landi and Iolanda Iacono and Jacopo Michilli and Gabbiadini Alessandro},
keywords = {E-contact interventions, Prejudice reduction, Artificial intelligence, Intergroup relations, intergroup contact},
abstract = {The present pre-registered report explores the potential of AI-driven contact interventions by integrating generative Artificial Intelligence-based artificial humans into E-contact paradigms. Grounded in Allport's (1954) Contact Hypothesis and the Dual Identity Model (DIM; Gaertner & Dovidio, 2000), the study examines whether structured interactions with artificial humans can foster positive intergroup attitudes. Following the framework of E-contact interventions (White & Abu-Rayya, 2012), participants (N = 70 Caucasian university students) will engage in a within-between mixed-design experiment over three days. They will interact daily with an AI-powered 3D digital assistant representing either an outgroup member (Black avatar) or an ingroup member (White avatar) depending on the experimental condition, with pre- and post-intervention measures of intergroup attitudes. The structured interactions will follow the two-phase design of E-contact interventions, initially fostering personal acquaintance, then emphasizing group salience, and finally reinforcing a shared superordinate identity—a process aligned with the principles of DIM to maximize the generalization of positive intergroup attitudes. The virtual assistant will facilitate cooperative activities designed to enhance inclusivity, promote cultural exchange, and maintain subgroup distinctiveness while fostering a common identity. To ensure the effectiveness and coherence of the intervention, the scripted interactions will be pretested through a pilot study before implementation. This research offers a preliminary step toward understanding how artificial intelligence might contribute to enhancing E-contact interventions, potentially providing scalable and structured tools for fostering positive intergroup relations and supporting social integration.}
}
@article{RESELFOLKERSMA2025S1749,
title = {A0902 – Evaluation of the quality of the responses regarding Lower Urinary Tract Symptoms (LUTS) of different generative Artificial Intelligence (AI) App in comparison with UrologuIA (generative AI App developed by urologists and urogynecologists)},
journal = {European Urology},
volume = {87},
pages = {S1749},
year = {2025},
note = {Abstracts EAU25 - 40th Annual EAU Congress},
issn = {0302-2838},
doi = {https://doi.org/10.1016/j.eururo.2025.09.4082},
url = {https://www.sciencedirect.com/science/article/pii/S0302283825045919},
author = {L. {Resel Folkersma} and B. {Padilla Fernández} and C. {González Enguita} and J.L. Gago and M. {García Sanz} and P. {Blasco Hernández} and R. Vozmediano and S. Arlandis and S. Zubillaga and J. {Medina Polo}}
}
@article{KATHAIT20241575,
title = {Assessing Laterality Errors in Radiology: Comparing Generative Artificial Intelligence and Natural Language Processing},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {10},
pages = {1575-1582},
year = {2024},
note = {Focus on Innovation},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S154614402400591X},
author = {Anjaneya Singh Kathait and Emiliano Garza-Frias and Tejash Sikka and Thomas J. Schultz and Bernardo Bizzo and Mannudeep K. Kalra and Keith J. Dreyer},
keywords = {generative AI, large language models, natural language processing, patient safety, radiology errors},
abstract = {Purpose
We compared the performance of generative artificial intelligence (AI) (Augmented Transformer Assisted Radiology Intelligence [ATARI, Microsoft Nuance, Microsoft Corporation, Redmond, Washington]) and natural language processing (NLP) tools for identifying laterality errors in radiology reports and images.
Methods
We used an NLP-based (mPower, Microsoft Nuance) tool to identify radiology reports flagged for laterality errors in its Quality Assurance Dashboard. The NLP model detects and highlights laterality mismatches in radiology reports. From an initial pool of 1,124 radiology reports flagged by the NLP for laterality errors, we selected and evaluated 898 reports that encompassed radiography, CT, MRI, and ultrasound modalities to ensure comprehensive coverage. A radiologist reviewed each radiology report to assess if the flagged laterality errors were present (reporting error—true-positive) or absent (NLP error—false-positive). Next, we applied ATARI to 237 radiology reports and images with consecutive NLP true-positive (118 reports) and false-positive (119 reports) laterality errors. We estimated accuracy of NLP and generative AI tools to identify overall and modality-wise laterality errors.
Results
Among the 898 NLP-flagged laterality errors, 64% (574 of 898) had NLP errors and 36% (324 of 898) were reporting errors. The text query ATARI feature correctly identified the absence of laterality mismatch (NLP false-positives) with a 97.4% accuracy (115 of 118 reports; 95% confidence interval [CI] = 96.5%-98.3%). Combined vision and text query resulted in 98.3% accuracy (116 of 118 reports or images; 95% CI = 97.6%-99.0%), and query alone had a 98.3% accuracy (116 of 118 images; 95% CI = 97.6%-99.0%).
Conclusion
The generative AI-empowered ATARI prototype outperformed the assessed NLP tool for determining true and false laterality errors in radiology reports while enabling an image-based laterality determination. Underlying errors in ATARI text query in complex radiology reports emphasize the need for further improvement in the technology.}
}
@article{CHONG2025103583,
title = {1345 A Generative Artificial Intelligence Framework for Automated Pathologic Diagnosis of Gastric Endoscopic Biopsy Samples},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103583},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103583},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032616},
author = {Yosep Chong and Anh Nguyen and Jin Sol Song and Kwangil Yim and Jumi Park and Jin Tae Kwak}
}
@article{HIDAYATULLAH2025100213,
title = {Exploring community pharmacist's psychological intentions to adopt generative artificial intelligence (GenAI) chatbots for patient information, education, and counseling},
journal = {Neuroscience Informatics},
volume = {5},
number = {3},
pages = {100213},
year = {2025},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2772528625000287},
author = {Hafidz Ihsan Hidayatullah and Muhammad Taufiq Saifullah and Muhammad Thesa Ghozali and Ayesha Aziz},
keywords = {Artificial intelligence, Communal pharmacy, Social intention, Procreative AI, Technology acceptance},
abstract = {Generative AI (GenAI) chatbots, driven by advanced machine learning algorithms, are emerging as transformative tools for enhancing patient education, information dissemination, and counseling (EIC) in healthcare. This study investigated the psychological determinants of community pharmacists' intentions to adopt GenAI chatbots using the Extended Technology Acceptance Model (ETAM). A cross-sectional survey of 240 licensed community pharmacists across several Indonesian provinces assessed key constructs, including self-efficacy (SE), perceived usefulness (PU), perceived ease of use (PEU), attitude toward technology (ATT), trust (TT), and behavioral intention (BI). Structural equation modeling revealed that SE significantly influenced PU (β=0.37) and PEU (β=0.57), indicating that confidence in using technology positively affects perceived utility and usability. PU further predicted ATT (β=0.39) and BI (β=0.236), emphasizing the motivational role of perceived benefits. Trust emerged as a crucial mediator, channeling favorable attitudes into actionable behavioral intentions (indirect β=0.148). The model demonstrated strong fit indices (χ2=263.09, RMSEA = 0.019, GFI = 0.915, CFI = 0.991), supporting the psychological framework. These findings highlight the importance of fostering trust, improving perceived usability, and enhancing self-efficacy through targeted training to promote GenAI chatbot adoption. Future research should explore longitudinal behavioral changes and contextual influences to support sustainable AI integration in pharmacy practice.}
}
@article{LUSETTI2025S250,
title = {T.06.3 APPLICATIONS OF GENERATIVE ARTIFICIAL INTELLIGENCE IN INFLAMMATORY BOWEL DISEASE: A SYSTEMATIC REVIEW},
journal = {Digestive and Liver Disease},
volume = {57},
pages = {S250-S251},
year = {2025},
note = {Abstracts of the 31st National Congress of Digestive Diseases, FISMAD},
issn = {1590-8658},
doi = {https://doi.org/10.1016/S1590-8658(25)00603-6},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825006036},
author = {F. Lusetti and S. Maimaris and G.P. {La Rosa} and D. Scalvini and A. Schiepatti and F. Biagi and G. Manes and S. Saibeni}
}
@article{MORTLOCK2024100481,
title = {Generative artificial intelligence (Gen-AI) in pharmacy education: Utilization and implications for academic integrity: A scoping review},
journal = {Exploratory Research in Clinical and Social Pharmacy},
volume = {15},
pages = {100481},
year = {2024},
issn = {2667-2766},
doi = {https://doi.org/10.1016/j.rcsop.2024.100481},
url = {https://www.sciencedirect.com/science/article/pii/S2667276624000787},
author = {R. Mortlock and C. Lucas},
keywords = {Artificial intelligence, Academic integrity, ChatGPT, Pharmacy education, Machine learning},
abstract = {Introduction
Generative artificial intelligence (Gen-AI), exemplified by the widely adopted ChatGPT, has garnered significant attention in recent years. Its application spans various health education domains, including pharmacy, where its potential benefits and drawbacks have become increasingly apparent. Despite the growing adoption of Gen-AI such as ChatGPT in pharmacy education, there remains a critical need to assess and mitigate associated risks. This review exploresthe literature and potential strategies for mitigating risks associated with the integration of Gen-AI in pharmacy education.
Aim
To conduct a scoping review to identify implications of Gen-AI in pharmacy education, identify its use and emerging evidence, with a particular focus on strategies which mitigate potential risks to academic integrity.
Methods
A scoping review strategy was employed in accordance with the PRISMA-ScR guidelines. Databases searched includedPubMed, ERIC [Education Resources Information Center], Scopus and ProQuestfrom August 2023 to 20 February 2024 and included all relevant records from 1 January 2000 to 20 February 2024 relating specifically to LLM use within pharmacy education. A grey literature search was also conducted due to the emerging nature of this topic. Policies, procedures, and documents from institutions such as universities and colleges, including standards, guidelines, and policy documents, were hand searched and reviewed in their most updated form. These documents were not published in the scientific literature or indexed in academic search engines.
Results
Articles (n = 12) were derived from the scientific data bases and Records (n = 9) derived from the grey literature. Potential use and benefits of Gen-AI within pharmacy education were identified in all included published articles however there was a paucity of published articles related the degree of consideration to the potential risks to academic integrity. Grey literature recordsheld the largest proportion of risk mitigation strategies largely focusing on increased academic and student education and training relating to the ethical use of Gen-AI as well considerations for redesigning of current assessments likely to be a risk for Gen-AI use to academic integrity.
Conclusion
Drawing upon existing literature, this review highlights the importance of evidence-based approaches to address the challenges posed by Gen-AI such as ChatGPT in pharmacy education settings. Additionally, whilst mitigation strategies are suggested, primarily drawn from the grey literature, there is a paucity of traditionally published scientific literature outlining strategies for the practical and ethical implementation of Gen-AI within pharmacy education. Further research related to the responsible and ethical use of Gen-AI in pharmacy curricula; and studies related to strategies adopted to mitigate risks to academic integrity would be beneficial.}
}
@article{ABUMALLOH2024104128,
title = {Impact of generative artificial intelligence models on the performance of citizen data scientists in retail firms},
journal = {Computers in Industry},
volume = {161},
pages = {104128},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104128},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000563},
author = {Rabab Ali Abumalloh and Mehrbakhsh Nilashi and Keng Boon Ooi and Garry Wei Han Tan and Hing Kai Chan},
keywords = {Generative AI models, ChatGPT, Citizen Data science, Retail firms, Industrial growth, Industrial and innovation},
abstract = {Generative Artificial Intelligence (AI) models serve as powerful tools for organizations aiming to integrate advanced data analysis and automation into their applications and services. Citizen data scientists—individuals without formal training but skilled in data analysis—combine domain expertise with analytical skills, making them invaluable assets in the retail sector. Generative AI models can further enhance their performance, offering a cost-effective alternative to hiring professional data scientists. However, it is unclear how AI models can effectively contribute to this development and what challenges may arise. This study explores the impact of generative AI models on citizen data scientists in retail firms. We investigate the strengths, weaknesses, opportunities, and threats of these models. Survey data from 268 retail companies is used to develop and validate a new model. Findings highlight that misinformation, lack of explainability, biased content generation, and data security and privacy concerns in generative AI models are major factors affecting citizen data scientists’ performance. Practical implications suggest that generative AI can empower retail firms by enabling advanced data science techniques and real-time decision-making. However, firms must address drawbacks and threats in generative AI models through robust policies and collaboration between domain experts and AI developers.}
}
@incollection{FU2024,
title = {Generative artificial intelligence in operations},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-28993-4.00057-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443289934000573},
author = {Yingxuan Fu and Hing Kai Chan and Zhao Cai},
keywords = {Generative AI, , Generative adversarial network, Large language model, Transformer, Variational autoencoder},
abstract = {The rise of generative artificial intelligence (AI) may present a significant opportunity for a profound revolution in operations and supply chain management. However, such technological advancement is accompanied by a scholarly discourse that navigates the balance between its promising abilities and challenges. This chapter provides an overview of generative AI in operations and supply chain management. It begins by expositing its fundamental technical concepts and role alongside existing AI technologies. Subsequently, it delves into potential applications and challenges in implementing generative AI in operations. A future research agenda and takeaways for practitioners and Operations Management (OM) researchers are proposed at the end.}
}
@article{COHEN2025100405,
title = {A comparative analysis of generative artificial intelligence responses from leading chatbots to questions about endometriosis},
journal = {AJOG Global Reports},
volume = {5},
number = {1},
pages = {100405},
year = {2025},
issn = {2666-5778},
doi = {https://doi.org/10.1016/j.xagr.2024.100405},
url = {https://www.sciencedirect.com/science/article/pii/S2666577824000996},
author = {Natalie D. Cohen and Milan Ho and Donald McIntire and Katherine Smith and Kimberly A. Kho},
keywords = {chatbots, endometriosis education, health information technology, large language models, patient education, patient information},
abstract = {Introduction
The use of generative artificial intelligence (AI) has begun to permeate most industries, including medicine, and patients will inevitably start using these large language model (LLM) chatbots as a modality for education. As healthcare information technology evolves, it is imperative to evaluate chatbots and the accuracy of the information they provide to patients and to determine if there is variability between them.
Objective
This study aimed to evaluate the accuracy and comprehensiveness of three chatbots in addressing questions related to endometriosis and determine the level of variability between them.
Study Design
Three LLMs, including Chat GPT-4 (Open AI), Claude (Anthropic), and Bard (Google) were asked to generate answers to 10 commonly asked questions about endometriosis. The responses were qualitatively compared to current guidelines and expert opinion on endometriosis and rated on a scale by nine gynecologists. The grading scale included the following: (1) Completely incorrect, (2) mostly incorrect and some correct, (3) mostly correct and some incorrect, (4) correct but inadequate, (5) correct and comprehensive. Final scores were averaged between the nine reviewers. Kendall's W and the related chi-square test were used to evaluate the reviewers’ strength of agreement in ranking the LLMs’ responses for each item.
Results
Average scores for the 10 answers amongst Bard, Chat GPT, and Claude were 3.69, 4.24, and 3.7, respectively. Two questions showed significant disagreement between the nine reviewers. There were no questions the models could answer comprehensively or correctly across the reviewers. The model most associated with comprehensive and correct responses was ChatGPT. Chatbots showed an improved ability to accurately answer questions about symptoms and pathophysiology over treatment and risk of recurrence.
Conclusion
The analysis of LLMs revealed that, on average, they mainly provided correct but inadequate responses to commonly asked patient questions about endometriosis. While chatbot responses can serve as valuable supplements to information provided by licensed medical professionals, it is crucial to maintain a thorough ongoing evaluation process for outputs to provide the most comprehensive and accurate information to patients. Further research into this technology and its role in patient education and treatment is crucial as generative AI becomes more embedded in the medical field.}
}
@article{AWIDI2024100226,
title = {Comparing expert tutor evaluation of reflective essays with marking by generative artificial intelligence (AI) tool},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100226},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000274},
author = {Isaiah T. Awidi}
}
@article{SINGH2024100531,
title = {Characterizing generative artificial intelligence applications: Text-mining-enabled technology roadmapping},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100531},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000702},
author = {Shiwangi Singh and Surabhi Singh and Sascha Kraus and Anuj Sharma and Sanjay Dhir},
keywords = {Generative AI, Technology roadmapping, Patents, Text-mining, Structural topic modeling, Patent data mining},
abstract = {This study aims to identify generative AI (GenAI) applications and develop a roadmap for the near, mid, and far future. Structural topic modeling (STM) is used to discover latent semantic patterns and identify the key application areas from a text corpus comprising 2,398 patents published between 2017 and 2023. The study identifies six latent topics of GenAI application, including object detection and identification; medical applications; intelligent conversational agents; image generation and processing; financial and information security applications; and cyber-physical systems. Emergent topic terms are listed for each topic, and inter-topic correlations are explored to understand the thematic structures and summarize the semantic relationships among GenAI application areas. Finally, a technology roadmap is developed for each identified application area for the near, mid, and far future. This study provides valuable insights into the evolving GenAI landscape and helps practitioners make strategic business decisions based on the GenAI roadmap.}
}
@article{ZHANG2025S-318,
title = {1299: GENERATIVE ARTIFICIAL INTELLIGENCE FOR DYNAMIC RISK ASSESSMENT TO PREDICT TRAJECTORIES IN PATIENTS WITH ACUTE GASTROINTESTINAL BLEEDING IN THE INTENSIVE CARE UNIT},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-318},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01677-4},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525016774},
author = {Xi Zhang and Jun Yup Kim and Yuan Pu and Andrew J. Loza and Alexander Tong and Dennis Shung}
}
@article{BREWER2024525,
title = {Navigating the challenges of generative technologies: Proposing the integration of artificial intelligence and blockchain},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {525-535},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000569},
author = {Jordan Brewer and Dhru Patel and Dennie Kim and Alex Murray},
keywords = {Blockcain, Generative artificial intelligence (GenAI), ChatGPT, Large language models (LLMs), Chatbots},
abstract = {The transformative impact of generative AI (GenAI), extending beyond traditional AI, raises numerous concerns including the replacement of human roles and AI misuse in an array of industries. This article introduces blockchain technology as a complementary technological safeguard to address some of these challenges. We emphasize blockchain’s role in promoting transparency, verifiability, and decentralization in AI development and usage, thereby offering potential solutions for four distinct challenges: (1) AI toxicity, biases, hallucinations, (2) AI interest misalignment, (3) AI as a black box, and (4) AI misuse. This article proposes ways to ensure responsible and transparent AI usage through the integration of blockchain. We position the convergence of AI and blockchain as a means to manage AI’s societal impact and unlock its benefits—contingent upon collaborative efforts among various stakeholders such as businesses, developers, and regulatory bodies. We contribute to the discourse on ethical AI usage and the potential of blockchain to enhance AI’s reliability and accountability for organizations.}
}
@article{RAJARAM2024629,
title = {Generative artificial intelligence in small and medium enterprises: Navigating its promises and challenges},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {629-648},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000685},
author = {Kumaran Rajaram and Patrick Nicolas Tinguely},
keywords = {Generative artificial intelligence, Small and medium enterprises, AI management, Competitiveness, Digital innovation},
abstract = {The latest technological developments in generative artificial intelligence (GenAI) offer powerful capabilities to small and medium enterprises (SMEs) as they facilitate the democratization of scalability and creativity. With little technical expertise or financial resources, SMEs can leverage this technology to streamline work processes and unleash innovation, improving their product offerings and long-term competitiveness. In this article, we discuss how SMEs can navigate both the promises and challenges of GenAI and offer a roadmap for deploying the technology. We then introduce a sailing metaphor that reveals key strategic dimensions for GenAI deployment: competency of employees, effective leadership and work values, organizational culture, collaboration and cooperation, and relationships with third parties. We conclude with practical recommendations for successfully deploying GenAI in SMEs.}
}
@article{ZHAO2024191,
title = {Employees’ perception of generative artificial intelligence and the dark side of work outcomes},
journal = {Journal of Hospitality and Tourism Management},
volume = {61},
pages = {191-199},
year = {2024},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2024.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1447677024001207},
author = {Hairong Zhao and Bocong Yuan and Yang Song},
keywords = {, , },
abstract = {Artificial intelligence (as well as generative AI) has been increasingly applied in the tourism and hospitality industry and has an important impact on the work behavior of practitioners. Drawing from the transactional theory of stress and coping, this study is to clarify the mechanism of potential negative impact of AI on the work outcomes of tourism and hospitality practitioners who use generative AI (GenAI) to assist their work. This study conducts in-depth interviews and thematic analysis to explore how the use of GenAI affects negative work behaviors among tourism and hospitality practitioners. The results show that employees’ technical fear towards AI is negatively associated with their sense of realism, self-investment, and habitual perception, but positively associated with the perceived threat of job intelligence to employment. Moreover, the technical fear towards AI can be positively associated with their transgression behavior. The findings of this study can be illuminating for helping tourism and hospitality organizations develop sustainable and healthy workplace guidelines.}
}
@article{MOUSSA2025202990,
title = {Validation of a generative artificial intelligence tool for the critical appraisal of articles on the epidemiology of mental health: Its application in the Middle East and North Africa},
journal = {Journal of Epidemiology and Population Health},
volume = {73},
number = {2},
pages = {202990},
year = {2025},
issn = {2950-4333},
doi = {https://doi.org/10.1016/j.jeph.2025.202990},
url = {https://www.sciencedirect.com/science/article/pii/S2950433325001843},
author = {Cheima Moussa and Sarah Altayyar and Marion Vergonjeanne and Thibaut Gelle and Pierre-Marie Preux},
keywords = {Artificial intelligence, ChatGPT, Critical appraisal, Mental health, MENA},
abstract = {Mental health disorders have a high disability-adjusted life years in the Middle East and North Africa. This rise has led to a surge in related publications, prompting researchers to use AI tools like ChatGPT to reduce time spent on routine tasks. Our study aimed to validate an AI-assisted critical appraisal (CA) tool by comparing it with human raters. We developed customized GPT models using ChatGPT-4. These models were tailored to evaluate studies using the Newcastle-Ottawa Scale (NOS) or the Jadad Scale in one model, while another model evaluated STROBE or CONSORT guidelines. Our results showed a moderate to good agreement between human CA and our GPTs for the NOS for cohort, case control and cross-sectional studies and for the Jadad scale, with an ICC of 0.68 [95 %CI: 0.24–0.82], 0.69 [95 %CI: 0.31–0.88], 0.76 [95 %CI: 0.47–0.90] and 0.84 [95 %CI: 0.57–0.94] respectively. There was also a moderate to substantial agreement between the two methods for STROBE in cross sectional, cohort, case control studies, and for CONSORT in trial design, with a K of 0.63 [95 %CI: 0.56–0.70], 0.57 [95 %CI: 0.47–0.66], 0.48 [95 %CI: 0.38–0.50] and 0.70 [95 %CI: 0.63–0.77] respectively. Our custom GPT models produced hallucinations in 6.5 % and 4.9 % of cases, respectively. Human raters took an average of 19.6 ± 4.3 min per article, whereas our customized GPTs took only 1.4. ChatGPT could be a useful tool for handling repetitive tasks yet its effective application relies on the critical expertise of researchers.}
}
@article{JIANG2024102883,
title = {When generative artificial intelligence meets multimodal composition: Rethinking the composition process through an AI-assisted design project},
journal = {Computers and Composition},
volume = {74},
pages = {102883},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102883},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000598},
author = {Jialei Jiang},
keywords = {Generative artificial intelligence, Multimodal composition process, Adobe Firefly, DALL·E, Wicked problems, Design, Writing studies},
abstract = {This study explores the integration of generative artificial intelligence (GenAI) design technologies, including Adobe Firefly and DALL·E, into the teaching and learning of multimodal composition. Through focus group discussions and case studies, this paper demonstrates the potential of GenAI in reshaping the various stages of the composition process, including invention, designing, and revising. The findings reveal that GenAI technologies have the potential to enhance students’ multimodal composition practices and offer alternative solutions to the wicked problems encountered during the design process. Specifically, GenAI facilitates invention by offering design inspirations and enriches designing by expanding, removing, and editing the student-produced design contents. The students in this study also shared their critical stance on the revision process by modifying and iterating their designs after their uses of GenAI. Through showcasing both the opportunities and challenges of GenAI technologies, this paper contributes to the ongoing scholarly conversations on multimodal composition and pedagogy. Moreover, the paper offers implications for the future research and teaching of GenAI-assisted multimodal composition projects, with the aim of encouraging thoughtful integration of GenAI technologies to foster critical AI literacy among college composition students.}
}
@article{ALLEN2025S64,
title = {OS03-09 Surveying the Landscape: A Modular Generative Artificial Intelligence Workflow to Identify NAMs for Systemic Toxicity},
journal = {Toxicology Letters},
volume = {411},
pages = {S64},
year = {2025},
note = {Abstracts of the 59th Congress of the European Societies of Toxicology (EUROTOX 2025) TOXICOLOGY ADDRESSES SOCIETY'S REAL LIFE RISKS FOR SUSTAINABLE HEALTH AND WELL BEING},
issn = {0378-4274},
doi = {https://doi.org/10.1016/j.toxlet.2025.07.180},
url = {https://www.sciencedirect.com/science/article/pii/S0378427425017631},
author = {D. Allen and E. Martin and J. Hamm and J. Wignall and K. To and T. Feiler and C. Lemeris and P. Kukic},
abstract = {To identify the areas of systemic toxicity with the greatest need, and which present the best opportunities for human-relevant model (i.e., new approach methodologies [NAMs]) development, standardization, and implementation, we conducted a landscape analysis to collect information on ongoing efforts in the NAMs space. This type of analysis traditionally requires the collection, manual review, summary, and synthesis of an extensive literature base that requires hundreds of hours to complete. To increase both speed and efficiency, we utilized a reproducible workflow that incorporates multiple computational tools including generative artificial intelligence (GenAI) to quickly summarize a large literature database. Our integrated approach coupled subject matter expertise with sorting and extraction algorithms to provide a comprehensive overview of the state of the science for NAMs used for, or potentially useful for, the assessment of systemic toxicity of cosmetics. To identify potentially relevant studies, we conducted a literature search with keywords related to NAMs across three major topic areas: in silico, in chemico, and in vitro. We prioritized studies by coupling supervised clustering, topic extraction and keyword analysis algorithms. These methods led to the prioritization of 8,418 studies. To identify relevant studies, subject matter experts were employed in conjunction with active machine learning to identify relevant studies that were then summarized via GenAI. Given the objective was to provide sufficient coverage of the landscape to both address pragmatic, near-term needs, as well as shaping the future of how safety assessments are performed, we designed prompts to characterize the current and past systematic efforts directed towards developing and refining NAMs, including both success stories, scientific and technical challenges, and roadblocks to wider adoption. Our analysis identified 3,010 peer-reviewed publications and 38 consortium websites cataloguing NAMs that were applicable to the cosmetics regulatory process, from hazard-focused endpoints to exposure-based waiving of studies altogether. Additionally, they covered the full spectrum of maturity, from those approaches that show promise at the research and development phase to fully validated approaches ready for immediate regulatory use. To the extent available, we identified the molecular/cellular endpoints associated with each NAM and the reference dataset that was used to develop and/or evaluate usefulness and limitations across a total of 60,960 endpoints. The landscape also captured opportunities to validate mature NAMs to support their regulatory use and market adoption. These results will support the development and identification of NAMs to be included in frameworks for assessing systemic toxicity potential.}
}
@article{COSCI2025112113,
title = {Generative artificial intelligence: A hot topic to face with},
journal = {Journal of Psychosomatic Research},
volume = {192},
pages = {112113},
year = {2025},
issn = {0022-3999},
doi = {https://doi.org/10.1016/j.jpsychores.2025.112113},
url = {https://www.sciencedirect.com/science/article/pii/S0022399925000777},
author = {Fiammetta Cosci and Antonina Mikocka-Walus}
}
@article{ASHRAF2024,
title = {Search Engines and Generative Artificial Intelligence Integration: Public Health Risks and Recommendations to Safeguard Consumers Online},
journal = {JMIR Public Health and Surveillance},
volume = {10},
year = {2024},
issn = {2369-2960},
doi = {https://doi.org/10.2196/53086},
url = {https://www.sciencedirect.com/science/article/pii/S2369296024000504},
author = {Amir Reza Ashraf and Tim Ken Mackey and András Fittler},
keywords = {generative artificial intelligence, artificial intelligence, comparative assessment, search engines, online pharmacies, patient safety, generative, safety, search engine, search, searches, searching, website, websites, Google, Bing, retrieval, information seeking, illegal, pharmacy, pharmacies, risk, risks, consumer, consumers, customer, customers, recommendation, recommendations, vendor, vendors, substance use, substance abuse, controlled substances, controlled substance, drug, drugs, pharmaceutic, pharmaceutics, pharmaceuticals, pharmaceutical, medication, medications},
abstract = {Background
The online pharmacy market is growing, with legitimate online pharmacies offering advantages such as convenience and accessibility. However, this increased demand has attracted malicious actors into this space, leading to the proliferation of illegal vendors that use deceptive techniques to rank higher in search results and pose serious public health risks by dispensing substandard or falsified medicines. Search engine providers have started integrating generative artificial intelligence (AI) into search engine interfaces, which could revolutionize search by delivering more personalized results through a user-friendly experience. However, improper integration of these new technologies carries potential risks and could further exacerbate the risks posed by illicit online pharmacies by inadvertently directing users to illegal vendors.
Objective
The role of generative AI integration in reshaping search engine results, particularly related to online pharmacies, has not yet been studied. Our objective was to identify, determine the prevalence of, and characterize illegal online pharmacy recommendations within the AI-generated search results and recommendations.
Methods
We conducted a comparative assessment of AI-generated recommendations from Google’s Search Generative Experience (SGE) and Microsoft Bing’s Chat, focusing on popular and well-known medicines representing multiple therapeutic categories including controlled substances. Websites were individually examined to determine legitimacy, and known illegal vendors were identified by cross-referencing with the National Association of Boards of Pharmacy and LegitScript databases.
Results
Of the 262 websites recommended in the AI-generated search results, 47.33% (124/262) belonged to active online pharmacies, with 31.29% (82/262) leading to legitimate ones. However, 19.04% (24/126) of Bing Chat’s and 13.23% (18/136) of Google SGE’s recommendations directed users to illegal vendors, including for controlled substances. The proportion of illegal pharmacies varied by drug and search engine. A significant difference was observed in the distribution of illegal websites between search engines. The prevalence of links leading to illegal online pharmacies selling prescription medications was significantly higher (P=.001) in Bing Chat (21/86, 24%) compared to Google SGE (6/92, 6%). Regarding the suggestions for controlled substances, suggestions generated by Google led to a significantly higher number of rogue sellers (12/44, 27%; P=.02) compared to Bing (3/40, 7%).
Conclusions
While the integration of generative AI into search engines offers promising potential, it also poses significant risks. This is the first study to shed light on the vulnerabilities within these platforms while highlighting the potential public health implications associated with their inadvertent promotion of illegal pharmacies. We found a concerning proportion of AI-generated recommendations that led to illegal online pharmacies, which could not only potentially increase their traffic but also further exacerbate existing public health risks. Rigorous oversight and proper safeguards are urgently needed in generative search to mitigate consumer risks, making sure to actively guide users to verified pharmacies and prioritize legitimate sources while excluding illegal vendors from recommendations.}
}
@article{FELICETTI2024100545,
title = {Artificial intelligence and project management: An empirical investigation on the appropriation of generative Chatbots by project managers},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100545},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100545},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000842},
author = {Alberto Michele Felicetti and Antonio Cimino and Alberto Mazzoleni and Salvatore Ammirato},
keywords = {Project managers, Generative artificial intelligence, Chatgpt, Appropriation Theory, Structural Equation Modeling},
abstract = {The integration of generative AI tools, such as chatbots, into project management is revolutionizing the field. This paper explores how project managers are adopting and adapting these tools, specifically focusing on ChatGPT, for enhanced project management. Using Adaptive Structuration Theory, the study examines project managers' appropriation of generative AI. It considers factors like Innovation Attitude, Peer Influence, and Task-Technology Fit, employing a survey of Italian project managers. The approach adopted to analyze data is based on Partial Least Square - Structural Equation Modeling. The research confirms the significance of the hypothesized antecedents in AI tool appropriation. Innovation Attitude and Peer Influence are shown to positively impact the creative and 'unfaithful' use of AI in project management. Task-Technology Fit is crucial for effective AI integration, impacting both creative behaviour and unfaithful appropriation. The study highlights the role of an innovative mindset, peer dynamics, and task compatibility in the effective use of AI tools in project management. It suggests potential areas for future research, including exploring cultural and organizational contexts and the rapid evolution of AI technologies.}
}
@article{RASHID2025S268,
title = {MT14 Role of Generative Artificial Intelligence in Assisting Systematic Review Process in Health Research: A Systematic Review},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S268},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1124},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525012495},
author = {Muhammed Rashid and Cheng Su Yi and Suwapat Lawin and Pongsapat Limhensin and Suppachai Insuk and Sajesh K. Veettil and Nai Ming Lai and Xiangyang Ye and Nathorn Chaiyakunapruk and Teerapon Dhippayom}
}
@article{KENOPURUM2025S301,
title = {MSR139 Application of Generative Artificial Intelligence for Extracting Structured Data from Unstructured Bladder Cancer Pathology Reports},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S301},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1290},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525014159},
author = {Jennifer Ken-Opurum and Sidharth Singh and P. Pranav and Rahul Bhonsle and Shekhar Thumake and Heather Marino and Luke Dunlap}
}
@article{YANG2025104877,
title = {The impact of TPACK on teachers’ willingness to integrate generative artificial intelligence (GenAI): The moderating role of negative emotions and the buffering effects of need satisfaction},
journal = {Teaching and Teacher Education},
volume = {154},
pages = {104877},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104877},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24004104},
author = {Yiming Yang and Qi Xia and Chuanbin Liu and Thomas K.F. Chiu},
keywords = {TPACK, Negative emotions, Self-determination theory (SDT), Generative artificial intelligence (GenAI), Teachers' willingness},
abstract = {Understanding teachers' willingness to integrate generative AI (WIAI) is essential in the current dilemma where students' adoption rate is faster than teachers'. Therefore, this study aims to identify factors affecting teachers' WIAI and their interactions from the perspectives of needs satisfaction and emotion. We used regression analyses to analyze data collected from 1348 teachers online. The results supported that TPACK positively influences teachers' WIAI, but this effect is weakened by negative emotions, while needs satisfaction for competence and relatedness buffers the negative effect more effectively than autonomy. These highlight the role of emotional and psychological support in fostering teachers’ adoptions.}
}
@article{KARELL2025101966,
title = {Synthetic duality: A framework for analyzing generative artificial intelligence's representation of social reality},
journal = {Poetics},
volume = {108},
pages = {101966},
year = {2025},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2024.101966},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X24001049},
author = {Daniel Karell and Jeffrey Sachs and Ryan Barrett},
keywords = {Duality, Mondo-Breiger, Socio-semantic networks, Large language models, Generative artificial intelligence},
abstract = {The development of generative artificial intelligence (genAI) has caused concern about its potential risks, including how its ability to generate human-like texts could affect our shared perception of the social world. Yet, it remains unclear how best to assess and understand genAI's influence on our understanding of social reality. Building on insights into the representation of social worlds within texts, we introduce a framework for analyzing genAI's content and its consequences for perceptions of social reality. We demonstrate this “synthetic duality” framework in two parts. First, we show that genAI can create, with minimal guidance, reasonable portrayals of actors and ascribe relational meaning to those actors – virtual social worlds within texts, or “Mondo-Breigers”. Second, we examine how these synthetic documents with interior social worlds affect readers’ view of social reality. We find that they change individuals’ perceptions of actors depicted in the documents, likely by updating individuals’ expectations about the actors and their meanings. However, additional exploratory analyses suggest it is texts’ style, not their construction of “Mondo-Breigers”, that might be influencing people's perceptions. We end with a discussion of theoretical and methodological implications, including how genAI may unsettle structural notions of individuality. Namely, reimagining the duality of individuals and groups could help theorize growing homogeneity in an increasingly genAI-informed world.}
}
@article{GANJOO2024,
title = {Beyond boundaries: exploring a generative artificial intelligence assignment in graduate, online science courses},
journal = {Journal of Microbiology & Biology Education},
volume = {25},
number = {3},
year = {2024},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00127-24},
url = {https://www.sciencedirect.com/science/article/pii/S1935787724000893},
author = {Rohini Ganjoo and James Rankin and Benjamin Lee and Lisa Schwartz},
keywords = {generative artificial intelligence, graduate courses, assignment, online education, health professional education},
abstract = {ABSTRACT

Generative artificial intelligence (GAI) offers increased accessibility and personalized learning, though the potential for inaccuracies, biases, and unethical use is concerning. We present a newly developed research paper assignment that required students to utilize GAI. The assignment was implemented within three online, asynchronous graduate courses for medical laboratory sciences. Student learning was assessed using a rubric, which rated students’ effective integration and evaluation of GAI-generated content against peer-reviewed research articles, thus demonstrating their critical thinking and synthesis skills, among other metrics. Overall rubric scores were high, suggesting that learning outcomes were met. After field testing, we administered a 16-item survey about GAI utilization, contribution to learning, and ethical concerns. Data (n = 32) were analyzed, and free-response answers were thematically coded. While 93.8% of respondents found the GAI-generated content to be “very good” or “excellent,” 28.1% found inaccuracies, and 68.8% “strongly agreed” or “agreed” that GAI should be allowed to be used as a tool to complete academic assignments. Interestingly, however, only 28.1% “strongly agreed” or “agreed” that GAI may be used for assignments if not explicitly authorized by the instructor. Though GAI allowed for more efficient completion of the project and better understanding of the topic, students noted concerns about academic integrity and the lack of citations in GAI responses. The assignment can easily be modified for different learning preferences and course environments. Raising awareness among students and faculty about the ethical use and limitations of GAI is crucial in today’s evolving pedagogical landscape.}
}
@article{CURRIE2025423,
title = {Generative Artificial Intelligence Biases, Limitations and Risks in Nuclear Medicine: An Argument for Appropriate Use Framework and Recommendations},
journal = {Seminars in Nuclear Medicine},
volume = {55},
number = {3},
pages = {423-436},
year = {2025},
note = {Artificial Intelligence},
issn = {0001-2998},
doi = {https://doi.org/10.1053/j.semnuclmed.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001299824000461},
author = {Geoffrey M. Currie and K. Elizabeth Hawk and Eric M. Rohren},
abstract = {Generative artificial intelligence (AI) algorithms for both text-to-text and text-to-image applications have seen rapid and widespread adoption in the general and medical communities. While limitations of generative AI have been widely reported, there remain valuable applications in patient and professional communities. Here, the limitations and biases of both text-to-text and text-to-image generative AI are explored using purported applications in medical imaging as case examples. A direct comparison of the capabilities of four common text-to-image generative AI algorithms is reported and recommendations for the most appropriate use, DALL-E 3, justified. The risks use and biases are outlined, and appropriate use guidelines framed for use of generative AI in nuclear medicine. Generative AI text-to-text and text-to-image generation includes inherent biases, particularly gender and ethnicity, that could misrepresent nuclear medicine. The assimilation of generative AI tools into medical education, image interpretation, patient education, health promotion and marketing in nuclear medicine risks propagating errors and amplification of biases. Mitigation strategies should reside inside appropriate use criteria and minimum standards for quality and professionalism for the application of generative AI in nuclear medicine.}
}
@article{PELLEGRINO2025S126,
title = {OC.02.7 CONVERSATIONAL LARGE LANGUAGE MODEL GENERATIVE ARTIFICIAL INTELLIGENCE CHATBOT CHATGPT-4 FOR COLONOSCOPY BOSTON BOWEL PREPARATION SCORING: AN AI-TO-HEAD HUMAN-BLINDED CONCORDANCE ANALYSIS ON A LARGE VOLUME OF ENDOSCOPIC FRAMES},
journal = {Digestive and Liver Disease},
volume = {57},
pages = {S126-S127},
year = {2025},
note = {Abstracts of the 31st National Congress of Digestive Diseases, FISMAD},
issn = {1590-8658},
doi = {https://doi.org/10.1016/S1590-8658(25)00382-2},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825003822},
author = {R. Pellegrino and G. Palladino and G. Imperio and A. Federico and A.G. Gravina}
}
@article{AMACHER2024100587,
title = {Prediction of outcomes after cardiac arrest by a generative artificial intelligence model},
journal = {Resuscitation Plus},
volume = {18},
pages = {100587},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100587},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000389},
author = {Simon A. Amacher and Armon Arpagaus and Christian Sahmer and Christoph Becker and Sebastian Gross and Tabita Urben and Kai Tisljar and Raoul Sutter and Stephan Marsch and Sabina Hunziker},
keywords = {Artificial intelligence, Cardiac arrest, Cardiopulmonary resuscitation, Mortality prediction, Neurological outcome},
abstract = {Aims
To investigate the prognostic accuracy of a non-medical generative artificial intelligence model (Chat Generative Pre-Trained Transformer 4 - ChatGPT-4) as a novel aspect in predicting death and poor neurological outcome at hospital discharge based on real-life data from cardiac arrest patients.
Methods
This prospective cohort study investigates the prognostic performance of ChatGPT-4 to predict outcomes at hospital discharge of adult cardiac arrest patients admitted to intensive care at a large Swiss tertiary academic medical center (COMMUNICATE/PROPHETIC cohort study). We prompted ChatGPT-4 with sixteen prognostic parameters derived from established post-cardiac arrest scores for each patient. We compared the prognostic performance of ChatGPT-4 regarding the area under the curve (AUC), sensitivity, specificity, positive and negative predictive values, and likelihood ratios of three cardiac arrest scores (Out-of-Hospital Cardiac Arrest [OHCA], Cardiac Arrest Hospital Prognosis [CAHP], and PROgnostication using LOGistic regression model for Unselected adult cardiac arrest patients in the Early stages [PROLOGUE score]) for in-hospital mortality and poor neurological outcome.
Results
Mortality at hospital discharge was 43% (n = 309/713), 54% of patients (n = 387/713) had a poor neurological outcome. ChatGPT-4 showed good discrimination regarding in-hospital mortality with an AUC of 0.85, similar to the OHCA, CAHP, and PROLOGUE (AUCs of 0.82, 0.83, and 0.84, respectively) scores. For poor neurological outcome, ChatGPT-4 showed a similar prediction to the post-cardiac arrest scores (AUC 0.83).
Conclusions
ChatGPT-4 showed a similar performance in predicting mortality and poor neurological outcome compared to validated post-cardiac arrest scores. However, more research is needed regarding illogical answers for potential incorporation of an LLM in the multimodal outcome prognostication after cardiac arrest.}
}
@article{LI2025S280,
title = {MSR33 Automated Extraction of Kaplan-Meier Survival Curves Using Generative Artificial Intelligence and Computer Vision},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S280},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1185},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525013105},
author = {Ying Li and Augustine Annan and Majid R. Mojarad and Jingcheng Du and Yingxin Xu}
}
@article{MCDONALD2025100121,
title = {Generative artificial intelligence in higher education: Evidence from an analysis of institutional policies and guidelines},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {3},
pages = {100121},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100121},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000052},
author = {Nora McDonald and Aditya Johri and Areej Ali and Aayushi Hingle Collier},
abstract = {The release of ChatGPT in November 2022 prompted a massive uptake of generative artificial intelligence (GenAI) across higher education institutions (HEIs). In response, HEIs focused on regulating its use, particularly among students, before shifting towards advocating for its productive integration within teaching and learning. Since then, many HEIs have increasingly provided policies and guidelines to direct GenAI. This paper presents an analysis of documents produced by 116 US universities classified as as high research activity or R1 institutions providing a comprehensive examination of the advice and guidance offered by institutional stakeholders about GenAI. Through an extensive analysis, we found a majority of universities (N = 73, 63%) encourage the use of GenAI, with many offering detailed guidance for its use in the classroom (N = 48, 41%). Over half the institutions provided sample syllabi (N = 65, 56%) and half (N = 58, 50%) provided sample GenAI curriculum and activities that would help instructors integrate and leverage GenAI in their teaching. Notably, the majority of guidance focused on writing activities focused on writing, whereas references to code and STEM-related activities were infrequent, and often vague, even when mentioned (N = 58, 50%). Finally, more than half of institutions talked about the ethics of GenAI on a broad range of topics, including Diversity, Equity and Inclusion (DEI) (N = 60, 52%). Based on our findings we caution that guidance for faculty can become burdensome as policies suggest or imply substantial revisions to existing pedagogical practices.}
}
@article{ERIKSEN2024100016,
title = {Generative artificial intelligence for increasing accessibility of patient information videos in ophthalmology},
journal = {AJO International},
volume = {1},
number = {1},
pages = {100016},
year = {2024},
issn = {2950-2535},
doi = {https://doi.org/10.1016/j.ajoint.2024.100016},
url = {https://www.sciencedirect.com/science/article/pii/S2950253524000169},
author = {Nathalie S. Eriksen and Moug Al-Bakri and Kirstine B. Boysen and Oliver N. Klefter and Diana C. Schmidt and Kirsten Reinwaldt and Jakob Grauslund and Lars M. Holm and Yousif Subhi},
keywords = {Artificial intelligence, Accessibility, Patient information videos},
abstract = {Purpose
Patient information videos are excellent for conveying information on eye health. Language barriers lead to inaccessibility for ethnic minorities. So far, overcoming language barriers have been very expensive, but in this short communications paper, we share our experiences with an inexpensive generative artificial intelligence-based translation system for videos.
Design
Explorative study.
Methods
We developed a patient information video on a very common and broadly relevant issue: how to use eye drops. The original video was made in Danish. We used HeyGen (HeyGen, Los Angeles, California, USA) to translate the video into three categories according to distance from Danish according to comparative linguistics: highly related (English and German), remotely related (French and Polish), and no recognizable relationship (Arabic and Turkish). Ophthalmologists with high proficiency in Danish and each of these languages evaluated and commented on the accuracy of the translations.
Results
All translations resulted in a recognizable clone of the original individual with synchronized lip movements and understandable language. We observed certain inaccuracies in the translation, however, these differed across languages without a specific pattern. Inconsistencies in formal/informal pronouns were observed across languages. But overall, the general information was conveyed across all languages.
Conclusion
Modern generative artificial intelligence-based translation tools can help tearing down language barriers and improve accessibility of patient information videos in ophthalmology.}
}
@article{YOGARATNAM2025100226,
title = {What Becomes of the Human Touch in the Age of Generative Artificial Intelligence?},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {2},
pages = {100226},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000331},
author = {Kishwen Kanna {Yoga Ratnam}}
}
@article{WANG2025100996,
title = {A systematic literature review on the application of generative artificial intelligence (GAI) in teaching within higher education: Instructional contexts, process, and strategies},
journal = {The Internet and Higher Education},
volume = {65},
pages = {100996},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.100996},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000053},
author = {Peijun Wang and Yuhui Jing and Shusheng Shen},
keywords = {GAI, Higher education, Systematic literature review, Chatgpt, Instructional strategies},
abstract = {Represented by ChatGPT, Generative Artificial Intelligence (GAI) is revolutionizing the field of education. Despite a series of related studies and reviews around GAI, existing reviews predominantly focus on macro-level discussions covering overall development trends, core issues, opportunities and risks. There has been a lack of systematic reviews from a meso-level perspective examining the application of GAI in classroom teaching within higher education. This study employs a systematic literature review method, examining 139 articles from Web of Science, EBSCO, and Scopus databases. Findings include: (1)In terms of disciplines and types of GAI applications, engineering, health and medicine, and language are the most popular, while humanities, social sciences, basic sciences, mathematics, sports sciences, and interdisciplinary fields have fewer applications. Based on Strobel's classification of GAI(2024), it is found that Generators, Reimaginators, and Assistants are the most widely applied types of GAI. In contrast, Synthesizers and Enablers are less commonly utilized. Regarding the adoption trends across disciplines, engineering and language have a diverse range of GAI product types applied, whereas health and medicine has fewer types of GAI products in use. Due to smaller sample sizes, the analysis of GAI product types in the remaining six disciplines is also relatively limited. (2)In terms of the application of GAI across different disciplines, a small portion of GAI applications reflect distinctive disciplinary characteristics. Regarding the roles mapped out by the application of GAI, based on Xu and Ouyang's classification(2022), instructors or students predominantly perceive GAI as “New Subject” or “Direct Mediator", with less emphasis on the role of “Supplement Assistant”. Regarding the integration into the classroom, as assessed through the SAMR framework, most GAI applications are in the Augmentation level. There are also some in the Substitution and Modification levels, while applications in the Redefinition level are relatively rare. (3)In terms of the selection of instructional strategies under GAI applications, there are 18 types of strategies across four orientations, primarily emphasizing constructive and reflective orientations. Strategies focusing on didactic and authentic orientiations are less frequently utilized. Regarding the roles GAI plays as reflected in instructional strategies, it predominantly assumes roles as “New Subject” and “Direct Mediator", with the role of “Supplementary Assistant” yet to be explored. Finally, this study evaluated the instructional application research of GAI from three dimensions: GAI product type and applied discipline, discipline-specific application and integration level, instructional strategies and GAI role, and put forward relevant research suggestions.}
}
@article{ABDALLAH2025,
title = {Generative Artificial Intelligence Models for Developing Neuroimaging Markers of Psychiatric Disorders},
journal = {Biological Psychiatry},
year = {2025},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2025.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0006322325011849},
author = {Chadi G. Abdallah and David {van Dijk}}
}
@article{ALEXANDER2025101416,
title = {Exploring Generative Artificial Intelligence to Enhance Reflective Writing in Pharmacy Education},
journal = {American Journal of Pharmaceutical Education},
volume = {89},
number = {6},
pages = {101416},
year = {2025},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2025.101416},
url = {https://www.sciencedirect.com/science/article/pii/S0002945925000610},
author = {Kaitlin M. Alexander and Margeaux Johnson and Michelle Z. Farland and Amy Blue and Emily K. Bald},
keywords = {Artificial intelligence, Reflective writing, Reflection techniques, Self-assessment, Pharmacy education},
abstract = {The integration of generative artificial intelligence (AI) holds the potential to impact teaching and learning. In this commentary, we explore the opportunity for AI to enhance reflective writing (RW) among student pharmacists. AI-guided RW has the potential to strengthen students’ reflective capacity, deepen their autobiographical memory, and develop their self-confidence. This commentary presents examples of how AI can be utilized to enrich RW and includes a sample prompt aimed at facilitating student self-reflection. We explore how integrating AI-facilitated RW assignments into the pharmacy curriculum can help students develop detailed examples for self-reflection and gain exposure to the potential uses of AI in their professional development and career advancement.}
}
@article{RUKADIKAR202427,
title = {Leadership development through self-upskilling: role of generative artificial intelligence},
journal = {Development and Learning in Organizations: An International Journal},
volume = {38},
number = {4},
pages = {27-30},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-01-2024-0005},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000170},
author = {Aaradhana Rukadikar and Komal Khandelwal},
keywords = {Leadership development, Leaders, Learning, Upskilling, Generative AI},
abstract = {Purpose
This viewpoint paper investigates the changing role of leadership in a dynamic, technologically driven society, and the vital requirement for leaders to engage in continuous self-upskilling to remain effective. It emphasizes the importance of generative artificial intelligence (GAI) in transforming personalized learning experiences for leaders and allowing them to adapt to an ever-changing world.
Design/methodology/approach
A review of current research papers, articles, and case studies is conducted to evaluate the integration of generative AI in leadership self-upskilling. It examines the possibilities and possible benefits of generative AI, and the issues it offers regarding data privacy, algorithmic bias, and learning requirements.
Findings
The findings highlight the transformational potential of GAI in self-upskilling for leaders. It demonstrates how GAI can build personalized learning materials, provide real-time feedback, and adapt content to individual learning styles. It identifies notable executives who have effectively embraced GAI for their self-upskilling journeys, resulting in increased productivity and competitiveness.
Practical implications
The paper investigates the application of GAI for self-improvement, addressing challenges such as data privacy and algorithmic bias while suggesting responsible AI use tactics.
Originality/value
This study investigates the relationship between leadership and AI, emphasizing the importance of leaders in self-improvement as well as the possibility of AI-powered self-upskilling to democratize leadership development while also promoting ethical use.}
}
@article{LEE2025,
title = {Use of a Medical Communication Framework to Assess the Quality of Generative Artificial Intelligence Replies to Primary Care Patient Portal Messages: Content Analysis},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/71966},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25005220},
author = {Natalie S Lee and Nathan Richards and Jodi Grandominico and Robert M Cronin and Amanda K Hendricks and Ravi S Tripathi and Daniel E Jonas},
keywords = {communication, artificial intelligence, primary care, electronic health record, patient portal, health communication},
abstract = {Background
There is growing interest in applying generative artificial intelligence (GenAI) to respond to electronic patient portal messages, particularly in primary care where message volumes are highest. However, evaluations of GenAI as an inbox communication tool are limited. Qualitative analysis of when and how often GenAI responses achieve communication goals can inform estimates of impact and guide continuous improvement.
Objective
This study aims to evaluate GenAI responses to primary care messages using a medical communication framework.
Methods
This was a descriptive quality improvement study of 201 GenAI replies to a purposively sampled, diverse pool of real primary care patient messages in a large midwestern academic medical center. Two physician reviewers (NSL and NR) used a hybrid deductive-inductive approach to qualitatively identify and define themes, guided by constructs from the “best practice” medical communication framework. After achieving thematic saturation, the reviewers assessed the presence or absence of identified communication themes, both independently and collaboratively. Discrepant observations were reconciled via discussion. Frequencies of identified themes were tallied.
Results
Themes in strengths and limitations emerged across 5 communication domains. In the domain of rapport building, expressing respect and restating key phrases were strengths, while inappropriate or inadequate rapport building statements were limitations. For information gathering, questions that built toward a plan or elicited patient needs were strengths, while questions that were out of place or redundant were limitations. For information delivery, accurate content delivered clearly and professionally was a strength, but delivery of inaccurate content was an observed limitation. GenAI responses could facilitate next steps by outlining choices or providing instruction, but sometimes those next steps were inappropriate or premature. Finally, in responding to emotion, strengths were that emotions were named and validated, while inadequate or absent acknowledgment of emotion was a limitation. Overall, 26.4% (53/201) of all messages displayed communication strengths without limitations, 27.4% (55/201) had limitations without strengths, and the remaining 46.3% (93/201) had both. Strengths outnumbered limitations in rapport building (87/201, 43.3% vs 35/201, 17.4%) and facilitating next steps (73/201, 36.3% vs 39/201, 19.4%). Limitations outnumbered strengths in the remaining domains of information delivery (89/201, 44.3% vs 43/201, 21.4%), information gathering (60/201, 29.9% vs 43/201, 21.4%), and responding to emotion (7/201, 8.5% vs 9/201, 4.5%).
Conclusions
GenAI response quality on behalf of primary care physicians and advanced practice providers may vary by communication function. Expressions of respect or descriptions of common next steps may be appropriate, but gathering and delivering appropriate information, or responding to emotion, may be limited. While communication standards were often met, they were also often compromised. Understanding these strengths and limitations can inform decisions about whether, when, and how to apply GenAI as a tool for primary care inbox communication.}
}
@article{MESSER2024100056,
title = {Co-creating art with generative artificial intelligence: Implications for artworks and artists},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100056},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100056},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000161},
author = {Uwe Messer},
keywords = {Art, Authenticity, Generative AI, Human-AI-Collaboration},
abstract = {Synthetic visual art is becoming a commodity due to generative artificial intelligence (AI). The trend of using AI for co-creation will not spare artists’ creative processes, and it is important to understand how the use of generative AI at different stages of the creative process affects both the evaluation of the artist and the result of the human-machine collaboration (i.e., the visual artifact). In three experiments (N = 560), this research explores how the evaluation of artworks is transformed by the revelation that the artist collaborated with AI at different stages of the creative process. The results show that co-created art is less liked and recognized, especially when AI was used in the implementation stage. While co-created art is perceived as more novel, it lacks creative authenticity, which exerts a dominant influence. The results also show that artists’ perceptions suffer from the co-creation process, and that artists who co-create are less admired because they are perceived as less authentic. Two boundary conditions are identified. The negative effect can be mitigated by disclosing the level of artist involvement in co-creation with AI (e.g., by training the algorithm on a curated set of images vs. simply prompting an off-the-shelf AI image generator). In the context of art that is perceived as commercially motivated (e.g., stock images), the effect is also diminished. This research has important implications for the literature on human-AI-collaboration, research on authenticity, and the ongoing policy debate regarding the transparency of algorithmic presence.}
}
@article{BUGHIN2024658,
title = {What drives the corporate payoffs of using generative artificial intelligence?},
journal = {Structural Change and Economic Dynamics},
volume = {71},
pages = {658-668},
year = {2024},
issn = {0954-349X},
doi = {https://doi.org/10.1016/j.strueco.2024.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0954349X24001413},
author = {Jacques Bughin},
keywords = {AI, Generative AI, Productivity impact, Capabilities, Entropy},
abstract = {Artificial Intelligence, a set of technologies that aim to replicate human cognitive functions, has seen remarkable improvements over the last decade. In particular, generative AI (GenAI), a subset of AI able to generate content tasks based on Large Language Models (LLM), has recently gained momentum. Based on an extensive analysis of generative AI use cases in large enterprises, we find that Gen AI shows strong labor productivity improvements across metrics such as throughput time, unit cost, and task effectiveness. However, the distribution of gains is asymmetric in favor of a few companies. While the current distribution of gains does not provide evidence of a power law effect, the current asymmetry reflects differences in AI resources/capabilities across companies - mainly data access, AI talent, or AI governance.}
}
@article{INAM2024102387,
title = {A review of top cardiology and cardiovascular medicine journal guidelines regarding the use of generative artificial intelligence tools in scientific writing},
journal = {Current Problems in Cardiology},
volume = {49},
number = {3},
pages = {102387},
year = {2024},
issn = {0146-2806},
doi = {https://doi.org/10.1016/j.cpcardiol.2024.102387},
url = {https://www.sciencedirect.com/science/article/pii/S0146280624000264},
author = {Maha Inam and Sana Sheikh and Abdul Mannan Khan Minhas and Elizabeth M. Vaughan and Chayakrit Krittanawong and Zainab Samad and Carl J. Lavie and Adeel Khoja and Melaine D'Cruze and Leandro Slipczuk and Farhana Alarakhiya and Azra Naseem and Adil H. Haider and Salim S. Virani},
keywords = {Artificial Intelligence, Editorial Policies, ChatGPT, Large Language Models, Machine Learning, Scientific Writing, Cardiology, SCImago},
abstract = {Background
Generative Artificial Intelligence (AI) tools have experienced rapid development over the last decade and are gaining increasing popularity as assistive models in academic writing. However, the ability of AI to generate reliable and accurate research articles is a topic of debate. Major scientific journals have issued policies regarding the contribution of AI tools in scientific writing.
Methods
We conducted a review of the author and peer reviewer guidelines of the top 25 Cardiology and Cardiovascular Medicine journals as per the 2023 SCImago rankings. Data were obtained though reviewing journal websites and directly emailing the editorial office. Descriptive data regarding journal characteristics were coded on SPSS. Subgroup analyses of the journal guidelines were conducted based on the publishing company policies.
Results
Our analysis revealed that all scientific journals in our study permitted the documented use of AI in scientific writing with certain limitations as per ICMJE recommendations. We found that AI tools cannot be included in the authorship or be used for image generation, and that all authors are required to assume full responsibility of their submitted and published work. The use of generative AI tools in the peer review process is strictly prohibited.
Conclusion
Guidelines regarding the use of generative AI in scientific writing are standardized, detailed, and unanimously followed by all journals in our study according to the recommendations set forth by international forums. It is imperative to ensure that these policies are carefully followed and updated to maintain scientific integrity.}
}
@article{HABIB2024100072,
title = {How does generative artificial intelligence impact student creativity?},
journal = {Journal of Creativity},
volume = {34},
number = {1},
pages = {100072},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100072},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000316},
author = {Sabrina Habib and Thomas Vogel and Xiao Anli and Evelyn Thorne},
keywords = {Creative process, Artificial intelligence (AI), Alternative uses Task (AUT), Mixed methods, Creative thinking, Higher education, Creative confidence},
abstract = {This study aimed to learn about the impact of generative artificial intelligence (AI) on student creative thinking skills and subsequently provide instructors with information on how to guide the use of AI for creative growth within classroom instruction. This mixed methods study used qualitative and quantitative data collected through an AUT test conducted in a college-level creativity course. The authors measured flexibility, fluency, elaboration, and originality of the data to assess the impact of ChatGPT-3 on students’ divergent thinking. The results advocate for a careful approach in integrating AI into creative education. While AI has the potential to significantly support creative thinking, there are also negative impacts on creativity and creative confidence. The authors of this study believe that creativity is central to learning, developing students’ ability to respond to challenges and find solutions within any field; thus the results of this study can be applicable to any classroom faced with the impact and/or integrating the use of AI on idea generation.}
}
@article{NA2025103614,
title = {1376 Virtual H&E Staining Using Generative Artificial Intelligence: A Novel Technique for Digital Transformation of Unstained Pathology Slides},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103614},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103614},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032926},
author = {Sei Na and Dawoon Na and Kyoungsook Park and SangYong Song and Byullee Park and Hyung Kyung Kim}
}
@article{KOOLI2025104476,
title = {Generative artificial intelligence addiction syndrome: A new behavioral disorder?},
journal = {Asian Journal of Psychiatry},
volume = {107},
pages = {104476},
year = {2025},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2025.104476},
url = {https://www.sciencedirect.com/science/article/pii/S1876201825001194},
author = {Chokri Kooli and Youssef Kooli and Eya Kooli},
keywords = {Generative AI Addiction, Behavioral Addiction, Artificial Intelligence Dependency, Digital Addiction, Cognitive and Emotional Well-being, AI and Mental Health, Human-AI Interaction}
}
@article{FOSSOWAMBA2025103235,
title = {Generative artificial intelligence and the challenges to adding value ethically},
journal = {Technovation},
volume = {144},
pages = {103235},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103235},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000677},
author = {Samuel {Fosso Wamba} and Maciel M. Queiroz and Krithika Randhawa and Gaurav Gupta},
keywords = {Generative AI, Gen-AI, LLMs, Ethical tensions, Business value, Innovation},
abstract = {Generative Artificial Intelligence (Gen-AI) is reshaping business models, innovation processes, and organizational strategies across industries. This editorial highlights its transformative potential through multiple lenses, including business model adaptation, strategic agility, social impact, creative industries, and ethical governance. The special issue “Generative artificial intelligence and the challenges to adding value ethically” presents diverse perspectives on how firms leverage Gen-AI to gain competitive advantage, drive value creation, and enhance resilience while addressing regulatory, ethical, and operational challenges. The accepted papers examine Gen-AI-driven shifts in entrepreneurship, decision-making, and digital ecosystems using quantitative, qualitative, and mixed-method approaches. Their findings point out both the opportunities and tensions of Gen-AI adoption, highlighting the need for responsible governance, strategic alignment, and human-AI collaboration. By integrating multidisciplinary perspectives, this collection offers a rigorous foundation for scholars, practitioners, and policymakers to understand how Gen-AI can be harnessed to drive sustainable and strategic innovation in an evolving and challenging digital landscape.}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{RAPP2025103375,
title = {How do people experience the images created by generative artificial intelligence? An exploration of people's perceptions, appraisals, and emotions related to a Gen-AI text-to-image model and its creations},
journal = {International Journal of Human-Computer Studies},
volume = {193},
pages = {103375},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2024.103375},
url = {https://www.sciencedirect.com/science/article/pii/S1071581924001587},
author = {Amon Rapp and Chiara {Di Lodovico} and Federico Torrielli and Luigi {Di Caro}},
keywords = {AI, Generative AI, Stable diffusion, User experience, Anthropomorphising, Humanness, Uncanny valley},
abstract = {Generative Artificial Intelligence (Gen-AI) has rapidly advanced in recent years, potentially producing enormous impacts on industries, societies, and individuals in the near future. In particular, Gen-AI text-to-image models allow people to easily create high-quality images possibly revolutionizing human creative practices. Despite their increasing use, however, the broader population's perceptions and understandings of Gen-AI-generated images remain understudied in the Human-Computer Interaction (HCI) community. This study investigates how individuals, including those unfamiliar with Gen-AI, perceive Gen-AI text-to-image (Stable Diffusion) outputs. Study findings reveal that participants appraise Gen-AI images based on their technical quality and fidelity in representing a subject, often experiencing them as either prototypical or strange: these experiences may raise awareness of societal biases and evoke unsettling feelings that extend to the Gen-AI itself. The study also uncovers several “relational” strategies that participants employ to cope with concerns related to Gen-AI, contributing to the understanding of reactions to uncanny technology and the (de)humanization of intelligent agents. Moreover, the study offers design suggestions on how to use the anthropomorphizing of the text-to-image model as design material, and the Gen-AI images as support for critical design sessions.}
}
@article{LENGUYEN2024138836,
title = {Generative artificial intelligence and optimisation framework for concrete mixture design with low cost and embodied carbon dioxide},
journal = {Construction and Building Materials},
volume = {451},
pages = {138836},
year = {2024},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2024.138836},
url = {https://www.sciencedirect.com/science/article/pii/S0950061824039783},
author = {Khuong {Le Nguyen} and Minhaz Uddin and Thong M. Pham},
keywords = {Concrete mixture design, Machine learning approach, Generative AI, Compressive strength prediction, Multi-objective optimisation},
abstract = {This research presents a generative Artificial Intelligence (AI) and design framework that integrates machine learning (ML) and optimisation methodologies to discover new concrete mixture designs. Unlike traditional ML models that predict based on existing data, this framework innovatively generates new concrete mix designs that meet specific requirements such as strength, cost-efficiency, and reduced embodied CO2. To propose a powerful and reliable generative AI model, several advanced ML algorithms were considered, e.g., CatBoost, XGBoost, and LGBM. These models were trained on a unique dataset consisting of 4,936 data points collected from five different batching plants and have not been published yet. Bayesian Optimisation was employed to fine-tune model hyperparameters, resulting in the most effective models attaining R2 values of 0.94 and 0.89 for raw and grouped data, respectively. To verify the trained generative AI model, a case study was conducted, in which the model was requested to provide designs of a mix with pre-determined strength and optimised cost and embodied CO2. The mix designs generated by the framework were successfully validated through experimental tests, corroborating the predictive outcomes. The research culminated in the development of a web application, a tool crafted to streamline the concrete mixture design and optimisation process. This generative AI design framework can be applied to many other aspects of material design and engineering problems.}
}
@article{MARIANI2024114542,
title = {Generative artificial intelligence in innovation management: A preview of future research developments},
journal = {Journal of Business Research},
volume = {175},
pages = {114542},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114542},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324000468},
author = {Marcello Mariani and Yogesh K. Dwivedi},
keywords = {Generative artificial intelligence, Delphi study, Management, Innovation},
abstract = {This study outlines the future research opportunities related to Generative Artificial Intelligence (GenAI) in innovation management. To this end, it combines a review of the academic literature with the results of a Delphi study involving leading innovation management scholars. Ten major research themes emerged that can guide future research developments at the intersection of GenAI and innovation management: 1) Gen AI and innovation types; 2) GenAI, dominant designs and technology evolution; 3) Scientific and artistic creativity and GenAI-enabled innovations; 4) GenAI-enabled innovations and intellectual property; 5) GenAI and new product development; 6) Multimodal/unimodal GenAI and innovation outcomes; 7) GenAI, agency and ecosystems; 8) Policymakers, lawmakers and anti-trust authorities in the regulation of GenAI-enabled innovation; 9) Misuse and unethical use of GenAI leading to biased innovation; and 10) Organizational design and boundaries for GenAI-enabled innovation. The paper concludes by discussing how these themes can inform theoretical development in innovation management studies.}
}
@article{SHIN2025108662,
title = {Artificial intelligence versus clinical judgement: how accurately do generative models reflect CNS guidelines for chiari malformation?},
journal = {Clinical Neurology and Neurosurgery},
volume = {248},
pages = {108662},
year = {2025},
issn = {0303-8467},
doi = {https://doi.org/10.1016/j.clineuro.2024.108662},
url = {https://www.sciencedirect.com/science/article/pii/S0303846724005493},
author = {David Shin and Hyunah Park and Isabel Shaffrey and Vahe Yacoubian and Taha M. Taka and Justin Dye and Olumide Danisa},
keywords = {Artificial intelligence, Chatgpt, Chiari malformation, Guidelines},
abstract = {Objective
This study investigated the response and readability of generative artificial intelligence (AI) models to questions and recommendations proposed by the 2023 Congress of Neurological Surgeons (CNS) guidelines for Chiari 1 malformation.
Methods
Thirteen questions were generated from CNS guidelines and asked to Perplexity, ChatGPT 4o, Microsoft Copilot, and Google Gemini. AI answers were divided into two categories, "concordant" and "non-concordant," according to their alignment with current CNS guidelines. Non-concordant answers were sub-categorized as “insufficient” or “over-conclusive.” Responses were evaluated for readability via the Flesch-Kincaid Grade Level, Gunning Fog Index, SMOG (Simple Measure of Gobbledygook) Index, and Flesch Reading Ease test.
Results
Perplexity displayed the highest concordance rate of 69.2 %, with non-concordant responses classified as 0 % insufficient and 30.8 % over-conclusive. ChatGPT 4o had the lowest concordance rate at 23.1 %, with 0 % insufficient and 76.9 % over-conclusive classifications. Copilot showed a 61.5 % concordance rate, with 7.7 % insufficient and 30.8 % over-conclusive. Gemini demonstrated a 30.8 % concordance rate, with 7.7 % insufficient and 61.5 % as over-conclusive. Flesch-Kincaid Grade Level scores ranged from 14.48 (Gemini) to 16.48 (Copilot), Gunning Fog Index scores varied between 16.18 (Gemini) and 18.8 (Copilot), SMOG Index scores ranged from 16 (Gemini) to 17.54 (Copilot), and Flesch Reading Ease scores were low across all models, with Gemini showing the highest mean score of 21.3.
Conclusion
Perplexity and Copilot emerged as the best-performing for concordance, while ChatGPT and Gemini displayed the highest over-conclusive rates. All responses showcased high complexity and difficult readability. While AI can be valuable in certain aspects of clinical practice, the low concordance rates show that AI should not replace clinician judgement.}
}
@article{LIU2024124511,
title = {Generative artificial intelligence and data augmentation for prognostic and health management: Taxonomy, progress, and prospects},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124511},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124511},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424013782},
author = {Shen Liu and Jinglong Chen and Yong Feng and Zongliang Xie and Tongyang Pan and Jingsong Xie},
keywords = {Fault diagnosis, Generative artificial intelligence, Data augmentation, Data generation, Prognostics and health management},
abstract = {Intelligent fault diagnosis, detection, and prognostics (DDP) for complex equipment prognostics and health management (PHM) have achieved remarkable breakthroughs. Equipment in industrial scenarios often operates in normal conditions, resulting in missing anomalies, limited failures, and incomplete degradation paths. Thus the limited information on the state of the equipment collected from sensor readings severely hinders the cognitive capabilities of discriminative artificial intelligence (AI) for PHM. Data augmentation and generation (DA&G) techniques, represented by generative AI, have shown great promise in overcoming the limitations of PHM application scenarios. Research on DA&G has yielded significant achievements, but a comprehensive review in the mechanical field is still lacking. To this end, this paper provides a comprehensive review of DA&G techniques aimed at solving the DDP problems, which are divided into three categories insights of data, mechanism, and features. The data-based randomized approach applies controlled randomness for augmentation. The mechanism-based domain-specific techniques advocate for exploring relationships between the physical entity and monitoring data for generating by reasoned inference. The feature-based generative model aims to identify the latent space of data and subsequently resample it. Finally, the paper explores strategies for evaluating DA&G and provides a deep insight into the challenges and opportunities of DA&G techniques.}
}
@article{DAS2025102546,
title = {Generative artificial intelligence, integrative bioinformatics, and single-cell analysis reveal Alzheimer’s genetic and immune landscape},
journal = {Molecular Therapy Nucleic Acids},
volume = {36},
number = {2},
pages = {102546},
year = {2025},
issn = {2162-2531},
doi = {https://doi.org/10.1016/j.omtn.2025.102546},
url = {https://www.sciencedirect.com/science/article/pii/S2162253125001003},
author = {Arpita Das and Manojit Bhattacharya and Ali Saber Abdelhameed and Sang-Soo Lee and Chiranjib Chakraborty},
keywords = {Bioinformatics, GenAI, single-cell analysis, Alzheimer’s disease, genetic and immune landscape},
abstract = {The research aims to understand Alzheimer’s genetic and immune landscapes using the amalgamation of three technologies: artificial intelligence (GenAI), integrative bioinformatics, and single-cell analysis. First, the study aims to identify and characterize the significant genes associated with Alzheimer’s disease (AD) using three GenAI models (GPT‑4o, Gemini model, and DeepSeek). After the genes were accumulated from GenAI models, 27 genes associated with AD were recoded. Furthermore, they were analyzed using integrative bioinformatics methods. Similarly, the immune landscape of AD using single-cell analysis was also explored, which reveals a high percentage of effector CD8+ T cells (33.42%) and naive T cells (45.95%). The single-cell study found that effector memory T cells have two subsets. It also found that the macrophage population has started to spread and dendritic cells have decreased in Alzheimer’s patients. The single-cell gene expression study reveals the top ten highly expressed genes (NDUFV2, CAT, MRPS34, PBX3, THOC2, CCDC57, PBXIP1, SDHAF3, PPP4C, and MAP3K8). The clonal frequency indicates that CD8+ T and naive T cell populations show the highest clonal frequency in healthy and AD individuals and are further noted them in the clonotype cell proportion study. Following our GenAI and single-cell profiling strategy, future studies will help in quickly understanding the genetic and immune basis of many diseases.}
}
@article{WONG2024100278,
title = {The sudden disruptive rise of generative artificial intelligence? An evaluation of their impact on higher education and the global workplace},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {10},
number = {2},
pages = {100278},
year = {2024},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2024.100278},
url = {https://www.sciencedirect.com/science/article/pii/S2199853124000726},
author = {Wilson Kia Onn Wong},
keywords = {GAI, Disruptive, GPT, LLMs, “AI-optimists”, “AI-sceptics”},
abstract = {This paper evaluates the rise of “Generative Artificial Intelligence” (GAI) in its myriad forms, with the highest profile being the “Large Language Models” (LLMs). More importantly, it analyses the potentially disruptive impact of this ascendant technology on higher education and the global workplace. The findings of this paper indicate that students pursuing higher education tend to perceive GAI favourably, as it frees them from the toil of rote-learning. However, the view is rather mixed in the case of educators, who are still coming to grips with this seemingly disruptive technology. In the case of the global labour market, GAI has the potential to decimate legions of white-collar jobs once it eliminates inherent issues of biases, security and misinformation. Despite the media’s constant labelling of GAI as a disruptive technology that has suddenly burst onto the technological scene, it is evidenced in this paper that the technology has taken nearly eight decades to reach today’s level of technological advancement. Further, it is far from reaching its full potential, as it is still incorporating advances in pattern recognition, planning and problem solving, and quantum computing technologies. This study also warns of concentrating the power of this game-changing technology in the hands of a few major corporate titans.}
}
@article{KOHNKE2025108600,
title = {Enhancing the emotional aspects of language education through generative artificial intelligence (GenAI): A qualitative investigation},
journal = {Computers in Human Behavior},
volume = {167},
pages = {108600},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108600},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225000470},
author = {Lucas Kohnke and Benjamin Luke Moorhouse},
keywords = {GenAI, Motivation, Emotions, Positive psychology},
abstract = {This qualitative study investigates the impact of generative artificial intelligence (GenAI) on the emotional engagement, motivation and well-being of first-year university students in Hong Kong. We conducted semi-structured interviews with 21 students and three instructors to explore their perceptions of how GenAI influences the affective dimensions of language learning. The data were analyzed using manual coding and inductive thematic analysis to identify key themes. The findings revealed that GenAI generally enhances students’ motivation, reduces anxiety and stress, and fosters an emotionally supportive learning environment. However, challenges related to cultural context and technical issues were also identified. The study highlights the pivotal role of instructors in shaping students’ experiences with GenAI and underscores the need for ongoing support and professional development. It also demonstrates the importance of cultural sensitivity, technological infrastructure and balance. The study is valuable for those who aim to harness GenAI while preserving the irreplaceable human elements of teaching. It contributes to the growing body of knowledge on integrating AI in language learning.}
}
@article{ROBINSON2025390,
title = {Response Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {390-391},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001337},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines}
}
@article{LEE2024102846,
title = {Generating TRIZ-inspired guidelines for eco-design using Generative Artificial Intelligence},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102846},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102846},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624004944},
author = {C.K.M. Lee and Jingying Liang and K.L. Yung and K.L. Keung},
keywords = {Eco-design, TRIZ, Large Language Models, Generative AI},
abstract = {Environmental considerations are emerging as stimuli for innovation during the eco-design ideation process. Integrating TRIZ (Teoriya Resheniya Izobretatelskikh Zadatch─Theory of Inventive Problem Solving) methodology into eco-design offers a structured problem-solving approach to address sustainability challenges. However, developing innovative designs requires expertise in TRIZ concepts and access to resources, which makes it a time-consuming process and can limit its application for eco-design innovation quickly. This study leverages the analytical and generative capabilities of large language models (LLMs) to enhance the TRIZ methodology and automate the ideation process in eco-design. An intelligent tool, “Eco-innovate Assistant,” is designed to provide users with eco-innovative solutions with design sketches. Its effectiveness is validated and evaluated through comparative studies. The findings demonstrate the potential of LLMs in automating design processes, catalyzing a transformation in AI-driven innovation and ideation in eco-design.}
}
@article{KHOSRAVI2024101503,
title = {Analyzing Racial Differences in Imaging Joint Replacement Registries Using Generative Artificial Intelligence: Advancing Orthopaedic Data Equity},
journal = {Arthroplasty Today},
volume = {29},
pages = {101503},
year = {2024},
issn = {2352-3441},
doi = {https://doi.org/10.1016/j.artd.2024.101503},
url = {https://www.sciencedirect.com/science/article/pii/S2352344124001882},
author = {Bardia Khosravi and Pouria Rouzrokh and Bradley J. Erickson and Hillary W. Garner and Doris E. Wenger and Michael J. Taunton and Cody C. Wyles},
keywords = {Generative AI, Explainability, Dataset curation, Equity, Bias},
abstract = {Background
Discrepancies in medical data sets can perpetuate bias, especially when training deep learning models, potentially leading to biased outcomes in clinical applications. Understanding these biases is crucial for the development of equitable healthcare technologies. This study employs generative deep learning technology to explore and understand radiographic differences based on race among patients undergoing total hip arthroplasty.
Methods
Utilizing a large institutional registry, we retrospectively analyzed pelvic radiographs from total hip arthroplasty patients, characterized by demographics and image features. Denoising diffusion probabilistic models generated radiographs conditioned on demographic and imaging characteristics. Fréchet Inception Distance assessed the generated image quality, showing the diversity and realism of the generated images. Sixty transition videos were generated that showed transforming White pelvises to their closest African American counterparts and vice versa while controlling for patients’ sex, age, and body mass index. Two expert surgeons and 2 radiologists carefully studied these videos to understand the systematic differences that are present in the 2 races’ radiographs.
Results
Our data set included 480,407 pelvic radiographs, with a predominance of White patients over African Americans. The generative denoising diffusion probabilistic model created high-quality images and reached an Fréchet Inception Distance of 6.8. Experts identified 6 characteristics differentiating races, including interacetabular distance, osteoarthritis degree, obturator foramina shape, femoral neck-shaft angle, pelvic ring shape, and femoral cortical thickness.
Conclusions
This study demonstrates the potential of generative models for understanding disparities in medical imaging data sets. By visualizing race-based differences, this method aids in identifying bias in downstream tasks, fostering the development of fairer healthcare practices.}
}
@article{SHLOBIN2024e769,
title = {Ethical Incorporation of Artificial Intelligence into Neurosurgery: A Generative Pretrained Transformer Chatbot-Based, Human-Modified Approach},
journal = {World Neurosurgery},
volume = {187},
pages = {e769-e791},
year = {2024},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2024.04.165},
url = {https://www.sciencedirect.com/science/article/pii/S1878875024007381},
author = {Nathan A. Shlobin and Max Ward and Harshal A. Shah and Ethan D.L. Brown and Daniel M. Sciubba and David Langer and Randy S. D'Amico},
keywords = {Bioethics, ChatGPT, Deep learning, Machine learning, Medical ethics, Neurologic surgery},
abstract = {Introduction
Artificial intelligence (AI) has become increasingly used in neurosurgery. Generative pretrained transformers (GPTs) have been of particular interest. However, ethical concerns regarding the incorporation of AI into the field remain underexplored. We delineate key ethical considerations using a novel GPT-based, human-modified approach, synthesize the most common considerations, and present an ethical framework for the involvement of AI in neurosurgery.
Methods
GPT-4, ChatGPT, Bing Chat/Copilot, You, Perplexity.ai, and Google Bard were queried with the prompt “How can artificial intelligence be ethically incorporated into neurosurgery?”. Then, a layered GPT-based thematic analysis was performed. The authors synthesized the results into considerations for the ethical incorporation of AI into neurosurgery. Separate Pareto analyses with 20% threshold and 10% threshold were conducted to determine salient themes. The authors refined these salient themes.
Results
Twelve key ethical considerations focusing on stakeholders, clinical implementation, and governance were identified. Refinement of the Pareto analysis of the top 20% most salient themes in the aggregated GPT outputs yielded 10 key considerations. Additionally, from the top 10% most salient themes, 5 considerations were retrieved. An ethical framework for the use of AI in neurosurgery was developed.
Conclusions
It is critical to address the ethical considerations associated with the use of AI in neurosurgery. The framework described in this manuscript may facilitate the integration of AI into neurosurgery, benefitting both patients and neurosurgeons alike. We urge neurosurgeons to use AI only for validated purposes and caution against automatic adoption of its outputs without neurosurgeon interpretation.}
}
@article{REN2024100073,
title = {Rapid estimation of γ' solvus temperature for composition design of Ni-based superalloy via physics-informed generative artificial intelligence},
journal = {Journal of Alloys and Metallurgical Systems},
volume = {6},
pages = {100073},
year = {2024},
issn = {2949-9178},
doi = {https://doi.org/10.1016/j.jalmes.2024.100073},
url = {https://www.sciencedirect.com/science/article/pii/S2949917824000208},
author = {Yunfei Ren and Tao Hu and Songzhe Xu and Chaoyue Chen and Weidong Xuan and Zhongming Ren},
keywords = {Ni-based superalloy, γ' Solvus temperature, Composition deviation index, Generative artificial intelligence, Thermodynamic calculation},
abstract = {The exceptional high-temperature mechanical properties of Ni-based superalloys are mainly stemmed from the L12 γ' phase, therefore it is crucial to discover Ni-based superalloys with high γ' solvus temperatures. Utilizing generative artificial intelligence, we have developed a framework to swiftly evaluate the γ' solvus temperature and tailor Ni-based superalloys, accelerating the process of discovering Ni-based superalloys. Physics-informed artificial neural network emerged as the optimal choice for reverse engineering, outperforming other models with an R2 score of 0.917 and a mean absolute error of 15 K. In the reverse design process, 20,000 virtual alloy samples were generated based on divide-and-conquer variational autoencoder which divides the dataset into distinct clusters by K-means algorithm provides a structured representation of the alloy composition space, thereby facilitating a more nuanced understanding of its inherent complexities. In a specific alloy design example, 563 samples were identified through screening based on criteria like γ' solvus temperature, composition deviation index, price, and density. Thermodynamic calculations were used to further screen Ni-based superalloys with exceptional high-temperature properties. The showcase of BA alloy discovery through generative artificial intelligence demonstrates the potential of our research to steer the creation of novel compositions for Ni-based superalloys with outstanding high-temperature properties.}
}
@article{HEINKE2024100089,
title = {A review of ophthalmology education in the era of generative artificial intelligence},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100089},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100089},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000902},
author = {Anna Heinke and Niloofar Radgoudarzi and Bonnie B. Huang and Sally L. Baxter},
keywords = {Generative AI, Large Language Models (LLMs), Ophthalmology Education, Artificial Intelligence (AI)},
abstract = {Purpose
To explore the integration of generative AI, specifically large language models (LLMs), in ophthalmology education and practice, addressing their applications, benefits, challenges, and future directions.
Design
A literature review and analysis of current AI applications and educational programs in ophthalmology.
Methods
Analysis of published studies, reviews, articles, websites, and institutional reports on AI use in ophthalmology. Examination of educational programs incorporating AI, including curriculum frameworks, training methodologies, and evaluations of AI performance on medical examinations and clinical case studies.
Results
Generative AI, particularly LLMs, shows potential to improve diagnostic accuracy and patient care in ophthalmology. Applications include aiding in patient, physician, and medical students’ education. However, challenges such as AI hallucinations, biases, lack of interpretability, and outdated training data limit clinical deployment. Studies revealed varying levels of accuracy of LLMs on ophthalmology board exam questions, underscoring the need for more reliable AI integration. Several educational programs nationwide provide AI and data science training relevant to clinical medicine and ophthalmology.
Conclusions
Generative AI and LLMs offer promising advancements in ophthalmology education and practice. Addressing challenges through comprehensive curricula that include fundamental AI principles, ethical guidelines, and updated, unbiased training data is crucial. Future directions include developing clinically relevant evaluation metrics, implementing hybrid models with human oversight, leveraging image-rich data, and benchmarking AI performance against ophthalmologists. Robust policies on data privacy, security, and transparency are essential for fostering a safe and ethical environment for AI applications in ophthalmology.}
}
@article{GUNTUKA2024140,
title = {Application of Generative Artificial Intelligence in Minimizing Cyber Attacks on Vehicular Networks},
journal = {Procedia Computer Science},
volume = {251},
pages = {140-149},
year = {2024},
note = {15th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 14th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare EUSPN/ICTH 2024},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.11.094},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924033283},
author = {Sony Guntuka and Elhadi Shakshuki},
keywords = {Cyber attacks, GenAI, Vehicular Networks},
abstract = {This paper explores the innovative applications of Generative Artificial Intelligence (GenAI) for strengthening the cybersecurity of vehicular networks. With the advent of intelligent transport systems and autonomous vehicles, the cybersecurity landscape has evolved significantly, which necessitating new strategies to tackle sophisticated threats. GenAI provides advanced capabilities for automating defenses, enhancing threat intelligence, and fostering dynamic security frameworks in vehicular networks. However, the incorporation of GenAI also introduces new risks, requiring robust ethical, legal, and technical oversight. This research paper outlines the current state of GenAI in vehicular network cybersecurity, showcases the Vehicular Threat Intelligence Flowchart (VTIF), focuses on the threat detection rule algorithm in VTIF, highlights the potential benefits and challenges, and proposes future research directions for developing resilient and ethical cybersecurity mechanisms.}
}
@article{ANDERSEN2025102813,
title = {Generative Artificial Intelligence (GenAI) in the research process – A survey of researchers’ practices and perceptions},
journal = {Technology in Society},
volume = {81},
pages = {102813},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102813},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2500003X},
author = {Jens Peter Andersen and Lise Degn and Rachel Fishberg and Ebbe K. Graversen and Serge P.J.M. Horbach and Evanthia Kalpazidou Schmidt and Jesper W. Schneider and Mads P. Sørensen},
keywords = {Generative Artificial Intelligence (GenAI), Research process, Research practice, use cases, Research integrity},
abstract = {This study explores the use of generative AI (GenAI) and research integrity assessments of use cases by researchers, including PhD students, at Danish universities. Conducted through a survey sent to all Danish researchers from January to February 2024, the study received 2534 responses and evaluated 32 GenAI use cases across five research phases: idea generation, research design, data collection, data analysis, and writing/reporting. Respondents reported on their own and colleagues' GenAI usage. They also assessed whether the practices in the use cases were considered good research practice. Through an explorative factor analysis, we identified three clusters of perception: "GenAI as a work horse", "GenAI as a language assistant only", and "GenAI as a research accelerator". The findings further show varied opinions on GenAI's research integrity implications. Language editing and data analysis were generally viewed positively, whereas experiment design and peer review tasks faced more criticism. Controversial areas included image creation/modification and synthetic data, with comments highlighting the need for critical and reflexive use of GenAI. Usage differed by main research area, with technical and quantitative sciences reporting slightly higher usage and more positive assessments. Junior researchers used GenAI more than senior colleagues, while no significant gender differences were observed. The study underscores the need for adaptable, discipline-specific guidelines for GenAI use in research, developed collaboratively with experts to align with diverse research practices and minimize ethical and practical misalignment.}
}
@article{PATEL2024105791,
title = {Generative artificial intelligence versus clinicians: Who diagnoses multiple sclerosis faster and with greater accuracy?},
journal = {Multiple Sclerosis and Related Disorders},
volume = {90},
pages = {105791},
year = {2024},
issn = {2211-0348},
doi = {https://doi.org/10.1016/j.msard.2024.105791},
url = {https://www.sciencedirect.com/science/article/pii/S2211034824003687},
author = {Mahi A. Patel and Francisco Villalobos and Kevin Shan and Lauren M. Tardo and Lindsay A. Horton and Peter V. Sguigna and Kyle M. Blackburn and Shanan B. Munoz and Tatum M. Moog and Alexander D. Smith and Katy W. Burgess and Morgan McCreary and Darin T. Okuda},
keywords = {Multiple sclerosis, Artificial intelligence, ChatGPT, Diagnosis, Generative AI},
abstract = {Background
Those receiving the diagnosis of multiple sclerosis (MS) over the next ten years will predominantly be part of Generation Z (Gen Z). Recent observations within our clinic suggest that younger people with MS utilize online generative artificial intelligence (AI) platforms for personalized medical advice prior to their first visit with a specialist in neuroimmunology. The use of such platforms is anticipated to increase given the technology driven nature, desire for instant communication, and cost-conscious nature of Gen Z. Our objective was to determine if ChatGPT (Generative Pre-trained Transformer) could diagnose MS in individuals earlier than their clinical timeline, and to assess if the accuracy differed based on age, sex, and race/ethnicity.
Methods
People with MS between 18 and 59 years of age were studied. The clinical timeline for people diagnosed with MS was retrospectively identified and simulated using ChatGPT-3.5 (GPT-3.5). Chats were conducted using both actual and derivatives of their age, sex, and race/ethnicity to test diagnostic accuracy. A Kaplan-Meier survival curve was estimated for time to diagnosis, clustered by subject. The p-value testing for differences in time to diagnosis was accomplished using a general Wilcoxon test. Logistic regression (subject-specific intercept) was used to capture intra-subject correlation to test the accuracy prior to and after the inclusion of MRI data.
Results
The study cohort included 100 unique people with MS. Of those, 50 were members of Gen Z (38 female; 22 White; mean age at first symptom was 20.6 years (y) (standard deviation (SD)=2.2y)), and 50 were non-Gen Z (34 female; 27 White; mean age at first symptom was 37.0y (SD=10.4y)). In addition, a total of 529 people that represented digital simulations of the original cohort of 100 people (333 female; 166 White; 136 Black/African American; 107 Asian; 120 Hispanic, mean age at first symptom was 31.6y (SD=12.4y)) were generated allowing for 629 scripted conversations to be analyzed. The estimated median time to diagnosis in clinic was significantly longer at 0.35y (95% CI=[0.28, 0.48]) versus that by ChatGPT at 0.08y (95% CI=[0.04, 0.24]) (p<0.0001). There was no difference in the diagnostic accuracy between ages and by race/ethnicity prior to the inclusion of MRI data. However, prior to including the MRI data, males had a 47% less likely chance of a correct diagnosis relative to females (p=0.05). Post-MRI data inclusion within GPT-3.5, the odds of an accurate diagnosis was 4.0-fold greater for Gen Z participants, relative to non-Gen Z participants (p=0.01) with the diagnostic accuracy being 68% less in males relative to females (p=0.009), and 75% less for White subjects, relative to non-White subjects (p=0.0004).
Conclusion
Although generative AI platforms enable rapid information access and are not principally designed for use in healthcare, an increase in use by Gen Z is anticipated. However, the obtained responses may not be generalizable to all users and bias may exist in select groups.}
}
@article{LAW2024100174,
title = {Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review},
journal = {Computers and Education Open},
volume = {6},
pages = {100174},
year = {2024},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2024.100174},
url = {https://www.sciencedirect.com/science/article/pii/S2666557324000156},
author = {Locky Law},
keywords = {Generative AI, AI, Language education, Scoping review, Content generation, ChatGPT},
abstract = {This scoping literature review examines the application of Generative Artificial Intelligence (GenAI), a disruptive technology, in language teaching and learning. Since its launch in November 2022, GenAI has captured global attention with OpenAI's ChatGPT, powered by the generative pre-trained transformer-3 (GPT-3) large-language model. The emergence of GenAI holds immense implications across various domains, including language education. This review aims to provide an overview of the current state of research and identify research gaps and future directions in this emerging field. The review follows the PRISMA-ScR guidelines and includes eligible publications published between 2017 and July 2023. Four electronic databases were searched and 41 of the 224 initial papers were eventually selected for review. The findings reveal key terms related to GenAI in language education, the most researched language study and education levels, areas of research, attitudes towards GenAI, and the potential benefits and challenges of GenAI application. The review highlights several research gaps, including the need for more empirical studies to assess the effectiveness and impact of GenAI tools, discussion of ethical considerations, targeted interventions for specific language skills, and stakeholder engagement in responsible integration. Educators are encouraged to incorporate GenAI tools into their teaching practices while remaining vigilant about potential risks. Continuous professional development for educators is crucial to ensure informed decision-making and effective integration of GenAI tools. This scoping review contributes to the existing knowledge on the use of GenAI in language education and informs future research and practice in this disruptive and rapidly evolving field.}
}
@article{GHANBARI2025101901,
title = {Free-breathing single-beat exercise cardiovascular magnetic resonance with generative artificial intelligence for evaluation of volumetric and functional cardiac indices: A reproducibility study},
journal = {Journal of Cardiovascular Magnetic Resonance},
volume = {27},
number = {1},
pages = {101901},
year = {2025},
issn = {1097-6647},
doi = {https://doi.org/10.1016/j.jocmr.2025.101901},
url = {https://www.sciencedirect.com/science/article/pii/S1097664725000638},
author = {Fahime Ghanbari and Alexander Schulz and Manuel A. Morales and Jennifer Rodriguez and Jordan A. Street and Kathryn Arcand and Scott Johnson and Patrick Pierce and Christopher W. Hoeger and Connie W. Tsao and Warren J. Manning and Reza Nezafat},
keywords = {Exercise-CMR, Free-breathing single-beat cine, Biventricular volumetric and functional indices},
abstract = {Background
Exercise cardiovascular magnetic resonance (Ex-CMR) can reveal pathophysiologies not evident at rest by quantifying biventricular volume and function during or immediately after exercise. However, achieving reproducible Ex-CMR measurements is challenging due to limited spatial and temporal resolution. This study aimed to develop and evaluate a free-breathing, high-spatiotemporal-resolution single-beat Ex-CMR cine enhanced by generative artificial intelligence. We assessed image analysis reproducibility, scan-rescan reproducibility, and impact of the reader's experience on the analysis.
Methods
Imaging was performed on a 3T CMR system using a free-breathing, highly accelerated, multi-slice, single-beat cine sequence (in-plane spatiotemporal resolution of 1.9 × 1.9 mm² and 37 ms, respectively). High acceleration was achieved by combining compressed sensing reconstruction with a resolution-enhancement generative adversarial inline neural network. Ex-CMR was performed using a supine ergometer positioned immediately outside the magnet bore. Single-beat cine images were acquired at rest and immediately post-exercise. In a prospective study, the protocol was evaluated in 141 subjects. A structured image analysis workflow was implemented. Four expert readers, with or without prior training in single-beat Ex-CMR, independently rated all images for diagnostic and image quality. The subjective assessment used two 3-point Likert scales. Biventricular parameters were calculated. Inter- and intra-observer reproducibility were assessed. Fifteen healthy subjects were re-imaged 1 year later for scan-rescan reproducibility. Reproducibility was assessed using intraclass correlation coefficient (ICC), with agreement evaluated via Bland-Altman analysis, linear regression, and Pearson correlation.
Results
Free-breathing, single-beat Ex-CMR cine enabled imaging of the beating heart within 30 ± 6 s, with technically successful scans in 96% (136/141) of subjects. Post-exercise single-beat cine images were assessed as diagnostic in 98% (133/136), 96% (131/136), 82% (112/136), and 65% (89/136) of cases by four readers (ordered by descending years of Ex-CMR experience). Good image quality was reported in 74% (100/136) to 80% (109/136) of subjects. Biventricular parameters were successfully measured in all subjects, demonstrating good to excellent inter-observer reproducibility. Scan/rescan reproducibility over 1 year, assessed by two independent readers, showed excellent inter-visit ICCs (0.96–1.0) and strong correlations (R² ≥ 0.92, p < 0.001 for left ventricle; R² ≥ 0.95, p < 0.001 for right ventricle).
Conclusion
Single-beat Ex-CMR enabled evaluation of biventricular volumetric and functional indices with excellent reproducibility.}
}
@article{CHUNG2025S-173,
title = {742: RANDOMIZED CONTROLLED TRIAL EVALUATING THE EFFICACY OF HUMAN-GENERATIVE ARTIFICIAL INTELLIGENCE TEAMING ON TECHNOLOGY ACCEPTANCE, USABILITY, AND TRUST: THE GUT-GPT SIMULATION STUDY},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-173},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01346-0},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525013460},
author = {Sunny Chung and Niroop Rajashekar and Yuan Pu and Yeo Eun Shin and Mauro Giuffrè and Colleen Chan and Kisung You and Theo Saarinen and Allen Hsiao and Jasjeet Sekhon and Ambrose Wong and Leigh Evans and Terika McCall and Rene F. Kizilcec and Loren Laine and Dennis Shung}
}
@article{CHAN2025102733,
title = {Generative artificial intelligence in a VUCA world: the ‘Lived Experiences’ of Southeast Asian teachers’ use of AI in higher education},
journal = {International Journal of Educational Research},
volume = {133},
pages = {102733},
year = {2025},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2025.102733},
url = {https://www.sciencedirect.com/science/article/pii/S088303552500206X},
author = {Nee Nee Chan and Richard Peter Bailey and Mabel Hwee Joo Tan and Genevieve Flores Dipolog and Garry Wei Han Tan and Saeid Motevalli and Nadia Samsudin and Chin Siang Ang},
keywords = {ChatGPT, Hermeneutic phenomenology, VUCA model, Educational quality, AI policy guidelines},
abstract = {This study explores how generative intelligence (GenAI) is used in teaching and learning, assessments, and research at Southeast Asian (SEA) universities. Using hermeneutic phenomenology as the philosophical underpinning and research methodology, SEA teachers’ ‘lived experiences’ of using ChatGPT and other GenAI tools were uncovered. 38 teachers from 10 SEA countries participated in 11 focus group interviews over five months. Three themes emerged: Learning Anew; Disequilibrium and Lack of Rootedness; and Ambiguity about New Norms, New Practices. It was found that teachers work with GenAI in deeply personal, fragmented, and continuously evolving ways. GenAI took the form of novel work companions, enhancing the efficiency and effectiveness of some work practices. It also was a disruptor to old habits of thinking, behaviour and practices. Teachers were in a state of disequilibrium in this new world beset by VUCA (volatility, uncertainty, complexity, and ambiguity). Some felt overwhelmed and ‘at breaking point’. A lack of rootedness in teachers’ beliefs and practices emerged. Teachers were generally against the notions of plagiarism and academic integrity held by students who believed the ends justified the means. However, with new ways of teaching, learning and assessment, many teachers recognised their beliefs and practices would have to change. Thus, in the absence of detailed AI guidelines, they called for the urgent need to establish boundaries and teach AI literacy to promote innovative and responsible use. In this VUCA world, more targeted change management training for teachers and students was strongly needed.}
}
@article{HASAN2025,
title = {Governance of Generative Artificial Intelligence:},
journal = {International Journal of Knowledge Management},
volume = {21},
number = {1},
year = {2025},
issn = {1548-0666},
doi = {https://doi.org/10.4018/IJKM.383061},
url = {https://www.sciencedirect.com/science/article/pii/S1548066625000359},
author = {A K M Kamrul Hasan},
keywords = {Knowledge Management, Knowledge Management System, Generative Artificial Intelligence (GenAI), Governance Structure, Institutional Economics},
abstract = {ABSTRACT
The field of knowledge management and knowledge management systems is evolving and dynamic. In the era of developed information technology systems, the dynamics of knowledge creation and dissemination have also changed. Generative artificial intelligence (GenAI)—an embedded entity in the knowledge management system—has become a prominent area of research nowadays, while accountability, transparency, and ethics are common research agendas in institutional economics related to GenAI. The research in this paper has investigated the convictions behind GenAI adoption and how to develop a GenAI governance framework. The research adopts a qualitative approach to investigate the problem and surveys undergraduate students to explore their motive for using GenAI. The study sheds analytical light on institutional economists’ view on the governance of GenAI. The study has found a positive relationship between perceived benefits and the adoption of GenAI in education by students. The theoretical model will have a considerable impact on the ongoing debate on the governance of GenAI and knowledge management systems.}
}
@article{LIM2025105306,
title = {Development and implementation of a generative artificial intelligence-enhanced simulation to enhance problem-solving skills for pre-service teachers},
journal = {Computers & Education},
volume = {232},
pages = {105306},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105306},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000740},
author = {Jieun Lim and Unggi Lee and Junbo Koh and Yeil Jeong and Yunseo Lee and Gyuri Byun and Haewon Jung and Yoonsun Jang and Sanghyeok Lee and Jewoong Moon},
keywords = {Generative AI, Virtual simulation, Teacher education, Problem-based learning, Design-based research},
abstract = {Effective teachers should be equipped to solve complex problems across diverse instructional and learning contexts. However, many teacher training programs struggle to bridge the gap between theoretical knowledge to real-world applications. The current study tackles this challenge by developing a generative artificial intelligence (GenAI)-enhanced simulation to improve preservice teachers’ problem-solving abilities. Using design-based research (DBR), we created a virtual environment that integrates problem-based learning (PBL) with GenAI technology. The simulation was rigorously refined through expert review and usability testing before being implemented in a teacher training program. We evaluated its effectiveness by comparing three groups: (1) a text-based scenario, (2) a rule-based simulation, and (3) a GenAI-enhanced simulation. Pre- and post-test results showed significant improvements in problem-solving skills for both the rule-based and GenAI-enhanced simulation groups compared to the text-based scenario group. Notably, qualitative findings revealed that students reported heightened realism and immersion in the GenAI-enhanced simulation, attributing this to more dynamic interactions with AI agents that helped them better contextualize PBL and increased their motivation. Our study findings contribute design principles for developing GenAI-enhanced simulations in teacher education, offering promising insights into leveraging AI technology to create more engaging and effective training experiences.}
}
@incollection{LEEFRANCISS2025237,
title = {Chapter 13 - Generative artificial intelligence in genetics: A comprehensive review},
editor = {Khalid Raza},
booktitle = {Deep Learning in Genetics and Genomics},
publisher = {Academic Press},
pages = {237-247},
year = {2025},
isbn = {978-0-443-27523-4},
doi = {https://doi.org/10.1016/B978-0-443-27523-4.00005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443275234000056},
author = {Nicholas {Lee Franciss}},
keywords = {Generative artificial intelligence, Generative pretrained transformers, Large language models, Model architecture, Transformers},
abstract = {Generative artificial intelligence (GenAI) is revolutionizing genetics by applying the computational capabilities of predictive algorithms to unveil the genome's intricate complexities. From protein prediction to gene discovery and motif detection, GenAI techniques are transforming our understanding of genetic processes that were not previously possible. Here we explore how Markov chains, long-standing predecessors of more modern technologies like large language models (LLMs) and generative pretrained transformers (GPTs), have been complemented by these advanced methods, empowering researchers to extract unprecedented levels of information from DNA sequences, including regulatory networks that govern gene expression. We dive deep into how the individual model architectures enable their capability to implicitly understand and generate biological data. The cultural and intellectual implications of DeepMind's AlphaFold on the prediction of three-dimensional protein structures and, with it, its cultural impact on generative approaches in protein design and is also explored.}
}
@article{LI2024118988,
title = {Inverse design of cellular structures with the geometry of triply periodic minimal surfaces using generative artificial intelligence algorithms},
journal = {Engineering Structures},
volume = {321},
pages = {118988},
year = {2024},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2024.118988},
url = {https://www.sciencedirect.com/science/article/pii/S0141029624015505},
author = {Zhou Li and Junhao Li and Jiahao Tian and Shiqi Xia and Kai Li and Maojun Li and Yao Lu and Mengyuan Ren and Zhengyi Jiang},
keywords = {Triply periodic minimal surface, Generative artificial intelligence algorithms, Additive manufacturing, Inverse design, Numerical simulation},
abstract = {Triply periodic minimal surfaces (TPMS) exhibit excellent mechanical and energy absorption properties due to their structural advantages. However, existing porous TPMS structural design methods are constrained to a forward process from structural parameters to mechanical properties. This study proposed an inverse design method that combines bidirectional generative adversarial networks (BiGAN) and mechanical performance targets, resulting in a combined TPMS structure of Primitive and IWP types with superior buffering and energy absorption capabilities. The results show that under a single load value target condition of the designed structure, the minimum deviation index (R2) between the load value corresponding to the displacement point and the target load value is only 0.987, and the maximum mean absolute percentage error (MAPE) is only 5.92 %. When considering the elastic modulus target, the approach successfully conducts two sets of combined structural designs meeting the requirements of both high and low elastic moduli. When targeting the specified load-displacement curve conditions, specifically when combining high elastic modulus with ascending plasticity, the designed structures exhibit an error of only 2.2 % compared to the target property. Moreover, the quasi-static uniaxial compression experiments conducted on additively manufactured designed structures confirm that the experimental curves match the target curves in terms of deformation trends and load value ranges. The success of this inverse design approach for cellular TPMS structures has the potential to expedite new structural material development processes.}
}
@article{HUESO2023309,
title = {Is Generative Artificial Intelligence the Next Step Toward a Personalized Hemodialysis?},
journal = {Revista de Investigación Clínica},
volume = {75},
number = {6},
pages = {309-317},
year = {2023},
issn = {0034-8376},
doi = {https://doi.org/10.24875/RIC.23000162},
url = {https://www.sciencedirect.com/science/article/pii/S0034837625001597},
author = {Miguel Hueso and Rafael Álvarez and David Marí and Vicent Ribas-Ripoll and Karim Lekadir and Alfredo Vellido},
keywords = {Personalized hemodialysis, Artificial intelligence, Natural language processing, Large Language Models},
abstract = {ABSTRACT
Artificial intelligence (AI) generative models driven by the integration of AI and natural language processing technologies, such as OpenAI’s chatbot generative pre-trained transformer large language model (LLM), are receiving much public attention and have the potential to transform personalized medicine. Dialysis patients are highly dependent on technology and their treatment generates a challenging large volume of data that has to be analyzed for knowledge extraction. We argue that, by integrating the data acquired from hemodialysis treatments with the powerful conversational capabilities of LLMs, nephrologists could personalize treatments adapted to patients’ lifestyles and preferences. We also argue that this new conversational AI integrated with a personalized patient-computer interface will enhance patients’ engagement and self-care by providing them with a more personalized experience. However, generative AI models require continuous and accurate updates of data, and expert supervision and must address potential biases and limitations. Dialysis patients can also benefit from other new emerging technologies such as Digital Twins with which patients’ care can also be addressed from a personalized medicine perspective. In this paper, we will revise LLMs potential strengths in terms of their contribution to personalized medicine, and, in particular, their potential impact, and limitations in nephrology. Nephrologists’ collaboration with AI academia and companies, to develop algorithms and models that are more transparent, understandable, and trustworthy, will be crucial for the next generation of dialysis patients. The combination of technology, patient-specific data, and AI should contribute to create a more personalized and interactive dialysis process, improving patients’ quality of life. (REV INVEST CLIN. 2023;75(6):309-17)}
}
@article{QIN2024109996,
title = {Intelligent design and optimization system for shear wall structures based on large language models and generative artificial intelligence},
journal = {Journal of Building Engineering},
volume = {95},
pages = {109996},
year = {2024},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.109996},
url = {https://www.sciencedirect.com/science/article/pii/S235271022401564X},
author = {Sizhong Qin and Hong Guan and Wenjie Liao and Yi Gu and Zhe Zheng and Hongjing Xue and Xinzheng Lu},
keywords = {Intelligent design, Structural optimization, Shear wall structure, Large language model, Generative artificial intelligence},
abstract = {Intelligent design technology for shear wall structures has great potential for enhancing design efficiency and addressing the challenges of tedious and repetitive design tasks. Recently, there has been a surge in the development of this technology. However, existing deep learning-based design methods for shear wall structures suffer from poor quality and usability issues. To address these challenges, this study proposes an intelligent design and optimization system for shear wall structures based on large language models (LLMs) and generative artificial intelligence (AI). The system employs an LLM as the core controller, which interacts with engineers to interpret their language descriptions and translate them into executable computer code. Subsequently, the system utilizes the corresponding structural generation and optimization methods to accomplish intelligent design tasks automatically. Furthermore, the system incorporates such critical factors as the empirical rules, mechanical performance, and material consumption into the structural optimization process. A unique three-level, two-stage optimization method is constructed based on topology, pattern, and size to enhance the overall design quality. Being able to complete the entire workflow of architectural drawing processing, structural scheme generation, and analysis model establishment, the proposed system enables automated and efficient design of shear wall structures. Through the analysis and validation of multiple cases, it was demonstrated that this system can significantly speed up the design by approximately 30 times compared to that of traditional methods whilst ensuring the safety and cost-effectiveness of the design schemes. Consequently, this study provides valuable insights for the advancement of automated structural design undertakings.}
}
@article{KUMAR2025102078,
title = {Evaluating Generative Artificial Intelligence Query of Pelvic Congestion Syndrome Management},
journal = {Journal of Vascular Surgery: Venous and Lymphatic Disorders},
volume = {13},
number = {2},
pages = {102078},
year = {2025},
issn = {2213-333X},
doi = {https://doi.org/10.1016/j.jvsv.2024.102078},
url = {https://www.sciencedirect.com/science/article/pii/S2213333X24004980},
author = {Arjun Kumar and Besher Tolaymat and Katherine McMackin and Patrick Conroy and Laurel Hastings and Bruce Tjaden and Philip Batista and Joseph Lombardi}
}
@article{CARROLL2024102899,
title = {Integrating large language models and generative artificial intelligence tools into information literacy instruction},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {4},
pages = {102899},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102899},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000600},
author = {Alexander J. Carroll and Joshua Borycz},
keywords = {Generative artificial intelligence, Large language models, Information literacy, STEM education, Information retrieval, Critical thinking},
abstract = {Generative artificial intelligence (AI) and large language models (LLMs) have induced a mixture of excitement and panic among educators. However, there is a lack of consensus over how much experience science and engineering students have with using these tools for research-related tasks. Likewise, it is not yet known how educators and information professionals can leverage these tools to teach students strategies for information retrieval and knowledge synthesis. This study assesses the extent of students' use of AI tools in research-related tasks and if information literacy instruction could impact their perception of these tools. Responses to Likert-scale questions indicate that many students did not have extensive experience using LLMs for research-related purposes prior to the information literacy sessions. However, after participating in a didactic lecture and discussion with an engineering librarian that explored how to use these tools effectively and responsibly, many students reported viewing these tools as potentially useful for future assignments. Student responses to open-response questions suggest that librarian-led information literacy training can assist students in developing more sophisticated understandings of the limitations and use cases for artificial intelligence in inquiry-based coursework.}
}
@article{ZHANG20252238,
title = {Research on the impact of generative artificial intelligence (GenAI) on enterprise innovation performance: a knowledge management perspective},
journal = {Journal of Knowledge Management},
volume = {29},
number = {7},
pages = {2238-2257},
year = {2025},
issn = {1367-3270},
doi = {https://doi.org/10.1108/JKM-10-2024-1198},
url = {https://www.sciencedirect.com/science/article/pii/S136732702500033X},
author = {Qichao Zhang and Jiaxiang Zuo and Songlin Yang},
keywords = {Generative artificial intelligence, Knowledge management, Enterprise innovation performance, Human–AI collaboration},
abstract = {Purpose
This study aims to investigate the impact of generative artificial intelligence (GenAI) on enterprise innovation performance, particularly from the perspective of knowledge management. It addresses key challenges in GenAI adoption – such as data biases, information overload and technological dependence – and proposes strategies to overcome these obstacles to enhance innovation.
Design/methodology/approach
Adopting a theoretical approach, this research analyzes the role of knowledge management in bridging the gap between GenAI and enterprise innovation. A structured framework based on four essential knowledge management processes – knowledge creation, retrieval and storage, transfer and sharing and application – is developed to tackle these challenges effectively.
Findings
The study reveals that while GenAI presents both opportunities and challenges for enterprise innovation, leveraging a structured knowledge management framework is key to unlocking its potential. It underscores the critical role of human–AI collaboration in mitigating issues such as data biases and integration challenges, ultimately improving innovation performance. The findings highlight the importance of complementing AI capabilities with human judgment to ensure successful outcomes in GenAI-driven innovation.
Research limitations/implications
This conceptual study calls for further empirical research to validate the findings and expand their generalizability. Future studies should explore contextual factors such as organizational characteristics, business environments and policy frameworks to refine the proposed framework.
Originality/value
This research offers novel insights into the intersection of GenAI, knowledge management and enterprise innovation. It stresses the importance of human involvement alongside GenAI, providing actionable recommendations for organizations navigating the complexities of AI adoption. In addition, it contributes to the evolving discourse on AI and innovation management, offering pathways for businesses to harness GenAI’s full potential and drive performance.}
}
@article{OCHIENG2024102710,
title = {Potential application of generative artificial intelligence and machine learning algorithm in oil and gas sector: Benefits and future prospects},
journal = {Technology in Society},
volume = {79},
pages = {102710},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102710},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002586},
author = {Edward G. Ochieng and Diana Ominde and Tarila Zuofa},
keywords = {Generative artificial intelligence, Machine learning algorithm, Value chain operations, Oil and gas, Productivity performance, Risk management},
abstract = {With the rapid advancement of technology and societies, the global energy sector now acknowledges that by integrating contemporary digital technologies into their operations and capabilities, can improve their competitive advantage and innovation performance and processes. Moreover, energy operators are also facing a significant undertaking: how to best use and secure large amounts of data that promote sustainable productivity performance and minimise potential threats in the oil and gas value chain and project operations. In view of the foregoing, various facets like Generative Artificial Intelligence (GAI) and Machine Learning Algorithms (MLA) are increasingly gaining popularity within oil and gas sector operations. Thus, we explored how GAI and ML algorithms can enhance oil and gas value chain productivity performance. The Principal Component Analysis (PCA) was employed to identify significant GAI and MLA variables influencing performance in the oil and gas value chain, while Structural Equation Modelling (SEM) was used to test regression equations related to their application. The study found that risk portfolios and profiles can be appraised throughout the value chain by effectively utilising GAI and ML algorithms in upstream, midstream and downstream undertakings. While these findings are noteworthy and have significant implications for current practice, the paper advocates that an array of digital technologies beyond GAI and ML can still be examined during future studies to demonstrate a holistic perspective on how digital transformation can be achieved across the energy sector value and project operations.}
}
@article{ALHUSBAN202421,
title = {Exploring professional perspectives on integrating generative artificial intelligence into corporate learning and development: an organizational change perspective},
journal = {Development and Learning in Organizations: An International Journal},
volume = {39},
number = {2},
pages = {21-24},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-05-2024-0131},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000522},
author = {Mohammad Issa Alhusban and Hashem Alshurafat and Ibrahim N. Khatatbeh},
keywords = {Learning and development, Expert interviews, Organizational change, ChatGPT, Generative artificial intelligence},
abstract = {Purpose
The primary aim of this study is to investigate the integration of generative artificial intelligence, specifically ChatGPT, into workplace L&D practices, exploring the associated advantages and challenges such integration from an organizational change perspective.
Design/methodology/approach
This study uses a qualitative approach, conducting semi-structured interviews with twelve learning and development (L&D) experts.
Findings
This study indicates that ChatGPT can positively impact L&D by streamlining processes and potentially enhancing employee performance, engagement and satisfaction. However, to mitigate employee resistance, organizations must clearly communicate the necessity and rationale behind the change, involve employees in the implementation process and address trust issues. Key challenges such as overreliance on ChatGPT, AI skill shortages and technology issues like privacy breaches and misinformation must be managed through strong governance frameworks, including policies, guidelines and regular audits.
Research limitations/implications
The study’s scope is confined to semi-structured interviews with L&D experts, potentially limiting its generalizability. Further research could explore the long-term effects and broader implications of ChatGPT integration in different organizational contexts.
Practical implications
By framing GenAI integration within the context of organizational change, this study offers insights into managing the transition effectively by providing guidance for managers on effectively integrating ChatGPT into L&D practices, emphasizing the importance of mitigating potential negative consequences while maximizing benefits.
Social implications
Integrating ChatGPT into organizational L&D has the potential to reshape how employees acquire new skills and knowledge, potentially influencing organizational culture and dynamics. However, careful consideration is required to ensure that the integration process aligns with ethical and social norms, minimizing adverse impacts.
Originality/value
This research contributes foundational insights into the integration of ChatGPT in corporate L&D by researching and understanding the opinions of corporate professionals. It serves as a starting point for organizations to identify challenges in adopting GenAI.}
}
@article{RATTEN2023100857,
title = {Generative artificial intelligence (ChatGPT): Implications for management educators},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100857},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100857},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000952},
author = {Vanessa Ratten and Paul Jones},
keywords = {Academic research, Teaching, Learning, Digital transformation, Management education, Artificial intelligence, ChatGPT},
abstract = {ChatGPT has been one of the most talked about computer programs amongst management educators in recent weeks due to its transformative ability to change how assessments are undertaken and graded. Unlike other educational technologies that can be tracked when used, ChatGPT has superior abilities that make it virtually untraceable when used. This creates a dilemma for management educators wanting to utilise the technology whilst staying relevant but also interested in authentic learning. Thus, it is critical for management educators to quickly implement policies regarding ChatGPT and subsequent new generative artificial intelligence because of its ease of use and affordability. This article is conceptual in nature and discusses ChatGPT as a generative form of artificial intelligence that presents challenges for management educators that need to be addressed through appropriate strategies. Thereby contributing to the literature on how technological innovations can be included in curriculum design and management learning practices. Practical and managerial implications are stated that highlight the critical need to re-examine existing education practices as a way of incorporating new technological innovation that can be utilised in a beneficial way.}
}
@article{LI2024112,
title = {On the Application of Generative Artificial Intelligence ChatGPT in Digital Trade},
journal = {Procedia Computer Science},
volume = {247},
pages = {112-120},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S187705092402814X},
author = {Rui Li and Qiaoling Zhong},
keywords = {Generative Artificial Intelligence ChatGPT, Natural Language Processing, Customer Service, Dialogue Interaction},
abstract = {The combination of human subjective judgment and machine data processing capabilities in human-machine collaborative evaluation can create a more efficient, accurate, and personalized customer service dialogue interaction system, thereby promoting digital trade efficiency and improving service quality. Generative artificial intelligence has the ability of intelligent interaction and contextual semantic understanding, which is an important means of implementing the concept of human-machine collaboration. This article introduces the basic principles and technical characteristics of ChatGPT, and explores in detail its various application scenarios in digital trade, including automated customer service, personalized recommendations, intelligent marketing, and data analysis. Finally, this article also discusses the challenges and future development directions of ChatGPT in digital trade, in order to provide certain reference value for research and practice in related fields. The data from the questionnaire survey shows that men, aged between 18-30 and 41-50 years old, with high education level, high monthly online shopping expenses, high monthly income, and frequent use of well-known e-commerce platforms, generally have a high level of understanding of ChatGPT.}
}