@article{HUO2024,
title = {Generative Artificial Intelligence in Business Higher Education:},
journal = {Journal of Global Information Management},
volume = {32},
number = {1},
year = {2024},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.364093},
url = {https://www.sciencedirect.com/science/article/pii/S1062737524000416},
author = {Xuenan Huo and Keng Leng Siau},
keywords = {Generative Artificial Intelligence, Agentic Artificial Intelligence, Artificial General Intelligence, Focus Group Study, Qualitative Research, Business Higher Education},
abstract = {ABSTRACT
This research investigates the opportunities and challenges of integrating generative artificial intelligence (GenAI) into business higher education, drawing insights from an asynchronous focus group research study with doctoral students who serve dual roles as both learners and educators. Key opportunities identified through thematic analysis include knowledge acquisition, intelligent co-ideation, supportive augmentation, and personalized learning. Challenges identified include AI trustworthiness, cognitive dependency, human value, policy and instruction, assessment integrity, and identity management. This study clarifies GenAI’s specific role in business education and provides practical insights for effectively integrating GenAI to enhance learning outcomes and address emerging challenges. An analysis theory on the opportunities and challenges of GenAI on business higher education is developed and described in the paper. The potential impact of Agentic Artificial Intelligence (autonomous AI agents) and Artificial General Intelligence (AGI) on education is also discussed.}
}
@article{HEROLD2025101012,
title = {Brave new procurement deals: An experimental study of how generative artificial intelligence reshapes buyer–supplier negotiations},
journal = {Journal of Purchasing and Supply Management},
volume = {31},
number = {4},
pages = {101012},
year = {2025},
issn = {1478-4092},
doi = {https://doi.org/10.1016/j.pursup.2025.101012},
url = {https://www.sciencedirect.com/science/article/pii/S1478409225000214},
author = {Silke Herold and Jonas Heller and Frank Rozemeijer and Dominik Mahr},
keywords = {Artificial intelligence, Chatbots, Negotiation},
abstract = {The technological breakthrough of artificial intelligence (AI) is impacting buyer-supplier negotiations, which are increasingly moving toward human-to-machine negotiations using AI-based chatbots. While the first AI-powered negotiation solutions are currently being used by procurement professionals to negotiate for non-critical spend items, which is an example of structural influence, the behavioral influence of AI-based chatbots (i.e., on negotiation approach) remains unknown. It is unclear in which behavioral settings these chatbots deliver value to the buying firm in terms of economic, psychological, and relational outcomes. To fill this gap, we conduct three experiments in buyer–supplier negotiation settings, two in a lab-setting with undergraduate business students and one online experiment with professional negotiators. In our interactive simulations, participants play the role of the supplier, while a ChatGPT-based custom-trained chatbot acts as the buyer. We find that when the chatbot deploys a competitive, as compared to a collaborative, negotiation approach, it will achieve a higher price discount, better payment terms, and a quicker negotiation. However, suppliers trust a collaboratively prompted, as compared to a competitively prompted, chatbot more and demonstrate higher outcome satisfaction, as well as a stronger desire for future interaction. A text analysis of the chat interactions indicates a higher level of similarity when a competitively prompted chatbot is employed, which implies that suppliers also use more insistent and intimidating language, thereby matching the chatbot's negotiation approach to a greater degree. While the negotiation approach is a significant influencing factor, we do not find significant evidence that item type, in our case non-critical or bottleneck, matters, which indicates that AI-based chatbots can be effective in various buyer–supplier settings.}
}
@article{PUGLIESE2025667,
title = {Generative Artificial Intelligence in Nutrition: A Revolution in Accessibility and Personalization},
journal = {The Journal of Nutrition},
volume = {155},
number = {3},
pages = {667-668},
year = {2025},
issn = {0022-3166},
doi = {https://doi.org/10.1016/j.tjnut.2025.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S002231662500032X},
author = {Nicola Pugliese and Federico Ravaioli}
}
@article{LV2023208,
title = {Generative artificial intelligence in the metaverse era},
journal = {Cognitive Robotics},
volume = {3},
pages = {208-217},
year = {2023},
issn = {2667-2413},
doi = {https://doi.org/10.1016/j.cogr.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667241323000198},
author = {Zhihan Lv},
abstract = {Generative artificial intelligence (AI) is a form of AI that can autonomously generate new content, such as text, images, audio, and video. Generative AI provides innovative approaches for content production in the metaverse, filling gaps in the development of the metaverse. Products such as ChatGPT have the potential to enhance the search experience, reshape information generation and presentation methods, and become new entry points for online traffic. This is expected to significantly impact traditional search engine products, accelerating industry innovation and upgrading. This paper presents an overview of the technologies and prospective applications of generative AI in the breakthrough of metaverse technology and offers insights for increasing the effectiveness of generative AI in creating creative content.}
}
@article{CHEN2024100531,
title = {Generative Artificial Intelligence Enhancements for Reducing Image-based Training Data Requirements},
journal = {Ophthalmology Science},
volume = {4},
number = {5},
pages = {100531},
year = {2024},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2666914524000678},
author = {Dake Chen and Ying Han and Jacque Duncan and Lin Jia and Jing Shan},
keywords = {Glaucoma, Generative AI, Data scarcity},
abstract = {Objective
Training data fuel and shape the development of artificial intelligence (AI) models. Intensive data requirements are a major bottleneck limiting the success of AI tools in sectors with inherently scarce data. In health care, training data are difficult to curate, triggering growing concerns that the current lack of access to health care by under-privileged social groups will translate into future bias in health care AIs. In this report, we developed an autoencoder to grow and enhance inherently scarce datasets to alleviate our dependence on big data.
Design
Computational study with open-source data.
Subjects
The data were obtained from 6 open-source datasets comprising patients aged 40–80 years in Singapore, China, India, and Spain.
Methods
The reported framework generates synthetic images based on real-world patient imaging data. As a test case, we used autoencoder to expand publicly available training sets of optic disc photos, and evaluated the ability of the resultant datasets to train AI models in the detection of glaucomatous optic neuropathy.
Main Outcome Measures
Area under the receiver operating characteristic curve (AUC) were used to evaluate the performance of the glaucoma detector. A higher AUC indicates better detection performance.
Results
Results show that enhancing datasets with synthetic images generated by autoencoder led to superior training sets that improved the performance of AI models.
Conclusions
Our findings here help address the increasingly untenable data volume and quality requirements for AI model development and have implications beyond health care, toward empowering AI adoption for all similarly data-challenged fields.
Financial Disclosure(s)
The authors have no proprietary or commercial interest in any materials discussed in this article.}
}
@article{RODMAN2025689,
title = {Is generative artificial intelligence capable of clinical reasoning?},
journal = {The Lancet},
volume = {405},
number = {10480},
pages = {689},
year = {2025},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(25)00348-4},
url = {https://www.sciencedirect.com/science/article/pii/S0140673625003484},
author = {Adam Rodman and Eric J Topol}
}
@article{BLEASE2024115724,
title = {Psychiatrists’ experiences and opinions of generative artificial intelligence in mental healthcare: An online mixed methods survey},
journal = {Psychiatry Research},
volume = {333},
pages = {115724},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.115724},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124000118},
author = {Charlotte Blease and Abigail Worthen and John Torous},
keywords = {Chatbots, LLM, Workforce, Psychiatry, Artificial intelligence},
abstract = {Following the launch of ChatGPT in November 2022, interest in large language model (LLM)-powered chatbots has surged with increasing focus on the clinical potential of these tools. Missing from this discussion, however, are the perspectives of physicians. The current study aimed to explore psychiatrists’ experiences and opinions on this new generation of chatbots in mental health care. An online survey including both quantitative and qualitative responses was distributed to a non-probability sample of psychiatrists affiliated with the American Psychiatric Association. Findings revealed 44 % of psychiatrists had used OpenAI's ChatGPT-3.5 and 33 % had used GPT-4.0 “to assist with answering clinical questions.” Administrative tasks were cited as a major benefit of these tools: 70 % somewhat agreed/agreed “documentation will be/is more efficient”. Three in four psychiatrists (75 %) somewhat agreed/agreed “the majority of their patients will consult these tools before first seeing a doctor”. Nine in ten somewhat agreed/agreed that clinicians need more support/training in understanding these tools. Open-ended responses reflected these opinions but respondents also expressed divergent opinions on the value of generative AI in clinical practice, including its impact on the future of the profession.}
}
@article{DAUNGSUPAWONG2024848,
title = {Generative artificial intelligence in ophthalmology: Correspondence},
journal = {Survey of Ophthalmology},
volume = {69},
number = {5},
pages = {848},
year = {2024},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000717},
author = {Hinpetch Daungsupawong and Viroj Wiwanitkit}
}
@article{LIU2023798,
title = {Generative artificial intelligence and its applications in materials science: Current situation and future perspectives},
journal = {Journal of Materiomics},
volume = {9},
number = {4},
pages = {798-816},
year = {2023},
issn = {2352-8478},
doi = {https://doi.org/10.1016/j.jmat.2023.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352847823000771},
author = {Yue Liu and Zhengwei Yang and Zhenyao Yu and Zitu Liu and Dahui Liu and Hailong Lin and Mingqing Li and Shuchang Ma and Maxim Avdeev and Siqi Shi},
keywords = {Machine learning, Artificial intelligence, Generative artificial intelligence, Materials science, Novel materials discovery, Deep learning},
abstract = {Generative Artificial Intelligence (GAI) is attracting the increasing attention of materials community for its excellent capability of generating required contents. With the introduction of Prompt paradigm and reinforcement learning from human feedback (RLHF), GAI shifts from the task-specific to general pattern gradually, enabling to tackle multiple complicated tasks involved in resolving the structure-activity relationships. Here, we review the development status of GAI comprehensively and analyze pros and cons of various generative models in the view of methodology. The applications of task-specific generative models involving materials inverse design and data augmentation are also dissected. Taking ChatGPT as an example, we explore the potential applications of general GAI in generating multiple materials content, solving differential equation as well as querying materials FAQs. Furthermore, we summarize six challenges encountered for the use of GAI in materials science and provide the corresponding solutions. This work paves the way for providing effective and explainable materials data generation and analysis approaches to accelerate the materials research and development.}
}
@article{BHATTACHARYA2024100194,
title = {ChatGPT’s scorecard after the performance in a series of tests conducted at the multi-country level: A pattern of responses of generative artificial intelligence or large language models},
journal = {Current Research in Biotechnology},
volume = {7},
pages = {100194},
year = {2024},
issn = {2590-2628},
doi = {https://doi.org/10.1016/j.crbiot.2024.100194},
url = {https://www.sciencedirect.com/science/article/pii/S2590262824000200},
author = {Manojit Bhattacharya and Soumen Pal and Srijan Chatterjee and Abdulrahman Alshammari and Thamer H. Albekairi and Supriya Jagga and Elijah {Ige Ohimain} and Hatem Zayed and Siddappa N. Byrareddy and Sang-Soo Lee and Zhi-Hong Wen and Govindasamy Agoramoorthy and Prosun Bhattacharya and Chiranjib Chakraborty},
keywords = {ChatGPT, Accuracy, Reproducibility, Plagiarism, Answer length},
abstract = {Recently, researchers have shown concern about the ChatGPT-derived answers. Here, we conducted a series of tests using ChatGPT by individual researcher at multi-country level to understand the pattern of its answer accuracy, reproducibility, answer length, plagiarism, and in-depth using two questionnaires (the first set with 15 MCQs and the second 15 KBQ). Among 15 MCQ-generated answers, 13 ± 70 were correct (Median : 82.5; Coefficient variance : 4.85), 3 ± 0.77 were incorrect (Median: 3, Coefficient variance: 25.81), and 1 to 10 were reproducible, and 11 to 15 were not. Among 15 KBQ, the length of each question (in words) is about 294.5 ± 97.60 (mean range varies from 138.7 to 438.09), and the mean similarity index (in words) is about 29.53 ± 11.40 (Coefficient variance: 38.62) for each question. The statistical models were also developed using analyzed parameters of answers. The study shows a pattern of ChatGPT-derive answers with correctness and incorrectness and urges for an error-free, next-generation LLM to avoid users’ misguidance.}
}
@article{WAQAS2023100255,
title = {Revolutionizing Digital Pathology With the Power of Generative Artificial Intelligence and Foundation Models},
journal = {Laboratory Investigation},
volume = {103},
number = {11},
pages = {100255},
year = {2023},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2023.100255},
url = {https://www.sciencedirect.com/science/article/pii/S0023683723001988},
author = {Asim Waqas and Marilyn M. Bui and Eric F. Glassy and Issam {El Naqa} and Piotr Borkowski and Andrew A. Borkowski and Ghulam Rasool},
keywords = {artificial intelligence, computational and digital pathology, foundation models, large language models, multimodal data, vision-language models},
abstract = {Digital pathology has transformed the traditional pathology practice of analyzing tissue under a microscope into a computer vision workflow. Whole-slide imaging allows pathologists to view and analyze microscopic images on a computer monitor, enabling computational pathology. By leveraging artificial intelligence (AI) and machine learning (ML), computational pathology has emerged as a promising field in recent years. Recently, task-specific AI/ML (eg, convolutional neural networks) has risen to the forefront, achieving above-human performance in many image-processing and computer vision tasks. The performance of task-specific AI/ML models depends on the availability of many annotated training datasets, which presents a rate-limiting factor for AI/ML development in pathology. Task-specific AI/ML models cannot benefit from multimodal data and lack generalization, eg, the AI models often struggle to generalize to new datasets or unseen variations in image acquisition, staining techniques, or tissue types. The 2020s are witnessing the rise of foundation models and generative AI. A foundation model is a large AI model trained using sizable data, which is later adapted (or fine-tuned) to perform different tasks using a modest amount of task-specific annotated data. These AI models provide in-context learning, can self-correct mistakes, and promptly adjust to user feedback. In this review, we provide a brief overview of recent advances in computational pathology enabled by task-specific AI, their challenges and limitations, and then introduce various foundation models. We propose to create a pathology-specific generative AI based on multimodal foundation models and present its potentially transformative role in digital pathology. We describe different use cases, delineating how it could serve as an expert companion of pathologists and help them efficiently and objectively perform routine laboratory tasks, including quantifying image analysis, generating pathology reports, diagnosis, and prognosis. We also outline the potential role that foundation models and generative AI can play in standardizing the pathology laboratory workflow, education, and training.}
}
@article{OGRADY2024S450,
title = {MSR63 Prompt Engineering for the Use of Generative Artificial Intelligence (AI) in Health Economic Modeling: Findings From a Targeted Literature Review},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S450},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2297},
url = {https://www.sciencedirect.com/science/article/pii/S109830152405160X},
author = {M O'Grady and N Adair and R Arguello and J Benner}
}
@incollection{MUKHUTY202537,
title = {Chapter 3 - Industry 5.0 era of digital supply chain: A generative artificial intelligence (GenAI) action model for workforce engagement},
editor = {Syed Abdul Rehman Khan and Adnan Ahmed Sheikh and Jyri Vilko and Sajid Nazir and Mahmood Ali and Marko Torkkeli},
booktitle = {Technological Innovations and Industry 5.0},
publisher = {Elsevier},
pages = {37-53},
year = {2025},
series = {Developments and Advances in the Supply Chain Industry},
isbn = {978-0-443-33813-7},
doi = {https://doi.org/10.1016/B978-0-443-33813-7.00003-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443338137000038},
author = {Sumona Mukhuty and Robert Dixon and Arvind Upadhyay},
keywords = {Generative artificial intelligence, Industry 4.0, Industry 5.0, Productivity enhancement, Supply chains},
abstract = {Industry 5.0 advocates triangulating the technology-centric emphasis of Industry 4.0 with human-centricity and sustainability. The focus is on creating an inclusive work environment facilitating human-machine reconciliation leading to “sustainable social welfare.” Within this context, the advent and accessibility of generative artificial intelligence (GenAI) have been received with equal measures of excitement and existential dread. This is a major disruptive digital technology that has begun to shake the equilibrium and stability of business survival and job security. Yet, the potential of GenAI in enhancing efficiency is revolutionary, spanning all sectors, including supply chains. Organizational success within the Industry 5.0 context is heavily dependent on the appropriate skills and capabilities. However, the rapid advancement and adoption of GenAI has left organizations with severe knowledge and skills gaps. In this study, we conduct a succinct review of GenAI’s impact on supply chains. Thereafter we draw upon strategic management theories and organizational change theories to develop an organizational GenAI action model to enable supply chain organizations to transition workers from a state of “unconscious GenAI incompetence” to “conscious GenAI competence,” working through the five stages of the model: getting urgent, exploration, formulation, iteration, and embedding. We will predominantly draw upon high-impact peer-reviewed articles, complemented by relevant gray literature, including the European Commission publications, in developing this review and conceptual model. We will close by highlighting the model’s applicability and future research directions.}
}
@article{YASSIN2025102284,
title = {Evaluating a generative artificial intelligence accuracy in providing medication instructions from smartphone images},
journal = {Journal of the American Pharmacists Association},
volume = {65},
number = {1},
pages = {102284},
year = {2025},
issn = {1544-3191},
doi = {https://doi.org/10.1016/j.japh.2024.102284},
url = {https://www.sciencedirect.com/science/article/pii/S1544319124003157},
author = {Yusef Yassin and Thien Nguyen and Krishna Panchal and Katharine Getchell and Timothy Aungst},
abstract = {Background
The Food and Drug Administration mandates patient labeling materials like the Medication Guide (MG) and Instructions for Use (IFU) to support appropriate medication use. However, challenges such as low health literacy and difficulties navigating these materials may lead to incorrect medication usage, resulting in therapy failure or adverse outcomes. The rise of generative AI, presents an opportunity to provide scalable, personalized patient education through image recognition and text generation.
Objective
This study aimed to evaluate the accuracy and safety of medication instructions generated by ChatGPT based on user-provided drug images, compared to the manufacturer's standard instructions.
Methods
Images of 12 medications requiring multiple steps for administration were uploaded to ChatGPT's image recognition function. ChatGPT's responses were compared to the official IFU and MG using text classifiers, Count Vectorization (CountVec), and Term Frequency-Inverse Document Frequency (TF-IDF). The clinical accuracy was further evaluated by independent pharmacists to determine if ChatGPT responses were valid for patient instruction.
Results
ChatGPT correctly identified all medications and generated patient instructions. CountVec outperformed TF-IDF in text similarity analysis, with an average similarity score of 76%. However, clinical evaluation revealed significant gaps in the instructions, particularly for complex administration routes, where ChatGPT's guidance lacked essential details, leading to lower clinical accuracy scores.
Conclusion
While ChatGPT shows promise in generating patient-friendly medication instructions, its effectiveness varies based on the complexity of the medication. The findings underscore the need for further refinement and clinical oversight to ensure the safety and accuracy of AI-generated medical guidance, particularly for medications with complex administration processes.}
}
@article{TEIXEIRADASILVA2025111607,
title = {Editing companies have the responsibility of ensuring their declared use of generative artificial intelligence},
journal = {Journal of Clinical Epidemiology},
volume = {177},
pages = {111607},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2024.111607},
url = {https://www.sciencedirect.com/science/article/pii/S0895435624003639},
author = {Jaime A. {Teixeira da Silva}}
}
@article{TAN2023100394,
title = {Generative Artificial Intelligence Through ChatGPT and Other Large Language Models in Ophthalmology: Clinical Applications and Challenges},
journal = {Ophthalmology Science},
volume = {3},
number = {4},
pages = {100394},
year = {2023},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2023.100394},
url = {https://www.sciencedirect.com/science/article/pii/S2666914523001264},
author = {Ting Fang Tan and Arun James Thirunavukarasu and J. Peter Campbell and Pearse A. Keane and Louis R. Pasquale and Michael D. Abramoff and Jayashree Kalpathy-Cramer and Flora Lum and Judy E. Kim and Sally L. Baxter and Daniel Shu Wei Ting},
keywords = {Artificial intelligence, Chatbots, ChatGPT, Large language models},
abstract = {The rapid progress of large language models (LLMs) driving generative artificial intelligence applications heralds the potential of opportunities in health care. We conducted a review up to April 2023 on Google Scholar, Embase, MEDLINE, and Scopus using the following terms: “large language models,” “generative artificial intelligence,” “ophthalmology,” “ChatGPT,” and “eye,” based on relevance to this review. From a clinical viewpoint specific to ophthalmologists, we explore from the different stakeholders’ perspectives—including patients, physicians, and policymakers—the potential LLM applications in education, research, and clinical domains specific to ophthalmology. We also highlight the foreseeable challenges of LLM implementation into clinical practice, including the concerns of accuracy, interpretability, perpetuating bias, and data security. As LLMs continue to mature, it is essential for stakeholders to jointly establish standards for best practices to safeguard patient safety.
Financial Disclosure(s)
Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.}
}
@article{WAISBERG2024849,
title = {Future directions of generative artificial intelligence in ophthalmology and vision science},
journal = {Survey of Ophthalmology},
volume = {69},
number = {5},
pages = {849-850},
year = {2024},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000729},
author = {Ethan Waisberg and Joshua Ong and Mouayad Masalkhi and Andrew G. Lee and Alireza Tavakkoli},
keywords = {Generative adversarial networks, Deep learning, ChatGPT, GPT4, Artificial ophthalmic image synthesis, AI, Machine learning}
}
@article{ROWE2024469,
title = {Artificial intelligence in radiation therapy: An emerging revolution that will be driven by generative methodologies},
journal = {Diagnostic and Interventional Imaging},
volume = {105},
number = {12},
pages = {469-470},
year = {2024},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2024.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2211568424001992},
author = {Steven P. Rowe and N. Ari Wijetunga},
keywords = {Artificial intelligence, Generative AI, Large-language models, Machine learning, Radiation therapy}
}
@article{EDAKKANAMBETHVARAYIL20251018,
title = {Artificial intelligence (AI) in nutrition: A case-based comparison of generative AI models},
journal = {Clinical Nutrition ESPEN},
volume = {69},
pages = {1018},
year = {2025},
issn = {2405-4577},
doi = {https://doi.org/10.1016/j.clnesp.2025.07.620},
url = {https://www.sciencedirect.com/science/article/pii/S240545772502371X},
author = {J. {Edakkanambeth Varayil} and O. {Mohamed Elfadil} and M. Mundi and G. Kolar and R. Hurt}
}
@article{ZENG2024,
title = {Assessing the Role of the Generative Pretrained Transformer (GPT) in Alzheimer’s Disease Management: Comparative Study of Neurologist- and Artificial Intelligence–Generated Responses},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/51095},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007325},
author = {Jiaqi Zeng and Xiaoyi Zou and Shirong Li and Yao Tang and Sisi Teng and Huanhuan Li and Changyu Wang and Yuxuan Wu and Luyao Zhang and Yunheng Zhong and Jialin Liu and Siru Liu},
keywords = {Alzheimer's disease, artificial intelligence, AI, large language model, LLM, Generative Pretrained Transformer, GPT, ChatGPT, patient information},
abstract = {Background
Alzheimer’s disease (AD) is a progressive neurodegenerative disorder posing challenges to patients, caregivers, and society. Accessible and accurate information is crucial for effective AD management.
Objective
This study aimed to evaluate the accuracy, comprehensibility, clarity, and usefulness of the Generative Pretrained Transformer’s (GPT) answers concerning the management and caregiving of patients with AD.
Methods
In total, 14 questions related to the prevention, treatment, and care of AD were identified and posed to GPT-3.5 and GPT-4 in Chinese and English, respectively, and 4 respondent neurologists were asked to answer them. We generated 8 sets of responses (total 112) and randomly coded them in answer sheets. Next, 5 evaluator neurologists and 5 family members of patients were asked to rate the 112 responses using separate 5-point Likert scales. We evaluated the quality of the responses using a set of 8 questions rated on a 5-point Likert scale. To gauge comprehensibility and participant satisfaction, we included 3 questions dedicated to each aspect within the same set of 8 questions.
Results
As of April 10, 2023, the 5 evaluator neurologists and 5 family members of patients with AD rated the 112 responses: GPT-3.5: n=28, 25%, responses; GPT-4: n=28, 25%, responses; respondent neurologists: 56 (50%) responses. The top 5 (4.5%) responses rated by evaluator neurologists had 4 (80%) GPT (GPT-3.5+GPT-4) responses and 1 (20%) respondent neurologist’s response. For the top 5 (4.5%) responses rated by patients’ family members, all but the third response were GPT responses. Based on the evaluation by neurologists, the neurologist-generated responses achieved a mean score of 3.9 (SD 0.7), while the GPT-generated responses scored significantly higher (mean 4.4, SD 0.6; P<.001). Language and model analyses revealed no significant differences in response quality between the GPT-3.5 and GPT-4 models (GPT-3.5: mean 4.3, SD 0.7; GPT-4: mean 4.4, SD 0.5; P=.51). However, English responses outperformed Chinese responses in terms of comprehensibility (Chinese responses: mean 4.1, SD 0.7; English responses: mean 4.6, SD 0.5; P=.005) and participant satisfaction (Chinese responses: mean 4.2, SD 0.8; English responses: mean 4.5, SD 0.5; P=.04). According to the evaluator neurologists’ review, Chinese responses had a mean score of 4.4 (SD 0.6), whereas English responses had a mean score of 4.5 (SD 0.5; P=.002). As for the family members of patients with AD, no significant differences were observed between GPT and neurologists, GPT-3.5 and GPT-4, or Chinese and English responses.
Conclusions
GPT can provide patient education materials on AD for patients, their families and caregivers, nurses, and neurologists. This capability can contribute to the effective health care management of patients with AD, leading to enhanced patient outcomes.}
}
@article{PREIKSAITIS2023,
title = {Opportunities, Challenges, and Future Directions of Generative Artificial Intelligence in Medical Education: Scoping Review},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/48785},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000697},
author = {Carl Preiksaitis and Christian Rose},
keywords = {medical education, artificial intelligence, ChatGPT, Bard, AI, educator, scoping, review, learner, generative},
abstract = {Background
Generative artificial intelligence (AI) technologies are increasingly being utilized across various fields, with considerable interest and concern regarding their potential application in medical education. These technologies, such as Chat GPT and Bard, can generate new content and have a wide range of possible applications.
Objective
This study aimed to synthesize the potential opportunities and limitations of generative AI in medical education. It sought to identify prevalent themes within recent literature regarding potential applications and challenges of generative AI in medical education and use these to guide future areas for exploration.
Methods
We conducted a scoping review, following the framework by Arksey and O'Malley, of English language articles published from 2022 onward that discussed generative AI in the context of medical education. A literature search was performed using PubMed, Web of Science, and Google Scholar databases. We screened articles for inclusion, extracted data from relevant studies, and completed a quantitative and qualitative synthesis of the data.
Results
Thematic analysis revealed diverse potential applications for generative AI in medical education, including self-directed learning, simulation scenarios, and writing assistance. However, the literature also highlighted significant challenges, such as issues with academic integrity, data accuracy, and potential detriments to learning. Based on these themes and the current state of the literature, we propose the following 3 key areas for investigation: developing learners’ skills to evaluate AI critically, rethinking assessment methodology, and studying human-AI interactions.
Conclusions
The integration of generative AI in medical education presents exciting opportunities, alongside considerable challenges. There is a need to develop new skills and competencies related to AI as well as thoughtful, nuanced approaches to examine the growing use of generative AI in medical education.}
}
@article{GALHOTRA2025S19,
title = {ID: 4349993 QUALITATIVE EVALUATION FRAMEWORK FOR COMPARING THE EFFECTIVENESS OF LARGE LANGUAGE MODELS THAT POWER HEALTH CARE CONVERSATIONS USING GENERATIVE ARTIFICIAL INTELLIGENCE IN ATRIAL FIBRILLATION},
journal = {Heart Rhythm O2},
volume = {6},
number = {9, Supplement },
pages = {S19-S20},
year = {2025},
note = {HRX AbstracX 2025},
issn = {2666-5018},
doi = {https://doi.org/10.1016/j.hroo.2025.07.059},
url = {https://www.sciencedirect.com/science/article/pii/S2666501825003241},
author = {Sainyam Galhotra and Hemang Jiwnani and Audrey Nicholson and Prashanthan Sanders and Ajay Tripuraneni}
}
@article{AHMED20241975,
title = {Generative Artificial Intelligence Tools in Gastroenterology Training},
journal = {Clinical Gastroenterology and Hepatology},
volume = {22},
number = {10},
pages = {1975-1978},
year = {2024},
issn = {1542-3565},
doi = {https://doi.org/10.1016/j.cgh.2024.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S1542356524006001},
author = {Tasnim Ahmed and Loren G. Rabinowitz and Adam Rodman and Tyler M. Berzin}
}
@article{GOMES2025A39,
title = {Graduate Students’ Use and Perceptions of Generative Artificial Intelligence (GenAI) in Higher Education},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {125},
number = {10, Supplement },
pages = {A39},
year = {2025},
note = {2025 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2025.06.303},
url = {https://www.sciencedirect.com/science/article/pii/S2212267225006409},
author = {A. Gomes}
}
@article{SHLOBIN2024e398,
title = {Opportunities and Considerations for the Incorporation of Artificial Intelligence into Global Neurosurgery: A Generative Pretrained Transformer Chatbot-Based Approach},
journal = {World Neurosurgery},
volume = {186},
pages = {e398-e412},
year = {2024},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2024.03.149},
url = {https://www.sciencedirect.com/science/article/pii/S1878875024005357},
author = {Nathan A. Shlobin and Gail Rosseau},
keywords = {Global health, Global neurosurgery, Global surgery, International development, Public health},
abstract = {Objective
Global neurosurgery is a public health focus in neurosurgery that seeks to ensure safe, timely, and affordable neurosurgical care to all individuals worldwide. Although investigators have begun to explore the promise of artificial intelligence (AI) for neurosurgery, its applicability to global neurosurgery has been largely hypothetical. We characterize opportunities and considerations for the incorporation of AI into global neurosurgery by synthesizing key themes yielded from a series of generative pretrained transformers (GPTs), discuss important limitations of GPTs and cautions when using AI in neurosurgery, and develop a framework for the equitable incorporation of AI into global neurosurgery.
Methods
ChatGPT, Bing Chat/Copilot, You, Perplexity.ai, and Google Bard were queried with the prompt “How can AI be incorporated into global neurosurgery?” A layered ChatGPT-based thematic analysis was performed. The authors synthesized the results into opportunities and considerations for the incorporation of AI in global neurosurgery. A Pareto analysis was conducted to determine common themes.
Results
Eight opportunities and 14 important considerations were synthesized. Six opportunities related to patient care, 1 to education, and another to public health planning. Four of the important considerations were deemed specific to global neurosurgery. The Pareto analysis included all 8 opportunities and 5 considerations.
Conclusions
AI may be incorporated into global neurosurgery in a variety of capacities requiring numerous considerations. The framework presented in this manuscript may facilitate the incorporation of AI into global neurosurgery initiatives while balancing contextual factors and the reality of limited resources.}
}
@article{CHAUHAN20241406,
title = {The Impact of Generative Artificial Intelligence in Scientific Content Synthesis for Authors},
journal = {The American Journal of Pathology},
volume = {194},
number = {8},
pages = {1406-1408},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024002001},
author = {Chhavi Chauhan}
}
@article{RODLER2024S947,
title = {A0193 - Exploring the efficiency of generative artificial intelligence in rapidly and accurately producing patient information for urological malignancy treatments aligned with the latest EAU guidelines},
journal = {European Urology},
volume = {85},
pages = {S947-S948},
year = {2024},
note = {Abstracts EAU24 - 39th Annual EAU Congress},
issn = {0302-2838},
doi = {https://doi.org/10.1016/S0302-2838(24)00773-5},
url = {https://www.sciencedirect.com/science/article/pii/S0302283824007735},
author = {S. Rodler and L.S. Ramacciotti and E. Checcucci and P. {De Backer} and I.R. Belenchon and M. Taraktin and S. Pulliatti and A. Veccia and P. Piazza and L. Baekelandt and K-F. Kowalewski and J.G. Rivas and A.L. Abreu and I.S. Gill and G.E. Cacciamani}
}
@article{HALL2024100256,
title = {Generative Artificial Intelligence, Large Language Models, and JID Innovations},
journal = {JID Innovations},
volume = {4},
number = {2},
pages = {100256},
year = {2024},
issn = {2667-0267},
doi = {https://doi.org/10.1016/j.xjidi.2024.100256},
url = {https://www.sciencedirect.com/science/article/pii/S2667026724000018},
author = {Russell P. Hall}
}
@article{LUBOWITZ2024651,
title = {Guidelines for the Use of Generative Artificial Intelligence Tools for Biomedical Journal Authors and Reviewers},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {40},
number = {3},
pages = {651-652},
year = {2024},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2023.10.037},
url = {https://www.sciencedirect.com/science/article/pii/S0749806323008812},
author = {James H. Lubowitz},
abstract = {Authors are permitted to use generative artificial intelligence (AI) large language models (LLM) to improve the readability of their own writing. However, authors must review and edit the output resulting from generative AI and are accountable for the accuracy of their publications. AI may not be listed, or cited, as an author. Authors who use AI in the scientific writing process must disclose the use of AI LLM in their manuscript including a description of the tool and reason for use. Authors are not permitted to use AI to create or alter images or videos, (unless this is part of the research design in which case a statement is required explaining what was created or altered, with what tools, how, and for what reason). Finally, AI use by reviewers and editors is not permitted and violates confidentiality and proprietary rights and may breach data privacy rights. In conclusion, scientific writing and peer review is the responsibility of humans.}
}
@article{RODRIGUES202578,
title = {Simulating social dynamics with artificial intelligence: Comment on “LLMs and generative agent-based models for complex systems research” by Yikang Lu et al.},
journal = {Physics of Life Reviews},
volume = {54},
pages = {78-79},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000910},
author = {Francisco A. Rodrigues and Paula Giovanna Rodrigues}
}
@article{SATURNO2023248,
title = {Generative artificial intelligence fails to provide sufficiently accurate recommendations when compared to established breast reconstruction surgery guidelines},
journal = {Journal of Plastic, Reconstructive & Aesthetic Surgery},
volume = {86},
pages = {248-250},
year = {2023},
issn = {1748-6815},
doi = {https://doi.org/10.1016/j.bjps.2023.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S1748681523005247},
author = {Michael P. Saturno and Mateo Restrepo Mejia and Anya Wang and Daniel Kwon and Olachi Oleru and Nargiz Seyidova and Peter W. Henderson},
keywords = {Large language model, ChatGPT, Artificial intelligence, Reconstructive breast surgery, Plastic and reconstructive surgery, Guidelines}
}
@article{CHAU2024616,
title = {Performance of Generative Artificial Intelligence in Dental Licensing Examinations},
journal = {International Dental Journal},
volume = {74},
number = {3},
pages = {616-621},
year = {2024},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2023.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0020653923009899},
author = {Reinhard Chun Wang Chau and Khaing Myat Thu and Ollie Yiru Yu and Richard Tai-Chiu Hsung and Edward Chin Man Lo and Walter Yu Hang Lam},
keywords = {Artificial intelligence, Communication, Dental education, Digital technology, Examination questions, Specialties, Dental},
abstract = {ABSTRACT
Objectives
Generative artificial intelligence (GenAI), including large language models (LLMs), has vast potential applications in health care and education. However, it is unclear how proficient LLMs are in interpreting written input and providing accurate answers in dentistry. This study aims to investigate the accuracy of GenAI in answering questions from dental licensing examinations.
Methods
A total of 1461 multiple-choice questions from question books for the US and the UK dental licensing examinations were input into 2 versions of ChatGPT 3.5 and 4.0. The passing rates of the US and UK dental examinations were 75.0% and 50.0%, respectively. The performance of the 2 versions of GenAI in individual examinations and dental subjects was analysed and compared.
Results
ChatGPT 3.5 correctly answered 68.3% (n = 509) and 43.3% (n = 296) of questions from the US and UK dental licensing examinations, respectively. The scores for ChatGPT 4.0 were 80.7% (n = 601) and 62.7% (n = 429), respectively. ChatGPT 4.0 passed both written dental licensing examinations, whilst ChatGPT 3.5 failed. ChatGPT 4.0 answered 327 more questions correctly and 102 incorrectly compared to ChatGPT 3.5 when comparing the 2 versions.
Conclusions
The newer version of GenAI has shown good proficiency in answering multiple-choice questions from dental licensing examinations. Whilst the more recent version of GenAI generally performed better, this observation may not hold true in all scenarios, and further improvements are necessary. The use of GenAI in dentistry will have significant implications for dentist–patient communication and the training of dental professionals.}
}
@article{WANG2023100516,
title = {Large-scale generative simulation artificial intelligence: The next hotspot},
journal = {The Innovation},
volume = {4},
number = {6},
pages = {100516},
year = {2023},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2023.100516},
url = {https://www.sciencedirect.com/science/article/pii/S2666675823001443},
author = {Qi Wang and Yanghe Feng and Jincai Huang and Yiqin Lv and Zheng Xie and Xiaoshan Gao}
}
@article{ABOGUNRIN2024S482,
title = {MSR224 Generative Artificial Intelligence: An Effective Alternative for Screening Titles and Abstracts in Systematic Literature Reviews},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S482},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2457},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524053208},
author = {S Abogunrin and RR Sieiro and M Lane}
}
@article{YILMAZ2023100147,
title = {The effect of generative artificial intelligence (AI)-based tool use on students' computational thinking skills, programming self-efficacy and motivation},
journal = {Computers and Education: Artificial Intelligence},
volume = {4},
pages = {100147},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100147},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000267},
author = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
keywords = {Artificial intelligence, ChatGPT, Generative pretrained transformer, Programming education, Computational thinking},
abstract = {ChatGPT (generative pre-trained transformer) is one of the artificial intelligence (AI) technologies that have started to be used in programming education. However, the effect of using ChatGPT in programming education on learning processes and outcomes is not yet known. This study investigated the effect of programming education using the ChatGPT on students' computational thinking skills, programming self-efficacy, and motivation toward the lesson. The research was conducted on 45 undergraduate students who took a university-level programming course. The research was carried out according to the experimental design with the pretest-posttest control group. Students were randomly divided into experimental (n = 21) and control (n = 24) groups. While the experimental group students benefited from the ChatGPT during the weekly programming practices, the control group students did not use this tool. Research data were obtained through the computational thinking scale, computer programming self-efficacy scale, and learning motivation in computer programming courses scale. Research findings revealed that the experimental group students' computational thinking skills, programming self-efficacy, and motivation for the lesson were significantly higher than the control group students. In line with this result, it can be said that it may be useful to benefit from AI technologies such as ChatGPT in programming trainings. The research findings, it was emphasized how the most effective use of AI support in the lessons could be made, and various suggestions were made for researchers and educators in this regard.}
}
@article{SHAPIRO2024492,
title = {Revolutionizing teledermatology: Exploring the integration of artificial intelligence, including Generative Pre-trained Transformer chatbots for artificial intelligence-driven anamnesis, diagnosis, and treatment plans},
journal = {Clinics in Dermatology},
volume = {42},
number = {5},
pages = {492-497},
year = {2024},
note = {Artificial Intelligence II},
issn = {0738-081X},
doi = {https://doi.org/10.1016/j.clindermatol.2024.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0738081X24001044},
author = {Jonathan Shapiro and Anna Lyakhovitsky},
abstract = {The integration of teledermatology and artificial intelligence (AI) marks a significant advancement in dermatologic care. This study examines the synergistic interplay between these two domains, highlighting their collective impact on enhancing the accuracy, accessibility, and efficiency of teledermatologic services. Teledermatology expands dermatologic care to remote and underserved areas, and AI technologies show considerable potential in analyzing dermatologic images and performing various tasks involved in teledermatology consultations. Such integration facilitates rapid, precise diagnoses, personalized treatment plans, and data-driven insights. Our explorative study involved designing a GPT-based chatbot named “Dr. DermBot” and exploring its performance in a teledermatologic consultation process. The design phase focused on the chatbot's ability to conduct consultations autonomously. The subsequent testing phase assessed its performance against the backdrop of current teledermatologic practices, exploring the potential of AI and chatbots to simulate and potentially enhance teledermatologic health care. Our study demonstrates the promising future of combining teledermatology with AI. It also brings to light ethical and legal concerns, including the protection of patient data privacy and adherence to regulatory standards. The union of teledermatology and AI not only aims to enhance the precision of teledermatologic diagnoses but also broadens the accessibility of dermatologic services to previously underserved populations, benefiting patients, health care providers, and the overall health care system.}
}
@article{KRUIDERING2024224,
title = {Can Generative Artificial Intelligence (AI) Reliably Score Open-Ended Questions (OEQs) in the Assessment of Medical Knowledge},
journal = {The Journal of Pharmacology and Experimental Therapeutics},
volume = {389},
pages = {224},
year = {2024},
issn = {0022-3565},
doi = {https://doi.org/10.1124/jpet.224.126248},
url = {https://www.sciencedirect.com/science/article/pii/S002235652417454X},
author = {Marieke Kruidering and Bao Bao Truongb and Kumiko Endo and Doreen M. Olvet and Tracy B. Fulton and Jeffrey B. Bird and Judith Brenner and Joanne M. Willey},
abstract = {Abstract ID 126248 Poster Board 224 Purpose: The objective of this study is to establish the accuracy of generative artificial intelligence (AI) when scoring medical student exam questions in an open-ended format (OEQ) compared to a faculty content expert. Background: Despite the numerous benefits to including OEQs in assessment of medical knowledge1,2, only 39% of US allopathic medical schools use them3. Faculty report that the biggest barrier is the time it takes to grade student responses1,2. Natural language processing has been explored to automate scoring of clinical reasoning4, but no study has evaluated the use of generative AI to score OEQ responses in the pre-clerkship curriculum. Methods: OEQ responses from two questions administered at the Zucker School of Medicine (ZSOM) and the University of California at San Francisco School of Medicine (UCSF) were used for the current study5. Responses from 54 students per site were analyzed. Content experts scored the responses using an analytic (ZSOM) or holistic rubric (UCSF). Questions, rubrics, and student responses were fed into the GPT-4 model via the Med2Lab platform. Once finalized, scores for each student’s response were generated. Cohen’s weighted kappa (kw) was used to evaluate inter-rater reliability (IRR) between the content expert and generative AI scores, with kw scores between 0.60 and 0.80 being considered substantial6. Prompt engineering was employed for question 1 (analytic rubric) to evaluate its impact on IRR. Results: IRR between the content expert and generative AI scores was substantial using the analytic rubric (question 1: kw = 0.71; question 2: kw = 0.63) and the holistic rubric (question 1: kw = 0.66; question 2: kw = 0.68). IRR for question 1 (analytic rubric) was initially kw = 0.61 but was increased to kw = 0.71 after adjustments with prompt engineering and re-run in GPT-4. Conclusions: Generative AI can score OEQs with substantial reliability. With the potential to alleviate grading burden, AI scoring will allow medical schools to broadly implement OEQs for assessment.}
}
@article{ZHUANG2024102122,
title = {From hearing to seeing: Linking auditory and visual place perceptions with soundscape-to-image generative artificial intelligence},
journal = {Computers, Environment and Urban Systems},
volume = {110},
pages = {102122},
year = {2024},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2024.102122},
url = {https://www.sciencedirect.com/science/article/pii/S0198971524000516},
author = {Yonggai Zhuang and Yuhao Kang and Teng Fei and Meng Bian and Yunyan Du},
keywords = {Soundscape, Street view images, Sense of place, Stable diffusion, Generative AI, LLMs},
abstract = {People experience the world through multiple senses simultaneously, contributing to our sense of place. Prior quantitative geography studies have mostly emphasized human visual perceptions, neglecting human auditory perceptions at place due to the challenges in characterizing the acoustic environment vividly. Also, few studies have synthesized the two-dimensional (auditory and visual) perceptions in understanding human sense of place. To bridge these gaps, we propose a Soundscape-to-Image Diffusion model, a generative Artificial Intelligence (AI) model supported by Large Language Models (LLMs), aiming to visualize soundscapes through the generation of street view images. By creating audio-image pairs, acoustic environments are first represented as high-dimensional semantic audio vectors. Our proposed Soundscape-to-Image Diffusion model, which contains a Low-Resolution Diffusion Model and a Super-Resolution Diffusion Model, can then translate those semantic audio vectors into visual representations of place effectively. We evaluated our proposed model by using both machine-based and human-centered approaches. We proved that the generated street view images align with our common perceptions, and accurately create several key street elements of the original soundscapes. It also demonstrates that soundscapes provide sufficient visual information places. This study stands at the forefront of the intersection between generative AI and human geography, demonstrating how human multi-sensory experiences can be linked. We aim to enrich geospatial data science and AI studies with human experiences. It has the potential to inform multiple domains such as human geography, environmental psychology, and urban design and planning, as well as advancing our knowledge of human-environment relationships.}
}
@article{JEHA20232105,
title = {ChatGPT and Generative Artificial Intelligence in Mohs Surgery: A New Frontier of Innovation},
journal = {Journal of Investigative Dermatology},
volume = {143},
number = {11},
pages = {2105-2107},
year = {2023},
issn = {0022-202X},
doi = {https://doi.org/10.1016/j.jid.2023.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0022202X23021425},
author = {George M. Jeha and Sultan Qiblawi and Neil Jairath and Kimberly Sable and Keith LeBlanc and Juliet Aylward and Yaohui Gloria Xu}
}
@article{BRAGAZZI2024,
title = {Assessing the Accuracy of Generative Conversational Artificial Intelligence in Debunking Sleep Health Myths: Mixed Methods Comparative Study With Expert Analysis},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/55762},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24002178},
author = {Nicola Luigi Bragazzi and Sergio Garbarino},
keywords = {sleep, sleep health, sleep-related disbeliefs, generative conversational artificial intelligence, chatbot, ChatGPT, misinformation, artificial intelligence, comparative study, expert analysis, adequate sleep, well-being, sleep trackers, sleep health education, sleep-related, chronic disease, healthcare cost, sleep timing, sleep duration, presleep behaviors, sleep experts, healthy behavior, public health, conversational agents},
abstract = {Background
Adequate sleep is essential for maintaining individual and public health, positively affecting cognition and well-being, and reducing chronic disease risks. It plays a significant role in driving the economy, public safety, and managing health care costs. Digital tools, including websites, sleep trackers, and apps, are key in promoting sleep health education. Conversational artificial intelligence (AI) such as ChatGPT (OpenAI, Microsoft Corp) offers accessible, personalized advice on sleep health but raises concerns about potential misinformation. This underscores the importance of ensuring that AI-driven sleep health information is accurate, given its significant impact on individual and public health, and the spread of sleep-related myths.
Objective
This study aims to examine ChatGPT’s capability to debunk sleep-related disbeliefs.
Methods
A mixed methods design was leveraged. ChatGPT categorized 20 sleep-related myths identified by 10 sleep experts and rated them in terms of falseness and public health significance, on a 5-point Likert scale. Sensitivity, positive predictive value, and interrater agreement were also calculated. A qualitative comparative analysis was also conducted.
Results
ChatGPT labeled a significant portion (n=17, 85%) of the statements as “false” (n=9, 45%) or “generally false” (n=8, 40%), with varying accuracy across different domains. For instance, it correctly identified most myths about “sleep timing,” “sleep duration,” and “behaviors during sleep,” while it had varying degrees of success with other categories such as “pre-sleep behaviors” and “brain function and sleep.” ChatGPT’s assessment of the degree of falseness and public health significance, on the 5-point Likert scale, revealed an average score of 3.45 (SD 0.87) and 3.15 (SD 0.99), respectively, indicating a good level of accuracy in identifying the falseness of statements and a good understanding of their impact on public health. The AI-based tool showed a sensitivity of 85% and a positive predictive value of 100%. Overall, this indicates that when ChatGPT labels a statement as false, it is highly reliable, but it may miss identifying some false statements. When comparing with expert ratings, high intraclass correlation coefficients (ICCs) between ChatGPT’s appraisals and expert opinions could be found, suggesting that the AI’s ratings were generally aligned with expert views on falseness (ICC=.83, P<.001) and public health significance (ICC=.79, P=.001) of sleep-related myths. Qualitatively, both ChatGPT and sleep experts refuted sleep-related misconceptions. However, ChatGPT adopted a more accessible style and provided a more generalized view, focusing on broad concepts, while experts sometimes used technical jargon, providing evidence-based explanations.
Conclusions
ChatGPT-4 can accurately address sleep-related queries and debunk sleep-related myths, with a performance comparable to sleep experts, even if, given its limitations, the AI cannot completely replace expert opinions, especially in nuanced and complex fields such as sleep health, but can be a valuable complement in the dissemination of updated information and promotion of healthy behaviors.}
}
@article{GUO2024102547,
title = {Harnessing Artificial Intelligence in Generative Content for enhancing motivation in learning},
journal = {Learning and Individual Differences},
volume = {116},
pages = {102547},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102547},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024001407},
author = {Jiesi Guo and Ying Ma and Tingting Li and Michael Noetel and Kewen Liao and Samuel Greiff}
}
@article{SEZGIN2022,
title = {Operationalizing and Implementing Pretrained, Large Artificial Intelligence Linguistic Models in the US Health Care System: Outlook of Generative Pretrained Transformer 3 (GPT-3) as a Service Model},
journal = {JMIR Medical Informatics},
volume = {10},
number = {2},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/32875},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422000643},
author = {Emre Sezgin and Joseph Sirrianni and Simon L Linwood},
keywords = {natural language processing, artificial intelligence, generative pretrained transformer, clinical informatics, chatbot},
abstract = {Generative pretrained transformer models have been popular recently due to their enhanced capabilities and performance. In contrast to many existing artificial intelligence models, generative pretrained transformer models can perform with very limited training data. Generative pretrained transformer 3 (GPT-3) is one of the latest releases in this pipeline, demonstrating human-like logical and intellectual responses to prompts. Some examples include writing essays, answering complex questions, matching pronouns to their nouns, and conducting sentiment analyses. However, questions remain with regard to its implementation in health care, specifically in terms of operationalization and its use in clinical practice and research. In this viewpoint paper, we briefly introduce GPT-3 and its capabilities and outline considerations for its implementation and operationalization in clinical practice through a use case. The implementation considerations include (1) processing needs and information systems infrastructure, (2) operating costs, (3) model biases, and (4) evaluation metrics. In addition, we outline the following three major operational factors that drive the adoption of GPT-3 in the US health care system: (1) ensuring Health Insurance Portability and Accountability Act compliance, (2) building trust with health care providers, and (3) establishing broader access to the GPT-3 tools. This viewpoint can inform health care practitioners, developers, clinicians, and decision makers toward understanding the use of the powerful artificial intelligence tools integrated into hospital systems and health care.}
}
@article{ESMAEILI2024127676,
title = {Enhancing digital rock analysis through generative artificial intelligence: Diffusion models},
journal = {Neurocomputing},
volume = {587},
pages = {127676},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127676},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224004478},
author = {Mohammad Esmaeili},
keywords = {Diffusion Models, Generative Artificial Intelligence, Computer Vision, Digital Rock Analysis, Single Image Super-Resolution},
abstract = {Within the realm of computer vision, the landscape has been significantly reshaped by the abundance of extensive and diverse datasets, leading to remarkable breakthroughs in image processing. These advancements have reverberated across a wide spectrum of applications, catalyzing transformative outcomes. However, in stark contrast, the field of digital rock analysis finds itself grappling with a conspicuous dearth of data, a challenge that casts a formidable shadow over the effective deployment of computer vision techniques for rock image analysis. In response to this pressing issue, this paper presents a pioneering methodology designed to surmount the hurdles posed by data limitation in the realm of digital rock analysis. At the core of this innovative approach lies the fusion of artificially generated digital rock images, created using a state-of-the-art diffusion model, with their authentic counterparts. This fusion is guided by the overarching objective of augmenting the efficacy of various digital rock analysis applications. This integration endeavors to bridge the gap between the limited available data and the substantial demands of the digital rock analysis domain. The practical significance and potential of this integrated approach are vividly demonstrated through a series of concrete implementations. These include, but are by no means limited to, enhancing image quality to facilitate clearer visualization of intricate rock structures and refining the estimation of petrophysical properties with increased accuracy.}
}
@article{RAMAN2024e24727,
title = {Fake news research trends, linkages to generative artificial intelligence and sustainable development goals},
journal = {Heliyon},
volume = {10},
number = {3},
pages = {e24727},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e24727},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024007588},
author = {Raghu Raman and Vinith {Kumar Nair} and Prema Nedungadi and Aditya {Kumar Sahu} and Robin Kowalski and Sasangan Ramanathan and Krishnashree Achuthan},
keywords = {Deep fake, Ethics, Fake news, Generative AI, Prominence percentile, Sustainable development goal},
abstract = {In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013–2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.}
}
@article{SAJJADIMOHAMMADABADI2024267,
title = {Generative artificial intelligence for distributed learning to enhance smart grid communication},
journal = {International Journal of Intelligent Networks},
volume = {5},
pages = {267-274},
year = {2024},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2024.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S2666603024000265},
author = {Seyed Mahmoud {Sajjadi Mohammadabadi} and Mahmoudreza Entezami and Aidin {Karimi Moghaddam} and Mansour Orangian and Shayan Nejadshamsi},
keywords = {Energy forecasting, Generative AI, Smart grid, Communication efficiency, Distributed training, LSTM},
abstract = {Machine learning models are the backbone of smart grid optimization, but their effectiveness hinges on access to vast amounts of training data. However, smart grids face critical communication bottlenecks due to the ever-increasing volume of data from distributed sensors. This paper introduces a novel approach leveraging Generative Artificial Intelligence (GenAI), specifically a type of pre-trained Foundation Model (FM) architecture suitable for time series data due to its efficiency and privacy-preserving properties. These GenAI models are distributed to agents, or data holders, empowering them to fine-tune the foundation model with their local datasets. By fine-tuning the foundation model, the updated model can produce synthetic data that mirrors real-world grid conditions. The server aggregates fine-tuned model from all agents and then generates synthetic data which considers all data collected in the grid. This synthetic data can be used to train global machine learning models for specific tasks like anomaly detection and energy optimization. Then, the trained task models are distributed to agents in the grid to leverage them. The paper highlights the advantages of GenAI for smart grid communication, including reduced communication burden, enhanced privacy through anonymized data transmission, and improved efficiency and scalability. By enabling a distributed and intelligent communication architecture, GenAI introduces a novel way for a more secure, efficient, and sustainable energy future.}
}
@article{SAKURAYA2024103947,
title = {Statement on use of generative artificial intelligence by adolescents},
journal = {Asian Journal of Psychiatry},
volume = {94},
pages = {103947},
year = {2024},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2024.103947},
url = {https://www.sciencedirect.com/science/article/pii/S187620182400039X},
author = {Asuka Sakuraya and Masayo Matsumura and Shohei Komatsu and Kotaro Imamura and Mako Iida and Norito Kawakami},
keywords = {Generative artificial intelligence, Adolescents, Mental health}
}
@article{ODRI2023103706,
title = {Detecting generative artificial intelligence in scientific articles: Evasion techniques and implications for scientific integrity},
journal = {Orthopaedics & Traumatology: Surgery & Research},
volume = {109},
number = {8},
pages = {103706},
year = {2023},
issn = {1877-0568},
doi = {https://doi.org/10.1016/j.otsr.2023.103706},
url = {https://www.sciencedirect.com/science/article/pii/S1877056823002244},
author = {Guillaume-Anthony Odri and Diane {Ji Yun Yoon}},
keywords = {Generative artificial intelligence, Academic writing, Scientific fraud},
abstract = {Background
Artificial intelligence (AI) tools, although beneficial for data collection and analysis, can also facilitate scientific fraud. AI detectors can help resolve this problem, but their effectiveness depends on their ability to track AI progress. In addition, many methods of evading AI detection exist and their constantly evolving sophistication can make the task more difficult. Thus, from an AI-generated text, we wanted to: (1) evaluate the AI detection sites on a text generated entirely by the AI, (2) test the methods described for evading AI detection, and (3) evaluate the effectiveness of these methods to evade AI detection on the sites tested previously.
Hypothesis
Not all AI detection tools are equally effective in detecting AI-generated text and some techniques used to evade AI detection can make an AI-produced text almost undetectable.
Materials and methods
We created a text with ChatGPT-4 (Chat Generative Pre-trained Transformer) and submitted it to 11 AI detection web tools (Originality, ZeroGPT, Writer, Copyleaks, Crossplag, GPTZero, Sapling, Content at scale, Corrector, Writefull et Quill), before and after applying strategies to minimise AI detection. The strategies used to minimize AI detection were the improvement of command messages in ChatPGT, the introduction of minor grammatical errors such as comma deletion, paraphrasing, and the substitution of Latin letters with similar Cyrillic letters (а and о) which is also a method used elsewhere to evade the detection of plagiarism. We have also tested the effectiveness of these tools in correctly identifying a scientific text written by a human in 1960.
Results
From the initial text generated by the AI, 7 of the 11 detectors concluded that the text was mainly written by humans. Subsequently, the introduction of simple modifications, such as the removal of commas or paraphrasing can effectively reduce AI detection and make the text appear human for all detectors. In addition, replacing certain Latin letters with Cyrillic letters can make an AI text completely undetectable. Finally, we observe that in a paradoxical way, certain sites detect a significant proportion of AI in a text written by a human in 1960.
Discussion
AI detectors have low efficiency, and simple modifications can allow even the most robust detectors to be easily bypassed. The rapid development of generative AI raises questions about the future of scientific writing but also about the detection of scientific fraud, such as data fabrication.
Level of evidence
III Control case study.}
}
@article{STERPETTI2025388,
title = {Letter Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {388-389},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.02.046},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001325},
author = {Antonio V. Sterpetti}
}
@article{LEE20241318,
title = {Generative Artificial Intelligence},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {8},
pages = {1318-1320},
year = {2024},
note = {Focus on Global Radiology},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S1546144024001303},
author = {Christoph I. Lee and Jonathan H. Chen and Marc D. Kohli and Andrew D. Smith and Joshua M. Liao}
}
@article{TRIANARODRIGUEZ20241158,
title = {Generative Artificial Intelligence: A Promising Instrument for Daily Living and Clinical Practice},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {8},
pages = {1158-1159},
year = {2024},
note = {Focus on Global Radiology},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2023.12.030},
url = {https://www.sciencedirect.com/science/article/pii/S1546144024000577},
author = {Gustavo Adolfo {Triana Rodriguez} and María M. Rojas-Rojas and Katherine Sotomayor and Juan P. Ovalle and José David {Cardona Ortegón}}
}
@article{SACHDEVA2024S445,
title = {MSR40 Leveraging Artificial Intelligence (AI) and Generative AI (GenAI) for Transforming Real-World Evidence ( RWE) Across the Product Value Chain and Industry Functions},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S445},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2274},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524051374},
author = {S Sachdeva and J Kaneria and R Malik and A Prasad and J Gopalakrishna and RS Shah and S Nandiraju}
}
@article{ROLLS2024e31965,
title = {The memory systems of the human brain and generative artificial intelligence},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31965},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31965},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079969},
author = {Edmund T. Rolls},
keywords = {The brain and AI, Generative Pre-trained Transformer, Generative artificial intelligence, Episodic memory, Semantic memory, Hippocampal memory system, Chat-GPT},
abstract = {Generative Artificial Intelligence foundation models (for example Generative Pre-trained Transformer – GPT – models) can generate the next token given a sequence of tokens. How can this ‘generative AI’ be compared with the ‘real’ intelligence of the human brain, when for example a human generates a whole memory in response to an incomplete retrieval cue, and then generates further prospective thoughts? Here these two types of generative intelligence, artificial in machines and real in the human brain are compared, and it is shown how when whole memories are generated by hippocampal recall in response to an incomplete retrieval cue, what the human brain computes, and how it computes it, are very different from generative AI. Key differences are the use of local associative learning rules in the hippocampal memory system, and of non-local backpropagation of error learning in AI. Indeed, it is argued that the whole operation of the human brain is performed computationally very differently to what is implemented in generative AI. Moreover, it is emphasized that the primate including human hippocampal system includes computations about spatial view and where objects and people are in scenes, whereas in rodents the emphasis is on place cells and path integration by movements between places. This comparison with generative memory and processing in the human brain has interesting implications for the further development of generative AI and for neuroscience research.}
}
@article{CHAUHAN20241802,
title = {The Impact of Generative Artificial Intelligence on the External Review of Scientific Manuscripts and Editorial Peer Review Processes},
journal = {The American Journal of Pathology},
volume = {194},
number = {10},
pages = {1802-1806},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024002864},
author = {Chhavi Chauhan and George Currie}
}
@article{MESKO2023,
title = {The ChatGPT (Generative Artificial Intelligence) Revolution Has Made Artificial Intelligence Approachable for Medical Professionals},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48392},
url = {https://www.sciencedirect.com/science/article/pii/S143888712300465X},
author = {Bertalan Mesko},
keywords = {artificial intelligence, digital health, future, technology, ChatGPT, medical practice, large language model, language model, generative, conversational agent, conversation agents, chatbot, generated text, computer generated, medical education, continuing education, professional development, curriculum, curricula},
abstract = {In November 2022, OpenAI publicly launched its large language model (LLM), ChatGPT, and reached the milestone of having over 100 million users in only 2 months. LLMs have been shown to be useful in a myriad of health care–related tasks and processes. In this paper, I argue that attention to, public access to, and debate about LLMs have initiated a wave of products and services using generative artificial intelligence (AI), which had previously found it hard to attract physicians. This paper describes what AI tools have become available since the beginning of the ChatGPT revolution and contemplates how it they might change physicians’ perceptions about this breakthrough technology.}
}
@article{MULE202343,
title = {Generative adversarial networks (GAN)-based data augmentation of rare liver cancers: The SFR 2021 Artificial Intelligence Data Challenge},
journal = {Diagnostic and Interventional Imaging},
volume = {104},
number = {1},
pages = {43-48},
year = {2023},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S2211568422001711},
author = {Sébastien Mulé and Littisha Lawrance and Younes Belkouchi and Valérie Vilgrain and Maité Lewin and Hervé Trillaud and Christine Hoeffel and Valérie Laurent and Samy Ammari and Eric Morand and Orphée Faucoz and Arthur Tenenhaus and Anne Cotten and Jean-François Meder and Hugues Talbot and Alain Luciani and Nathalie Lassau},
keywords = {Artificial intelligence, Deep learning, Generative adversarial networks, Liver cancer, Magnetic resonance imaging},
abstract = {Purpose
The 2021 edition of the Artificial Intelligence Data Challenge was organized by the French Society of Radiology together with the Centre National d’Études Spatiales and CentraleSupélec with the aim to implement generative adversarial networks (GANs) techniques to provide 1000 magnetic resonance imaging (MRI) cases of macrotrabecular-massive (MTM) hepatocellular carcinoma (HCC), a rare and aggressive subtype of HCC, generated from a limited number of real cases from multiple French centers.
Materials and methods
A dedicated platform was used by the seven inclusion centers to securely upload their anonymized MRI examinations including all three cross-sectional images (one late arterial and one portal-venous phase T1-weighted images and one fat-saturated T2-weighted image) in compliance with general data protection regulation. The quality of the database was checked by experts and manual delineation of the lesions was performed by the expert radiologists involved in each center. Multidisciplinary teams competed between October 11th, 2021 and February 13th, 2022.
Results
A total of 91 MTM-HCC datasets of three images each were collected from seven French academic centers. Six teams with a total of 28 individuals participated in this challenge. Each participating team was asked to generate one thousand 3-image cases. The qualitative evaluation was performed by three radiologists using the Likert scale on ten randomly selected cases generated by each participant. A quantitative evaluation was also performed using two metrics, the Frechet inception distance and a leave-one-out accuracy of a 1-Nearest Neighbor algorithm.
Conclusion
This data challenge demonstrates the ability of GANs techniques to generate a large number of images from a small sample of imaging examinations of a rare malignant tumor.}
}
@article{M2025530,
title = {Debunking myths about Enhanced Recovery After Surgery (ERAS) using Generative Artificial Intelligence},
journal = {Clinical Nutrition ESPEN},
volume = {65},
pages = {530-531},
year = {2025},
issn = {2405-4577},
doi = {https://doi.org/10.1016/j.clnesp.2024.10.104},
url = {https://www.sciencedirect.com/science/article/pii/S2405457724014414},
author = {Aravind M}
}
@article{CONTE2024110893,
title = {Statistical analysis and generative Artificial Intelligence (AI) for assessing pain experience, pain-induced disability, and quality of life in Parkinson's disease patients},
journal = {Brain Research Bulletin},
volume = {208},
pages = {110893},
year = {2024},
issn = {0361-9230},
doi = {https://doi.org/10.1016/j.brainresbull.2024.110893},
url = {https://www.sciencedirect.com/science/article/pii/S0361923024000261},
author = {Luana Conte and Roberto Lupo and Pierluigi Lezzi and Alessio Pedone and Ivan Rubbi and Alessia Lezzi and Elsa Vitale and Antonio Fasano and Giorgio {De Nunzio}},
keywords = {Parkinson's disease, Pain, King's Parkinson's Disease Pain Questionnaire (KPPQ), Parkinson's Disease Questionnaire (PDQ), Generative Artificial Intelligence (AI)},
abstract = {The Parkinson's Disease (PD) is a chronic neurodegenerative condition characterized by motor symptoms such as tremors, rigidity, and bradykinesia, which can significantly impact various aspects of daily life. Among these aspects, pain is a prominent element. Despite the widespread use of therapies aimed at improving symptoms and quality of life, effective pain management is essential to enhance the quality of life of individuals affected by this disease. However, a detailed understanding of the factors associated with pain in PD is still evolving. In this study, we examined the disability caused by pain and the pain experienced by PD patients using two validated questionnaires, namely the Parkinson's Disease Questionnaire (PDQ) and the King's Parkinson's Disease Pain Questionnaire (KPPQ). Customized questions were also included to further explore the pain experience and management strategies adopted by PD patients. Through statistical analysis, we explored the relationships between questionnaire scores, socio-demographic data, and other relevant variables. Additionally, generative Artificial Intelligence (AI) was employed to gain a deeper understanding of patient responses. The results indicate the extent and impact of pain in PD and provide valuable insights for more targeted and personalized management. This study lays the foundation for future research and the development of interventions aimed at improving the quality of life for individuals affected by this condition.}
}
@article{ISLEEM202427,
title = {Can generative artificial intelligence pass the orthopaedic board examination?},
journal = {Journal of Orthopaedics},
volume = {53},
pages = {27-33},
year = {2024},
issn = {0972-978X},
doi = {https://doi.org/10.1016/j.jor.2023.10.026},
url = {https://www.sciencedirect.com/science/article/pii/S0972978X23002593},
author = {Ula N. Isleem and Bashar Zaidat and Renee Ren and Eric A. Geng and Aonnicha Burapachaisri and Justin E. Tang and Jun S. Kim and Samuel K. Cho},
abstract = {Background
Resident training programs in the US use the Orthopaedic In-Training Examination (OITE) developed by the American Academy of Orthopaedic Surgeons (AAOS) to assess the current knowledge of their residents and to identify the residents at risk of failing the Amerian Board of Orthopaedic Surgery (ABOS) examination. Optimal strategies for OITE preparation are constantly being explored. There may be a role for Large Language Models (LLMs) in orthopaedic resident education. ChatGPT, an LLM launched in late 2022 has demonstrated the ability to produce accurate, detailed answers, potentially enabling it to aid in medical education and clinical decision-making. The purpose of this study is to evaluate the performance of ChatGPT on Orthopaedic In-Training Examinations using Self-Assessment Exams from the AAOS database and approved literature as a proxy for the Orthopaedic Board Examination.
Methods
301 SAE questions from the AAOS database and associated AAOS literature were input into ChatGPT's interface in a question and multiple-choice format and the answers were then analyzed to determine which answer choice was selected. A new chat was used for every question. All answers were recorded, categorized, and compared to the answer given by the OITE and SAE exams, noting whether the answer was right or wrong.
Results
Of the 301 questions asked, ChatGPT was able to correctly answer 183 (60.8%) of them. The subjects with the highest percentage of correct questions were basic science (81%), oncology (72.7%, shoulder and elbow (71.9%), and sports (71.4%). The questions were further subdivided into 3 groups: those about management, diagnosis, or knowledge recall. There were 86 management questions and 47 were correct (54.7%), 45 diagnosis questions with 32 correct (71.7%), and 168 knowledge recall questions with 102 correct (60.7%).
Conclusions
ChatGPT has the potential to provide orthopedic educators and trainees with accurate clinical conclusions for the majority of board-style questions, although its reasoning should be carefully analyzed for accuracy and clinical validity. As such, its usefulness in a clinical educational context is currently limited but rapidly evolving.
Clinical relevance
ChatGPT can access a multitude of medical data and may help provide accurate answers to clinical questions.}
}
@article{XIAO20232973,
title = {Generative Artificial Intelligence GPT‑4 Accelerates Knowledge Mining and Machine Learning for Synthetic Biology},
journal = {ACS Synthetic Biology},
volume = {12},
number = {10},
pages = {2973-2982},
year = {2023},
issn = {2161-5063},
doi = {https://doi.org/10.1021/acssynbio.3c00310},
url = {https://www.sciencedirect.com/science/article/pii/S2161506323000323},
author = {Zhengyang Xiao and Wenyu Li and Hannah Moon and Garrett W. Roell and Yixin Chen and Yinjie J. Tang},
keywords = {feature selection, natural language processing, human intervention, prompt engineering, transfer learning,   },
abstract = {Knowledge mining from synthetic biology journal articles for machine learning (ML) applications is a labor-intensive process. The development of natural language processing (NLP) tools, such as GPT-4, can accelerate the extraction of published information related to microbial performance under complex strain engineering and bioreactor conditions. As a proof of concept, we proposed prompt engineering for a GPT-4 workflow pipeline to extract knowledge from 176 publications on two oleaginous yeasts (Yarrowia lipolytica and Rhodosporidium toruloides). After human intervention, the pipeline obtained a total of 2037 data instances. The structured data sets and feature selections enabled ML approaches (e.g., a random forest model) to predict Yarrowia fermentation titers with decent accuracy (R 2 of 0.86 for unseen test data). Via transfer learning, the trained model could assess the production potential of the engineered nonconventional yeast, R. toruloides, for which there are fewer published reports. This work demonstrated the potential of generative artificial intelligence to streamline information extraction from research articles, thereby facilitating fermentation predictions and biomanufacturing development.
}
}
@article{CAO2024e147,
title = {GENERATIVE ARTIFICIAL INTELLIGENCE SUBSTANTIALLY ENHANCES THE ACCURACY OF EMBRYO SELECTION MODELS},
journal = {Fertility and Sterility},
volume = {122},
number = {4, Supplement },
pages = {e147},
year = {2024},
note = {80th Scientific Congress of the American Society for Reproductive Medicine},
issn = {0015-0282},
doi = {https://doi.org/10.1016/j.fertnstert.2024.07.533},
url = {https://www.sciencedirect.com/science/article/pii/S0015028224011506},
author = {Ping Cao and Ganesh Acharya and Andres Salumets and Masoud Zamani Esteki}
}
@article{FIJACKO2024100584,
title = {Using generative artificial intelligence in bibliometric analysis: 10 years of research trends from the European Resuscitation Congresses},
journal = {Resuscitation Plus},
volume = {18},
pages = {100584},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100584},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000353},
author = {Nino Fijačko and Ruth Masterson Creber and Benjamin S. Abella and Primož Kocbek and Špela Metličar and Robert Greif and Gregor Štiglic},
keywords = {Emergency medicine, European Resuscitation Council, Congress, Bibliometrics analysis, Generative artificial intelligence},
abstract = {Aims
The aim of this study is to use generative artificial intelligence to perform bibliometric analysis on abstracts published at European Resuscitation Council (ERC) annual scientific congress and define trends in ERC guidelines topics over the last decade.
Methods
In this bibliometric analysis, the WebHarvy software (SysNucleus, India) was used to download data from the Resuscitation journal's website through the technique of web scraping. Next, the Chat Generative Pre-trained Transformer 4 (ChatGPT-4) application programming interface (Open AI, USA) was used to implement the multinomial classification of abstract titles following the ERC 2021 guidelines topics.
Results
From 2012 to 2022 a total of 2491 abstracts have been published at ERC congresses. Published abstracts ranged from 88 (in 2020) to 368 (in 2015). On average, the most common ERC guidelines topics were Adult basic life support (50.1%), followed by Adult advanced life support (41.5%), while Newborn resuscitation and support of transition of infants at birth (2.1%) was the least common topic. The findings also highlight that the Basic Life Support and Adult Advanced Life Support ERC guidelines topics have the strongest co-occurrence to all ERC guidelines topics, where the Newborn resuscitation and support of transition of infants at birth (2.1%; 52/2491) ERC guidelines topic has the weakest co-occurrence.
Conclusion
This study demonstrates the capabilities of generative artificial intelligence in the bibliometric analysis of abstract titles using the example of resuscitation medicine research over the last decade at ERC conferences using large language models.}
}
@article{DAUNGSUPAWONG2024361,
title = {Generative Artificial Intelligence in Dental Licensing Examinations: Comment},
journal = {International Dental Journal},
volume = {74},
number = {2},
pages = {361},
year = {2024},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2024.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0020653924000431},
author = {Hinpetch Daungsupawong and Viroj Wiwanitkit}
}
@incollection{BEHESHTI2025333,
title = {Chapter 13 - Exploring the convergence of Internet of things and big data technologies in the age of generative artificial intelligence},
editor = {Mohamed Adel Serhani and Yang Xu and Zakaria Maamar},
booktitle = {Empowering IoT with Big Data Analytics},
publisher = {Academic Press},
pages = {333-354},
year = {2025},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-21640-4},
doi = {https://doi.org/10.1016/B978-0-443-21640-4.00004-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443216404000041},
author = {Amin Beheshti and Wathiq Mansoor},
keywords = {Internet of things (IoT), Big data analytics, Generative artificial intelligence (AI), Data curation},
abstract = {The Internet of things (IoT) has transformed the way we interact with the physical world, generating an unprecedented volume of data. In modern enterprises, the convergence of IoT, big data, and generative artificial intelligence (GAI) is reshaping the landscape of digital solutions. This chapter explores this convergence, shedding light on emerging solutions, software architectures, and challenges and opportunities in the age of GAI. We explore the complexities of effectively using IoT-generated data, emphasizing the challenges of gathering, organizing, curating, and processing these data for meaningful insights. We highlight the importance of linking analytical, cognitive, and GAI to enable the development of self-evolving systems capable of learning from extensive data streams and making instant data-driven decisions and predictions. This synergy between IoT, big data, and AI can transform various industries by enhancing automation, augmentation, and improvement of their processes.}
}
@article{AZIZOGLU2025162359,
title = {Generative Artificial Intelligence Accuracy in Interpreting Forest Plots in Pediatric Surgery Meta-analyses: A Perspective From Pediatric Surgery Meta-analysis Study Group (PESMA)},
journal = {Journal of Pediatric Surgery},
volume = {60},
number = {7},
pages = {162359},
year = {2025},
issn = {0022-3468},
doi = {https://doi.org/10.1016/j.jpedsurg.2025.162359},
url = {https://www.sciencedirect.com/science/article/pii/S0022346825002040},
author = {Mustafa Azizoglu and Maria Escolino and Tahsin Onat Kamci and Sergey Klyuev and Sonia {Perez Bertolez} and Toni Risteski and Ismael Elhalaby and Nitinkumar Borkar and Ciro Esposito and Mehmet Hanifi Okur and Martin Lacher and Annika Mutanen and Sameh Shehata and Fabio Chiarenza and Mark Davenport}
}
@article{RAY20231457,
title = {Generative Artificial Intelligence (AI) and Medical Ethics: A Symbiotic Dance for the Future},
journal = {Journal of Oral and Maxillofacial Surgery},
volume = {81},
number = {12},
pages = {1457-1459},
year = {2023},
issn = {0278-2391},
doi = {https://doi.org/10.1016/j.joms.2023.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0278239123011588},
author = {Partha Pratim Ray}
}
@article{BYRNE2023519,
title = {Generative Artificial Intelligence and ChatGPT},
journal = {Journal of PeriAnesthesia Nursing},
volume = {38},
number = {3},
pages = {519-522},
year = {2023},
issn = {1089-9472},
doi = {https://doi.org/10.1016/j.jopan.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1089947223001405},
author = {Matthew D. Byrne}
}
@article{VLACHOPOULOS2024120,
title = {Generative artificial intelligence tools in scientific writing: entering a brave new world?},
journal = {Hellenic Journal of Cardiology},
volume = {77},
pages = {120-121},
year = {2024},
issn = {1109-9666},
doi = {https://doi.org/10.1016/j.hjc.2024.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S1109966624001180},
author = {Charalambos Vlachopoulos and Alexios Antonopoulos and Dimitrios Terentes-Printzios}
}
@article{PIERCE2024S444,
title = {MSR33 Utilizing Generative Artificial Intelligence in Network Meta-Analysis: Assessing the Effectiveness of GenAI as a Tool in Feasibility Assessments},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S444},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2267},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524051301},
author = {P Pierce and C Kraan and C Bennison and S Petersohn and S Kroep and K Nickel}
}
@article{BRITOZERON2025570,
title = {POS0311 SARCOIDOSIS AS A SYSTEMIC DISEASE: IDENTIFYING PATTERNS OF MULTIORGAN-SPECIFIC INVOLVEMENT AND EPIDEMIOLOGICAL PROFILING THROUGH GENERATIVE ARTIFICIAL INTELLIGENCE-DRIVEN CLUSTERING},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {570-571},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.05.698},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725017315},
author = {P. Brito-Zerón and A. Flores-Chávez and C. Feijoo-Masso and G. Policarpo-Torres and R. {Gómez de la Torre} and B. Escalante and J.M. Lopez-Dupla and C. Soler-i-Ferrer and E. Fonseca-Aizpuru and A. González-García and J.C. Herranz-Pérez and S. {GARCÍA MORILLO} and A. Alguacil and Á. {Robles Marhuenda} and M. Bonet and M.V. Villalba-García and A.J. Chamorro and B. {De Miguel-Campo} and M.G. {CRUZ CAPARROS} and M. {Akasbi Montalvo} and A. Mayer-Fuentes and M. Ramos-Casals},
keywords = {Registries, Artificial Intelligence, Prognostic factors, Epidemiology, Comorbidities},
abstract = {Background:
Sarcoidosis is a heterogeneous granulomatous disease characterized by a wide range of clinical manifestations stemming from multiple organ involvement. While clustering techniques offer a robust method for uncovering these patterns, traditional approaches may fail to fully capture the complexity of multisystem diseases like sarcoidosis. Leveraging generative artificial intelligence (AI) offers a unique opportunity to improve data analysis and interpretation in complex systemic settings, providing novel insights into multifaceted disease patterns and guiding both hypothesis generation and clinical decision-making.
Objectives:
This study aimed to identify distinct clusters of organ involvement in patients with sarcoidosis, assess their corresponding epidemiological characteristics, and highlight the benefits of AI-driven methodologies in handling complex multisystem data—underscoring the feasibility and advantages of advanced AI-based approaches for systemic phenotypes in this heterogeneous disease.
Methods:
We conducted an AI-assisted analysis to identify organ-involvement clusters in a dataset of 2,187 anonymized sarcoidosis patients (Spanish National Registry SarcoGEAS, all fulfilling the 1999 ATS/ERS/WASOG criteria). Organ involvement was retrospectively determined in each patient at the time of diagnosis using the 2014 WASOG organ assessment instrument. Clustering was carried out via the k-means algorithm in Python's scikit-learn library (version 1.0.2). The optimal number of clusters was determined using the elbow method, supported by silhouette scores to evaluate cluster quality. Statistical comparisons (ANOVA, Kruskal-Wallis, and Chi-square tests—using exact tests for low-frequency data) were applied to characterize cluster differences. Significance was set at p < 0.05, ensuring rigorous evaluation of epidemiological and clinical distinctions. The analysis was conducted in a secure computational environment using generative AI (via OpenAI's GPT-4 model) using Python (version 3.9) with essential libraries including pandas (1.4.3) for data manipulation, numpy (1.21.5) for numerical computations, and matplotlib (3.5.1) and seaborn (0.11.2) for visualizations. Data processing and analysis workflows adhered to GDPR standards to ensure patient privacy. All patient data were anonymized prior to analysis, and no identifiable information was accessed at any point. Code modularity and reproducibility were prioritized, with all scripts managed in version control systems (e.g., Git) to enable transparency.
Results:
The cohort comprised 2,187 patients, with a female predominance (61.4%), a mean age at diagnosis of 48.6 years (range: 5-95), and a majority identifying as White (88%). Cluster quality analysis identified 5 as the optimal number of clusters potential; an additional clinically significant cluster (hepatic-splenic) was manually identified and confirmed post hoc through statistical validation. Ultimately, we defined six distinct clusters of systemic involvement: the lymphadenopathic cluster (Cluster 1, characterized by 100% lymphadenopathy), the pulmonary cluster (Cluster 2, characterized by 100% lung involvement and co-occurring 100% lymphadenopathy), the cutaneous cluster (Cluster 3, 100% of cutaneous involvement), the ocular cluster (Cluster 4, 100% ocular involvement), the hepato-splenic cluster (Cluster 5, defined by 100% hepatic and splenic involvement), and the multisystemic cluster (Cluster 6, exhibiting generalized, but not predominant, organ involvement). Each cluster demonstrated statistically significant epidemiological differences (Figure 1). For age, the lymphadenopathic cluster had the highest mean (51.7 years), whereas the cutaneous cluster had the lowest (42.9 years) (p = 0.00056). For sex, the proportion of females ranged from 49.0% in the hepato-splenic cluster to 65.9% in the ocular cluster (p = 0.000017). For ethnicity, the proportion of White patients ranged from 81.4% in the ocular cluster to 94.6% in the lymphadenopathic cluster (p = 0.00135).
Conclusion:
This generative AI-driven clustering study successfully identified six distinct patterns of systemic involvement in sarcoidosis, offering a deeper understanding of the disease's heterogeneity. Each cluster exhibited specific epidemiological profiles: cutaneous cluster was associated with the youngest age at sarcoidosis diagnosis, lymphadenopathic cluster with the oldest age and the highest frequency of White patients, ocular cluster with the highest frequency of women and highest frequency of non-White patients, and the hepato-splenic cluster with the highest rate of men. The significant epidemiological disparities among clusters underscore the disease's variability and offer a framework for refined patient stratification.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{BURNS2024100166,
title = {Practical implementation of generative artificial intelligence systems in healthcare: A United States perspective},
journal = {Future Healthcare Journal},
volume = {11},
number = {3},
pages = {100166},
year = {2024},
issn = {2514-6645},
doi = {https://doi.org/10.1016/j.fhj.2024.100166},
url = {https://www.sciencedirect.com/science/article/pii/S251466452401556X},
author = {Barclay Burns and Bo Nemelka and Anmol Arora}
}
@article{BRITOZERON20252097,
title = {ABS0885 COMPLEMENT CONSUMPTION PATTERNS AS AN EARLY PREDICTOR OF SYSTEMIC SJÖGREN DISEASE: GENERATIVE ARTIFICIAL INTELLIGENCE-ASSISTED ANALYSIS USING STRATIFIED CROSS-VALIDATION GENERALIZABILITY MODELS},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {2097-2098},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.06.1702},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725037550},
author = {P. Brito-Zerón and A. Flores-Chávez and L.T. {Delgado Garcia} and I.F. Horváth and R. Priori and H. Bootsma and B. Armagan and V. Manfrè and S. Praprotnik and G. Hernandez-Molina and R. {Pereira da Costa} and R. Gerli and M. Rischmueller and Y. Suzuki and R. Solans-Laqué and S. Pasoto and E. Skoglund and I. Sanchez-Berna and A. Alunno and V. {Fernandes Moça Trevisani} and V. Valim and S. {Melchor Díaz} and B. {Maure Noia} and E. Fonseca-Aizpuru and H. Nakamura and L.D. Miguel and M. Vázquez and M. {Akasbi Montalvo} and G. Policarpo-Torres and B. {De Miguel-Campo} and A. Szántó and A. Gattamelata and A. Vissink and L. Quartuccio and L. Kiliç and K. Perdan-Pirkmajer and V.C. Romão and E. Bartoloni and S. Downie-Doyle and Y. Fujisawa and M. Ramos-Casals},
keywords = {Validation, Artificial Intelligence},
abstract = {Background:
Complement consumption, characterized by decreased C3 and/or C4 levels, is a hallmark of immune complex-mediated inflammation and vascular involvement in patients with systemic autoimmune diseases. In patients with Sjögren Disease (SjD), hypocomplementemia at diagnosis has been mainly linked to an increased risk of lymphoma. By analysing the relationship between complement consumption profiles and systemic activity in the largest international cohort, we aim to refine early prognostic paradigms and inform tailored clinical surveillance strategies in SjD, thereby addressing a critical gap in precision medicine for this complex autoimmune disease.
Objectives:
The objectives of this study were to identify and classify complement consumption patterns, investigate their association with an early phenotype consisting of systemic activity across ESSDAI domains while adjusting for age and gender, and explore how cross-validation techniques may validate the predictive accuracy and generalizability of developed models.
Methods:
This study analyzed data from the International Sjögren Big Data Registry. Patients were categorized into four distinct groups according to their complement consumption patterns (isolated low C3, isolated low C4, combined low C3 and C4, and normal C3 and C4 levels). We used Chi-square tests to evaluate univariate associations, and Kruskal-Wallis H-test and Mann-Whitney U test to investigate significant differences with respect to systemic activity (mean ESSDAI score and DAS categories). Multivariable logistic regression models were developed to analyze associations between complement patterns and ESSDAI domains, adjusting for age and gender. Odds ratios (ORs) and 95% confidence intervals (CIs) were calculated. A five-fold stratified cross-validation was carried out to rigorously evaluate the models' generalizability, with the Area Under the Curve (AUC) serving as the primary performance metric. Generative Artificial Intelligence (AI) (ChatGPT-4o model) was used within a secure offline environment to automate anonymized data recoding and statistical scripting. Python libraries, including pandas, statsmodels, and scikit-learn, were integral for data processing, model development, and cross-validation.
Results:
Complement values determined at diagnosis were available in 13,710 patients. Stratification according to the 4 complement consumption patterns identified that 79.58% of patients had normal levels of C3 and C4, 7.42% exhibited isolated low C3, 6.90% showed isolated low C4, and 6.09% presented combined low C3 and C4 levels. Combined low C3-C4 levels exhibited the highest mean ESSDAI score (11.41), follwed by isolated low C3, isolated low C4 and normocomplementemia (mean ESSDAI score of 9.26, 7.39, and 5.66, respectively) (Figure 1); Kruskal-Wallis H-test revealed a highly significant difference between the groups (p<0.001), as well as pairwise comparisons using the Mann-Whitney U test (p<0.001). The Chi-square test revealed significant differences in the distribution of DAS categories across the C3-C4 combined groups (χ2=476.41, p<0.001) (Figure 2). However, multivariate logistic regression confirmed significant associations in only three domains. For the pulmonary domain, combined low C3 and C4 levels were associated with the highest odds of activity (OR: 3.12, 95% CI: 2.50–3.91, p < 0.001; AUC: 0.591). In the biological domain, isolated low C3 strongly correlated with activity (OR: 2.45, 95% CI: 1.98–3.03, p < 0.001; AUC: 0.580). For constitutional symptoms, isolated low C3 was associated with the highest activity frequency (18.54%), whereas normal complement levels showed the lowest frequency (11.06%, OR: 0.56, 95% CI: 0.48–0.67, p < 0.001; AUC: 0.563). After adjusting for epidemiological factors, sex and age emerged as influential variables: men had higher odds of constitutional activity (OR 1.24, 95% CI: 1.02–1.52, p = 0.03), while older age had a protective effect, reducing systemic activity by about 1% per year (OR: 0.99, 95% CI: 0.99–1.00, p = 0.0003). The AUC values obtained after running the five-fold stratified cross-validation generalizability models ranged between 0.56 and 0.59, indicating modest ability to discriminate between active and inactive states.
Conclusion:
This study demonstrates that complement consumption patterns are strongly associated with baseline systemic activity in SjD, highlighting their potential as early prognostic markers. While complement patterns provide valuable insights for risk stratification, the current predictive models exhibit modest discriminatory ability (AUC values between 0.5 and 0.6), suggesting that complement patterns are relevant but insufficient alone as predictors to improve clinical applicability. The nuanced influence of epidemiological factors—such as the protective effect of age and the increased susceptibility of men to systemic disease—adds complexity to our understanding of early systemic Sjögren.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{THELANCET20241,
title = {Rethinking research and generative artificial intelligence},
journal = {The Lancet},
volume = {404},
number = {10447},
pages = {1},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)01394-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624013941},
author = { {The Lancet}}
}
@article{ZHU2024114132,
title = {OpenAI’s GPT-4o in surgical oncology: Revolutionary advances in generative artificial intelligence},
journal = {European Journal of Cancer},
volume = {206},
pages = {114132},
year = {2024},
issn = {0959-8049},
doi = {https://doi.org/10.1016/j.ejca.2024.114132},
url = {https://www.sciencedirect.com/science/article/pii/S0959804924007883},
author = {Ning Zhu and Nan Zhang and Qipeng Shao and Kunming Cheng and Haiyang Wu}
}
@article{MARTIN2024100265,
title = {Navigating the data frontier in science assessment: Advancing data augmentation strategies for machine learning applications with generative artificial intelligence},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100265},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100265},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000687},
author = {Paul P. Martin and Nicole Graulich},
keywords = {Assessment, Large language models (LLMs), Machine learning (ML), Data augmentation, Science education},
abstract = {Machine learning (ML) techniques are commonly seen as an inductive learning procedure, typically involving the identification of patterns in a specific training dataset to make predictions in novel contexts. By doing so, the performance and generalizability of these techniques often rely on the quality and quantity of the available training data. However, gathering a diverse training dataset that captures multiple nuances of students’ reasoning poses challenges in educational settings due to resource constraints. We compared three data augmentation strategies to address this issue: collecting additional student data, utilizing chatbots to paraphrase existing responses, and prompting chatbots to generate synthetic responses. We found that leveraging data augmentation significantly improved ML model performance. In detail, combining authentic and/or paraphrased responses with chatbot responses yielded the best machine-human score agreements across various validation conditions. This data augmentation allowed us to expand our applied scoring rubric by introducing a more detailed categorization that better captured the level of causality in undergraduate chemistry students’ reasoning about reaction mechanisms. Together, these findings highlight effective possibilities for augmenting the size and heterogeneity of the training data to improve ML model performance and generalizability, introduce a more fine-grained categorization, and reduce human effort in data collection. In the future, these benefits may enhance the scalability of formative assessments that adaptively support students’ reasoning in postsecondary chemistry classes.}
}
@article{BAGENAL20241118,
title = {Generative artificial intelligence and scientific publishing: urgent questions, difficult answers},
journal = {The Lancet},
volume = {403},
number = {10432},
pages = {1118-1120},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)00416-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624004161},
author = {Jessamy Bagenal}
}
@article{DAUNGSUPAWONG2024105498,
title = {Correspondence: Generative artificial intelligence in healthcare},
journal = {International Journal of Medical Informatics},
volume = {189},
pages = {105498},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105498},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001618},
author = {Hineptch Daungsupawong and Viroj Wiwanitkit},
keywords = {Generative, Artificial intelligence, Healthcare}
}
@article{GLYNN2024596,
title = {Suspected undeclared use of generative artificial intelligence},
journal = {Intelligent Pharmacy},
volume = {2},
number = {5},
pages = {596-597},
year = {2024},
issn = {2949-866X},
doi = {https://doi.org/10.1016/j.ipha.2024.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949866X24000492},
author = {Alex Glynn},
keywords = {Generative artificial intelligence, Transparency, Accountability},
abstract = {In a recent article in Intelligent Pharmacy, a portion of the text appears to have been generated by a generative artificial intelligence (AI) system. The usage of AI is not documented in the article. If AI was used, therefore, the article is in violation of the journal's policy on generative AI use and declaration.}
}
@article{DHAWAN202447,
title = {Generative artificial intelligence in surgery: balancing innovation with ethical challenges},
journal = {Journal of Plastic, Reconstructive & Aesthetic Surgery},
volume = {90},
pages = {47-48},
year = {2024},
issn = {1748-6815},
doi = {https://doi.org/10.1016/j.bjps.2024.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1748681524000731},
author = {Ravi Dhawan and Akshay Nair and Denys Shay}
}
@article{PILLAI2023100213,
title = {Accuracy of generative artificial intelligence models in differential diagnoses of familial Mediterranean fever and deficiency of Interleukin-1 receptor antagonist},
journal = {Journal of Translational Autoimmunity},
volume = {7},
pages = {100213},
year = {2023},
issn = {2589-9090},
doi = {https://doi.org/10.1016/j.jtauto.2023.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2589909023000266},
author = {Joshua Pillai and Kathryn Pillai},
keywords = {DIRA, Deficiency of Interleukin-1 receptor antagonist, Familial Mediterranean fever, FMF, Artificial intelligence},
abstract = {With the increasing development of artificial intelligence, large language models (LLMs) have been utilized to solve problems in natural language processing tasks. More recently, LLMs have shown unique potential in numerous applications within medicine but have been particularly investigated for their ability in clinical reasoning. Although the diagnostic accuracy of LLMs in forming differential diagnoses has been reviewed in general internal medicine applications, much is unknown in autoinflammatory disorders. From the nature of autoinflammatory diseases, forming a differential diagnosis is challenging due to the overlapping symptoms between disorders and even more difficult without genetic screening. In this work, the diagnostic accuracy of the Generative Pre-Trained Transformer Model-4 (GPT-4), GPT-3.5, and Large Language Model Meta AI (LLaMa) were evaluated in clinical vignettes of Deficiency of Interleukin-1 Receptor Antagonist (DIRA) and Familial Mediterranean Fever (FMF). We then compared these models to a control group including one internal medicine physician. It was found that GPT-4 did not significantly differ in correctly identifying DIRA and FMF patients compared to the internist. However, the physician maintained a significantly higher accuracy than GPT-3.5 and LLaMa 2 for either disease. Overall, we explore and discuss the unique potential of LLMs in diagnostics for autoimmune diseases.}
}
@article{HYUNBAEK2023102030,
title = {Is ChatGPT scary good? How user motivations affect creepiness and trust in generative artificial intelligence},
journal = {Telematics and Informatics},
volume = {83},
pages = {102030},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102030},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323000941},
author = {Tae {Hyun Baek} and Minseong Kim},
keywords = {ChatGPT, Generative artificial intelligence (AI), Uses and gratifications theory, Creepiness, Trust, Continuance intention},
abstract = {Few studies have examined user motivations to use generative artificial intelligence (AI). This research aims to address this gap by examining how user motivations for ChatGPT usage affect perceived creepiness, trust, and the intention to continue using AI chatbot technology. The findings of an online survey (N = 421) reveal a negative relationship between personalization and creepiness, while task efficiency and social interaction are positively associated with creepiness. Increased levels of creepiness, in turn, result in decreased continuance intention. Furthermore, task efficiency and personalization have a positive impact on trust, leading to increased continuance intention. The results contribute to the field of human–computer interaction by investigating the motivations for utilizing generative AI chatbots and advancing our comprehension of AI creepiness, trust, and continuance intention. The practical ramifications of this research can inform the design of user interfaces and the development of features for generative AI chatbots.}
}
@article{BRAGAZZI2023,
title = {The Impact of Generative Conversational Artificial Intelligence on the Lesbian, Gay, Bisexual, Transgender, and Queer Community: Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/52091},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123009330},
author = {Nicola Luigi Bragazzi and Andrea Crapanzano and Manlio Converti and Riccardo Zerbetto and Rola Khamisy-Farah},
keywords = {generative conversational artificial intelligence, chatbot, lesbian, gay, bisexual, transgender, and queer community, LGBTQ, scoping review, mobile phone},
abstract = {Background
Despite recent significant strides toward acceptance, inclusion, and equality, members of the lesbian, gay, bisexual, transgender, and queer (LGBTQ) community still face alarming mental health disparities, being almost 3 times more likely to experience depression, anxiety, and suicidal thoughts than their heterosexual counterparts. These unique psychological challenges are due to discrimination, stigmatization, and identity-related struggles and can potentially benefit from generative conversational artificial intelligence (AI). As the latest advancement in AI, conversational agents and chatbots can imitate human conversation and support mental health, fostering diversity and inclusivity, combating stigma, and countering discrimination. In contrast, if not properly designed, they can perpetuate exclusion and inequities.
Objective
This study aims to examine the impact of generative conversational AI on the LGBTQ community.
Methods
This study was designed as a scoping review. Four electronic scholarly databases (Scopus, Embase, Web of Science, and MEDLINE via PubMed) and gray literature (Google Scholar) were consulted from inception without any language restrictions. Original studies focusing on the LGBTQ community or counselors working with this community exposed to chatbots and AI-enhanced internet-based platforms and exploring the feasibility, acceptance, or effectiveness of AI-enhanced tools were deemed eligible. The findings were reported in accordance with the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews).
Results
Seven applications (HIVST-Chatbot, TelePrEP Navigator, Amanda Selfie, Crisis Contact Simulator, REALbot, Tough Talks, and Queer AI) were included and reviewed. The chatbots and internet-based assistants identified served various purposes: (1) to identify LGBTQ individuals at risk of suicide or contracting HIV or other sexually transmitted infections, (2) to provide resources to LGBTQ youth from underserved areas, (3) facilitate HIV status disclosure to sex partners, and (4) develop training role-play personas encompassing the diverse experiences and intersecting identities of LGBTQ youth to educate counselors. The use of generative conversational AI for the LGBTQ community is still in its early stages. Initial studies have found that deploying chatbots is feasible and well received, with high ratings for usability and user satisfaction. However, there is room for improvement in terms of the content provided and making conversations more engaging and interactive. Many of these studies used small sample sizes and short-term interventions measuring limited outcomes.
Conclusions
Generative conversational AI holds promise, but further development and formal evaluation are needed, including studies with larger samples, longer interventions, and randomized trials to compare different content, delivery methods, and dissemination platforms. In addition, a focus on engagement with behavioral objectives is essential to advance this field. The findings have broad practical implications, highlighting that AI’s impact spans various aspects of people’s lives. Assessing AI’s impact on diverse communities and adopting diversity-aware and intersectional approaches can help shape AI’s positive impact on society as a whole.}
}
@article{HASAN2025545,
title = {Generative Versus Nongenerative Artificial Intelligence},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {3},
pages = {545-546},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0749806324010181},
author = {Sayyida S. Hasan and Joshua J. Woo and Mark P. Cote and Prem N. Ramkumar},
abstract = {Abstract
Artificial intelligence (AI) is a colossal buzzword, a confusing subject matter, but also an inevitable reality. Generative and nongenerative AI are the 2 core subtypes of AI. Generative AI uses current data to understand patterns and generate new information, and it is especially valuable in producing synthetic medical images, enhancing surgical simulations, and expanding training datasets. Techniques such as generative adversarial networks (GANs), large language models (LLMs), and variational autoencoders (VAEs) allow for the creation of realistic simulations, text, and models that can be used for perioperative communication and planning. Conversely, nongenerative AI is centered on the examination and categorization of pre-existing data to formulate predictions or decisions—the most popular denomination namely machine learning. This approach is instrumental in tasks such as forecasting surgical outcomes, segmenting medical images, and determining patient risk profiles. Models such as convolutional neural networks (CNNs), random forests, and support vector machines (SVMs) are widely used for these purposes, demonstrating high accuracy and reliability in clinical decision making. Although generative AI offers innovative tools for creating new data and simulations, nongenerative AI excels in analyzing existing data to inform patient care. Both approaches have the potential of supporting clinical workflows to automate redundancies and improve efficiencies. However, there are also limitations in the application of AI in orthopaedics, including the potential for bias in models, the challenge of interpreting AI-driven insights, and the ethics of oversight. As the integration of AI in orthopaedics continues to grow, it is essential for practitioners to understand these technologies' capabilities and limitations to harness their full potential and establish appropriate governance.}
}
@article{WINNIFRITH2024102794,
title = {Generative artificial intelligence for de novo protein design},
journal = {Current Opinion in Structural Biology},
volume = {86},
pages = {102794},
year = {2024},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2024.102794},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X24000216},
author = {Adam Winnifrith and Carlos Outeiral and Brian L. Hie},
abstract = {Engineering new molecules with desirable functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called ‘de novo’ design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example, in determining the best in silico metrics to prioritise designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.}
}
@article{DINAPOLI2024S2935,
title = {1871: Generative artificial intelligence for toxicity detection in radiotherapy},
journal = {Radiotherapy and Oncology},
volume = {194},
pages = {S2935-S2936},
year = {2024},
note = {ESTRO 2024, 3-7 May 2024, Glasgow, UK},
issn = {0167-8140},
doi = {https://doi.org/10.1016/S0167-8140(24)02186-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167814024021868},
author = {Nicola Dinapoli and Francesco Esposito and Martina D'Antoni and Vito Lanzotti and Luca Tagliaferri and Mariangela Massaccesi and Francesco Miccichè and Vincenzo Valentini and Maria Antonietta Gambacorta}
}
@article{CHAUHAN20242234,
title = {The Impact of Generative Artificial Intelligence on Research Integrity in Scholarly Publishing},
journal = {The American Journal of Pathology},
volume = {194},
number = {12},
pages = {2234-2238},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024003651},
author = {Chhavi Chauhan and George Currie}
}
@article{HE20241210,
title = {Generative Artificial Intelligence: A New Frontier of Scientific Misconduct?},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {120},
number = {5},
pages = {1210-1213},
year = {2024},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2024.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0360301624004413},
author = {Ling He and Hannah Hausman and Frank Pajonk}
}
@article{KSHETRI2024102760,
title = {The academic industry’s response to generative artificial intelligence: An institutional analysis of large language models},
journal = {Telecommunications Policy},
volume = {48},
number = {5},
pages = {102760},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102760},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124000570},
author = {Nir Kshetri},
keywords = {Academic industry, ChatGPT, Generative artificial intelligence, Institutional theory, Large language models, Theorization},
abstract = {This paper examines academic institutions' heterogeneous initial responses to generative AI (GAI) tools like ChatGPT and factors influencing increased acceptance over time. GAI's disruptive nature coupled with uncertainty about impacts poses adoption challenges. However, external pressures from stakeholders seeking GAI integration contribute to changing attitudes. Actions of institutional change agents also drive growing acceptance by increasing awareness of GAI advantages. They challenge prevailing logics emphasizing assessments, proposing new values around employability and job performance. Additionally, academic institutions reevaluating GAI's value creation potential through applications and evolving business models contributes to favorable responses. The paper proposes an institutional theory framework explaining dynamics underpinning academic institutions' assimilation of GAI. It highlights how various mechanisms like external pressures, institutional entrepreneurs' theorization efforts justifying technology use, and internal sensemaking shape institutional norms and values, enabling academic systems' adaptation. The study informs policy and practice while directing future research toward validating propositions empirically and examining contextual dimensions including industry characteristics affecting GAI adoption.}
}
@article{YANG20241184,
title = {Chat Generative Pretrained Transformer (ChatGPT) and Bard: Artificial Intelligence Does not yet Provide Clinically Supported Answers for Hip and Knee Osteoarthritis},
journal = {The Journal of Arthroplasty},
volume = {39},
number = {5},
pages = {1184-1190},
year = {2024},
issn = {0883-5403},
doi = {https://doi.org/10.1016/j.arth.2024.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0883540324000275},
author = {JaeWon Yang and Kyle S. Ardavanis and Katherine E. Slack and Navin D. Fernando and Craig J. {Della Valle} and Nicholas M. Hernandez},
keywords = {ChatGPT, bard, machine learning, artificial intelligence, large language models},
abstract = {Background
Advancements in artificial intelligence (AI) have led to the creation of large language models (LLMs), such as Chat Generative Pretrained Transformer (ChatGPT) and Bard, that analyze online resources to synthesize responses to user queries. Despite their popularity, the accuracy of LLM responses to medical questions remains unknown. This study aimed to compare the responses of ChatGPT and Bard regarding treatments for hip and knee osteoarthritis with the American Academy of Orthopaedic Surgeons (AAOS) Evidence-Based Clinical Practice Guidelines (CPGs) recommendations.
Methods
Both ChatGPT (Open AI) and Bard (Google) were queried regarding 20 treatments (10 for hip and 10 for knee osteoarthritis) from the AAOS CPGs. Responses were classified by 2 reviewers as being in “Concordance,” “Discordance,” or “No Concordance” with AAOS CPGs. A Cohen’s Kappa coefficient was used to assess inter-rater reliability, and Chi-squared analyses were used to compare responses between LLMs.
Results
Overall, ChatGPT and Bard provided responses that were concordant with the AAOS CPGs for 16 (80%) and 12 (60%) treatments, respectively. Notably, ChatGPT and Bard encouraged the use of non-recommended treatments in 30% and 60% of queries, respectively. There were no differences in performance when evaluating by joint or by recommended versus non-recommended treatments. Studies were referenced in 6 (30%) of the Bard responses and none (0%) of the ChatGPT responses. Of the 6 Bard responses, studies could only be identified for 1 (16.7%). Of the remaining, 2 (33.3%) responses cited studies in journals that did not exist, 2 (33.3%) cited studies that could not be found with the information given, and 1 (16.7%) provided links to unrelated studies.
Conclusions
Both ChatGPT and Bard do not consistently provide responses that align with the AAOS CPGs. Consequently, physicians and patients should temper expectations on the guidance AI platforms can currently provide.}
}
@article{HOSSEINI2025100520,
title = {A social-environmental impact perspective of generative artificial intelligence},
journal = {Environmental Science and Ecotechnology},
volume = {23},
pages = {100520},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2024.100520},
url = {https://www.sciencedirect.com/science/article/pii/S2666498424001340},
author = {Mohammad Hosseini and Peng Gao and Carolina Vivas-Valencia}
}
@article{WAELALKHATIB2023102403,
title = {Drivers of generative artificial intelligence to fostering exploitative and exploratory innovation: A TOE framework},
journal = {Technology in Society},
volume = {75},
pages = {102403},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102403},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23002087},
author = {Ayman {wael AL-khatib}},
keywords = {Generative artificial intelligence, TOE framework, Exploratory innovation, Exploitative innovation},
abstract = {This research work aims to investigate the antecedents of generative artificial intelligence (GEN-AI) adoption, and exploratory and exploitative innovation. A conceptual model based on the technology-organization-environment (TOE) framework is proposed and tested empirically using online survey-based data collected from 260 managers and administrative employees located in the Jordanian retailing industry. To achieve the objectives of this work a covariance-based- structural equation modelling (CB-SEM) was employed. The results indicate that relative advantage, top management support, organizational readiness, and customer pressures positively influence GEN-AI adoption. The empirical results demonstrated that the influence of compatibility and competitive pressures on GEN-AI adoption are insignificant. It was found that complexity negatively influence of GEN-AI adoption, also the findings confirm the positive impact of GEN-AI on both exploratory and exploitative innovation. The findings of the existing research would be valuable for GEN-AI technology providers, managers and top management in the retail firms sector in terms of building effective procedures to promote the successful adoption of GEN-AI technologies and innovation.}
}
@article{CHENG2024899,
title = {Principles and challenges of generative artificial intelligence detection},
journal = {British Journal of Anaesthesia},
volume = {133},
number = {4},
pages = {899-901},
year = {2024},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2024.06.037},
url = {https://www.sciencedirect.com/science/article/pii/S000709122400415X},
author = {Kunming Cheng and Wanqing Li and Nan Zhang and Xiaojun Liu and Haiyang Wu},
keywords = {academic publishing, artificial intelligence, ChatGPT, detection, generative AI, peer review}
}
@article{XU2024e32364,
title = {Generative artificial intelligence in healthcare from the perspective of digital media: Applications, opportunities and challenges},
journal = {Heliyon},
volume = {10},
number = {12},
pages = {e32364},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32364},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024083956},
author = {Rui Xu and Zhong Wang},
keywords = {ChatGPT, Healthcare, Digital media, Applications, Opportunities, Challenges, Digital health, Generative artificial intelligence, Large language models, Artificial intelligence generated content},
abstract = {Introduction
The emergence and application of generative artificial intelligence/large language models (hereafter GenAI LLMs) have the potential for significant impact on the healthcare industry. However, there is currently a lack of systematic research on GenAI LLMs in healthcare based on reliable data. This article aims to conduct an exploratory study of the application of GenAI LLMs (i.e., ChatGPT) in healthcare from the perspective of digital media (i.e., online news), including the application scenarios, potential opportunities, and challenges.
Methods
This research used thematic qualitative text analysis in five steps: firstly, developing main topical categories based on relevant articles; secondly, encoding the search keywords using these categories; thirdly, conducting searches for news articles via Google ; fourthly, encoding the sub-categories using the elaborate category system; and finally, conducting category-based analysis and presenting the results. Natural language processing techniques, including the TermRaider and AntConc tool, were applied in the aforementioned steps to assist in text qualitative analysis. Additionally, this study built a framework, using for analyzing the above three topics, from the perspective of five different stakeholders, including healthcare demanders and providers.
Results
This study summarizes 26 applications (e.g., provide medical advice, provide diagnosis and triage recommendations, provide mental health support, etc.), 21 opportunities (e.g., make healthcare more accessible, reduce healthcare costs, improve patients care, etc.), and 17 challenges (e.g., generate inaccurate/misleading/wrong answers, raise privacy concerns, lack of transparency, etc.), and analyzes the reasons for the formation of these key items and the links between the three research topics.
Conclusions
The application of GenAI LLMs in healthcare is primarily focused on transforming the way healthcare demanders access medical services (i.e., making it more intelligent, refined, and humane) and optimizing the processes through which healthcare providers offer medical services (i.e., simplifying, ensuring timeliness, and reducing errors). As the application becomes more widespread and deepens, GenAI LLMs is expected to have a revolutionary impact on traditional healthcare service models, but it also inevitably raises ethical and security concerns. Furthermore, GenAI LLMs applied in healthcare is still in the initial stage, which can be accelerated from a specific healthcare field (e.g., mental health) or a specific mechanism (e.g., GenAI LLMs’ economic benefits allocation mechanism applied to healthcare) with empirical or clinical research.}
}
@article{NIKOLOPOULOS2024104693,
title = {P.6.4 DEVELOPMENT OF A GENERATIVE ARTIFICIAL INTELLIGENCE ALGORITHM FOR THE REGENERATION OF VIRTUAL VOLUNTEERS IN BIOEQUIVALENCE STUDIES},
journal = {Physica Medica},
volume = {127},
pages = {104693},
year = {2024},
note = {Abstracts of the 2nd Panhellenic Congress of Medical Physics},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2024.104693},
url = {https://www.sciencedirect.com/science/article/pii/S1120179724012912},
author = {A. Nikolopoulos and V. Karalis}
}
@article{TRAN2024104079,
title = {Visual narratives in nursing education: A generative artificial intelligence approach},
journal = {Nurse Education in Practice},
volume = {79},
pages = {104079},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.104079},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324002087},
author = {Linh Duc Tran and Neo Tung and Eugene Tordecilla Macalinga and Arthur Tang and Brigitte Woo and Wilson Tam},
keywords = {Nursing education, Visual narrative, Generative artificial intelligence, DALL-E},
abstract = {Aim
The aim of this paper is to investigate the incorporation of visual narratives, such as comics and graphics, into nursing education using Generative Artificial Intelligence (GAI) models like DALL-E.
Background
Visual narratives serve as a powerful method for communicating intricate concepts in nursing education. Despite their advantages, challenges in creating effective educational comics persist due to the need for expertise in graphic design and the associated time and resource constraints.
Design
This study examines existing literature that highlights the efficacy of visual narratives in education and demonstrates the potential of GAI models, specifically DALL-E, in creating visual narratives for nursing education.
Methods
We analyze the potential of GAI models, specifically DALL-E, to create visual narratives for educational purposes. This was demonstrated through illustrative examples addressing sensitive topics, illustrating research methodology and designing recruitment posters for clinical trials. Additionally, we discussed the necessity of reviewing and editing the text generated by DALL-E to ensure its accuracy and relevance in educational contexts. The method also considered legal concerns related to copyright and ownership of the generated content, highlighting the evolving legal landscape in this domain.
Results
The study found that GAI, specifically DALL-E, has significant potential to bridge the gap in creating visual narratives for nursing education. While offering cost-effectiveness and accessibility, GAI tools require careful consideration of challenges such as text-related errors, misinterpretation of user prompts and legal concerns.
Conclusions
GAI models like DALL-E offer promising solutions for enhancing visual storytelling in nursing education. However, their effective integration requires a collaborative approach, where educators engage with these tools as co-pilots, leveraging their capabilities while mitigating potential drawbacks. By doing so, educators can harness the full potential of GAI to enrich the educational experience for learners through compelling visual narratives.}
}
@article{SINGH2024102776,
title = {Enhancing Patient Education on the Heart-Healthy Diet With Generative Artificial Intelligence Models},
journal = {Current Developments in Nutrition},
volume = {8},
pages = {102776},
year = {2024},
note = {Abstracts from NUTRITION 2024},
issn = {2475-2991},
doi = {https://doi.org/10.1016/j.cdnut.2024.102776},
url = {https://www.sciencedirect.com/science/article/pii/S2475299124007108},
author = {Som P Singh and Dharti Patel and Farah S Qureshi and Rohma Zaidi and Fawad Qureshi}
}
@article{GUO2024102408,
title = {Letter to the editor “A review of top cardiology and cardiovascular medicine journal guidelines regarding the use of generative artificial intelligence tools in scientific writing”},
journal = {Current Problems in Cardiology},
volume = {49},
number = {3},
pages = {102408},
year = {2024},
issn = {0146-2806},
doi = {https://doi.org/10.1016/j.cpcardiol.2024.102408},
url = {https://www.sciencedirect.com/science/article/pii/S0146280624000471},
author = {Dongke Guo and Yonghua Fu and Zhongxin Zhu}
}
@article{BARKER2024A43,
title = {Generative Artificial Intelligence as a Tool for Teaching Communication in Nutrition and Dietetics Education – an Novel Education Innovation},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {124},
number = {10, Supplement },
pages = {A43},
year = {2024},
note = {2024 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2024.06.093},
url = {https://www.sciencedirect.com/science/article/pii/S2212267224003873},
author = {L. Barker and J. Moore and H. Cook}
}
@article{NIKOLOPOULOS2024104690,
title = {P.6.1 CREATING VIRTUAL PATIENTS WITH A GENERATIVE ARTIFICIAL INTELLIGENCE ALGORITHM FOR CLINICAL STUDIES},
journal = {Physica Medica},
volume = {127},
pages = {104690},
year = {2024},
note = {Abstracts of the 2nd Panhellenic Congress of Medical Physics},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2024.104690},
url = {https://www.sciencedirect.com/science/article/pii/S1120179724012882},
author = {A. Nikolopoulos and V. Karalis}
}
@article{KOHNKE2023100156,
title = {Exploring generative artificial intelligence preparedness among university language instructors: A case study},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100156},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000358},
author = {Lucas Kohnke and Benjamin Luke Moorhouse and Di Zou},
keywords = {Artificial intelligence, AI, Generative AI, University language instructors, Higher education, English},
abstract = {The integration of generative artificial intelligence (AI) in English language teaching presents opportunities and challenges for instructors. This study explores the attitudes of higher education English language instructors towards generative AI tools, their intentions to use them and the institutional support and professional development necessary to teach and learn with them. As the field continues to evolve rapidly, it is essential to comprehend the readiness of front-line language instructors. This qualitative interpretive study seeks to identify the digital competencies and pedagogical knowledge required to implement generative AI in education and provide guidance for the design of professional development programmes that address the challenges and concerns associated with adopting AI. Drawing on semi-structured interviews with twelve instructors at a higher education institution in Hong Kong, the findings reveal the significance of familiarity and confidence with using AI-driven teaching tools, the challenges and concerns language instructors face and the need for tailored support and professional development. The study offers ten practical implications to cultivate language instructors’ digital competencies, pedagogical knowledge and positive attitudes towards integrating AI to enhance their students’ learning experiences.}
}
@article{SONG2024100069,
title = {Developing an immersive game-based learning platform with generative artificial intelligence and virtual reality technologies – “LearningverseVR”},
journal = {Computers & Education: X Reality},
volume = {4},
pages = {100069},
year = {2024},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2024.100069},
url = {https://www.sciencedirect.com/science/article/pii/S2949678024000199},
author = {Yanjie Song and Kaiyi Wu and Jiaoyang Ding},
keywords = {Generative AI, Virtual reality (VR), Game-based learning, Immersion, Interaction},
abstract = {The rapid evolution of generative artificial intelligence (AI) and virtual reality (VR) technologies are revolutionising various fields, including education and gaming industries. However, studies on how to enhance immersive game-based learning with AI and VR technologies remain scant. Given this, the article presents the creation of “LearningverseVR,” an immersive game-based learning platform developed using generative AI and VR technologies, which is based on “Learningverse,” a metaverse platform developed by the lead author and her research team. The “LearningverseVR” platform uses Unity as the client and Python, Flask and MySQL as the backend. Unity's multiplayer service provides multiplayer online functionality, supporting learners to engage in immersive and interactive learning activities. The design framework of the platform consists of two main components: Game-based learning with generative AI and immersion with VR technologies. First, generative AI is used to create NPCs with diverse personalities and life backgrounds, and enable learners to interact with NPCs without scripted dialogues, creating an interactive and immersive game-based learning environment. Secondly, such a learning experience is enhanced by leveraging the Large Language Model (LLM) ecosystem with VR technology. The creation of the “LearningverseVR” platform provides novel perspectives on digital game-based learning.}
}